job_title,company,job_location,post_date,salary,job_url,job_description
Software Engineer - Data Insights,PayPal,"Chicago, IL",Posted 19 days ago,,https://www.indeed.com/rc/clk?jk=902d5c38516cb9a3&fccid=978d9fd9799d55a8&vjs=3,"At PayPal (NASDAQ: PYPL), we believe that every person has the right to participate fully in the global economy. Our mission is to democratize financial services to ensure that everyone, regardless of background or economic standing, has access to affordable, convenient, and secure products and services to take control of their financial lives.
Job Description Summary: Your way to impact: Merchant reporting is crucial for our Merchants so that they can close their account books timely and accurately with complete payment data in core markets. We are looking for people who have a passion for developing massively scalable, distributed software systems that require high availability to our business. As a member on the Merchant Reporting and reconciliation team, you thrive in a fast-paced environment and enjoy driving innovation through rapid prototyping and iterative development. You will work directly with our Product Owners and Domain Technical Leads to create outstanding solutions and deliver incredible reporting products. You will be involved from ideation to rollout.
Job Description: 

  Your day to day:
  

Work with Product Managers and other business partners to identify opportunities for improvement
Analyze data based on product requirements
Create reports for internal teams and/or external clients
Use graphs, infographics and other methods to visualize data
Structure large data sets to find usable information
Work with a team of analysts and other associates to process information
Create presentations and reports based on recommendations and findings
Define validation queries when needed and how to identify discrepancies in the data as they arise
Write queries for runbooks that automate the discrepancy identification process
Implement the reporting data model
Deliver within schedule in an Agile software development using test-driven development methodologies.
Participate in development life cycle activities like design, coding, testing and production release.
Be proactive with identifying areas for improvement and innovation to improve development productivity



   What do you need to bring:
  

BS in EE/CS or equivalent work experience and successful completion of major projects for which you can show code examples.
1-2 years of hands-on data/software engineering experience
Experience working with coding languages—preferably SQL, Java, Spark-SQL, Pyspark, Python
Experience working with SQL and noSQL DataBase
High proficiency in MS Excel, MS powerpoint, GIT, Apache Airflow
Have a passion for quality and writing clean and solid code that scales and performs well.
Strong desire to learn, push the envelope, and share knowledge with others.
Excellent analytical and time management skills
Teamwork skills with a problem-solving attitude



Our Benefits:
 At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.
 We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com 

Who We Are:
 To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx 

PayPal has remained at the forefront of the digital payment revolution for more than 20 years. By leveraging technology to make financial services and commerce more convenient, affordable, and secure, the PayPal platform is empowering more than 400 million consumers and merchants in more than 200 markets to join and thrive in the global economy. For more information, visit paypal.com.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.
 As part of PayPal’s commitment to employees’ health and safety, we have established in-office Covid-19 protocols and requirements, based on expert guidance. Depending on location, this might include a Covid-19 vaccination requirement for any employee whose role requires them to work onsite. Employees may request reasonable accommodation based on a medical condition or religious belief that prevents them from being vaccinated."
Data Engineer,Discover Financial Services,"Riverwoods, IL 60015",PostedJust posted,"$84,500 - $142,500 a year",https://www.indeed.com/rc/clk?jk=747dbc6ddb48f69a&fccid=6ce7e0d9f67a9961&vjs=3,"Discover. A brighter future. 
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine. 

 Come build your future, while being the reason millions of people find a brighter financial future with Discover. 


Job Description:
 The Data Engineer is responsible for designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community . Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management. 

 Responsibilities 

 Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members 

 Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies 

 Demonstrates strong technical aptitude across data engineering practices: 

 Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting 

 Designing advanced SQL queries 

 Leveraging metadata-driven framework for solutions 

 Developing test scripts for unit and integration testing 

 Develops test methodologies for specific products 

 Leads code review sessions and other process and operational improvement initiatives 

 Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack) 

 Works on holistic solutions, driving feature and story delivery (Agile) 

 Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline 

 Participates in the on-call rotation for support 

 Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities 

 Builds strong collaborative working relationship both within the team and cross- functionally 

 Minimum Qualifications 


At a minimum, here’s what we need from you:
 Bachelor's Degree in Computer Science or related field 

 3 + years of experience in Data Platform Administration/Engineering 


Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale 

 Preferred Qualifications 


If we had our say, we’d also look for:
 ETL/ELT Tools (AbInitio, DataStage, Informatica) 

 Cloud Tools and Databases (AWS, Snowflake, Postgres, DynmaoDB) 

 Programming languages (Unix scripting, Python, etc.) 

 Leverage CI/CD framework for data integration, Open Source 

 Experience working in cloud platforms (AWS, GCP, Azure) 

 Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs 

 Experience optimizing SQL both relational and nosql 

 External applicants will be required to perform a technical interview. 

 #LI-CM 


Compensation: The base pay for this position generally ranges between $84,500.00 to $142,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position. 


Benefits:
 We also offer a range of benefits and programs based on eligibility. These benefits include: 

 Paid Parental Leave 

 Paid Time Off 

 401(k) Plan 

 Medical, Dental, Vision, & Health Savings Account 

 STD, Life, LTD and AD&D 

 Recognition Program 

 Education Assistance 

 Commuter Benefits 

 Family Support Programs 

 Employee Stock Purchase Plan 

 Learn more at MyDiscoverBenefits.com . 

 What are you waiting for? Apply today! 

 All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management. 

 Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)"
Data Engineer,ThreeFlow,"Remote in Chicago, IL",Posted 2 days ago,,https://www.indeed.com/rc/clk?jk=8dc1503a5d87e416&fccid=3e64b230df939e8b&vjs=3,"ThreeFlow is looking for results-driven teammates who are eager to solve problems and question the status quo. We cultivate an inclusive culture where everyone can contribute, grow, feel valued, and make an impact.
 We're excited to add an experienced Data Engineer to join our Data & Analytics Engineering team. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. You will support our software developers, data analysts, and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
 Our tech stack is dbt, Postgresql, BigQuery, and Stitch Data, and our work is managed and delivered through agile methodologies. We are a fully distributed team.
 About the role

Partner with data and analytics experts to assemble complex data sets that meet functional / non-functional business requirements 
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. 
Build and maintain optimal data pipeline infrastructure required for extraction, transformation, and loading of data from a wide variety of data sources using SQL, dbt, and BigQuery technologies 
Work with stakeholders including the Executive, RevOps, Product, Data and Engineering teams to assist with data-related technical issues and support their data infrastructure needs 
Collaborate with our data science team to train AI models on our document corpus 

About you

You are a self-starter and are comfortable supporting the data needs of multiple teams, systems, and products 
You are excited by the prospect of optimizing and contributing to our future data architecture in support of our next generation of products and data initiatives 
You have strong project management and organizational skills 
You have experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement 
Experience with ETL/ELT patterns designed for scale and reliability 
Moderate dbt experience is a plus 
Experience developing advanced SQL 
Experience working in an agile environment and comfortable working with remote team members 
Experience with one or more of the following data warehouse platforms: Snowflake, Redshift, BigQuery 
Experience with Perfect, PostgreSQL, AWS, and GCP is helpful, though not required 


Please note that immigration sponsorship (H-1B, TN, etc.) is not currently available for this position.
 Notice
 Scams in which fraudsters impersonate legitimate businesses for personal gain are on the rise and can come in many forms. ThreeFlow doesn't interview candidates via email, and job offers are only extended by the hiring manager after a thorough interview process involving phone and/or Zoom interviews. Our recruiters only use @threeflow.com email addresses, and we'll never ask you to provide sensitive information like your social security number or bank account details as a part of our interview process or through a PDF form. If you receive a suspicious email regarding a position or job offer with ThreeFlow, please don't respond. Report it as spam, and forward that email to careers@threeflow.com.
 Our (FTE) benefits

Competitive salary and equity
Comprehensive health benefits for you and your family
401(k) plan
Generous paid time off
Paid parental leave
Stipend to improve your work from home experience
Stipend for learning and development 

Our values


ThreeFlow's core values are the foundation of our culture and remain constant as we grow.



Constantly push boundaries We think beyond what might be easy or obvious when we're problem solving. We get scrappy and creative in front of hurdles.
Collaborate enthusiastically Our collaboration as a team is our most valuable asset. We're able to go farther when we act together.
Work with respect We're deliberate, honest, and kind with the words and actions we use. We believe people have positive intent with their actions.
Grow together We value developing ourselves personally and professionally to achieve our goals. We encourage taking chances and celebrate curiosity.

About ThreeFlow
 ThreeFlow is a Benefits Placement System, a new category of enterprise software that allows benefits brokers and insurance carriers to manage the entire placement process in one shared system. We make it easier for carriers to win business and brokers to empower employers with the details they need to make better decisions. By connecting people, systems, and information, we enable easier communication, a quicker process, and better decisions making busy people more productive. Learn more at threeflow.com
 ThreeFlow is committed to building an inclusive working environment regardless of gender, sexual orientation, religion, ethnicity, race, education, age, or other personal characteristics. We believe that people do their best work when they can be themselves, and we're creating an environment to enable them to do just that."
Data Engineer- Costco Logistics BI,Costco Wholesale,"Chicago, IL",Posted 30+ days ago,"$75,000 - $110,000 a year",https://www.indeed.com/rc/clk?jk=134b06388de37de7&fccid=9b77e2b0ccfb3838&vjs=3,"Costco IT is responsible for the technical future of Costco Wholesale, the third largest retailer in the world with wholesale operations in fourteen countries. Despite our size and explosive international expansion, we continue to provide a family, employee centric atmosphere in which our employees thrive and succeed. As proof, Costco ranks seventh in Forbes “World’s Best Employers”. 
This is an environment unlike anything in the high-tech world and the secret of Costco’s success is its culture. The value Costco puts on its employees is well documented in articles from a variety of publishers including Bloomberg and Forbes. Our employees and our members come FIRST. Costco is well known for its generosity and community service and has won many awards for its philanthropy. The company joins with its employees to take an active role in volunteering by sponsoring many opportunities to help others. 
Come join the Costco Wholesale IT family. Costco IT is a dynamic, fast-paced environment, working through exciting transformation efforts. We are building the next generation retail environment where you will be surrounded by dedicated and highly professional employees. 
The Data Engineer - Costco Logistics BI is responsible for the end to end data pipelines to power Costco Logistics reporting. This role is focused on data engineering to build and deliver automated data pipelines from a plethora of internal and external data sources. The Data Engineer will partner with product owners, engineering and data platform teams to design, build, test, and automate data pipelines that are relied upon across the company as the single source of truth. 
If you want to be a part of one of the worldwide BEST companies “to work for”, simply apply and let your career be reimagined.


 ROLE
 Develops and operationalizes data pipelines to make data available for consumption (Costco Logistics BI).
 Works with data architects and data/BI engineers to design data pipelines and recommends ongoing optimization of data storage, data ingestion, data quality, and orchestration.
 Designs, develops, and implements ETL/ELT processes using IICS (Informatica Cloud).
 Uses MySQL to improve and speed up delivery of our data products and services. 
 Uses Azure services such as Azure SQL DW (Synapse), ADLS, Azure Event Hub, Azure Data Factory to improve and speed up delivery of our data products and services.
 Implements big data and NoSQL solutions by developing scalable data processing platforms to drive high-value insights to the organization.
 Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery.
 Identifies ways to improve data reliability, efficiency, and quality of data management.
 Communicates technical concepts to non-technical audiences both written and verbal.
 Performs peer reviews for other data engineer’s work.
 REQUIRED
 3+ years’ experience engineering and operationalizing data pipelines with large and complex datasets.
 2+ years’ experience with Informatica PowerCenter.
 2+ years’ experience with Informatica IICS.
 2+ years’ experience working with Cloud technologies; such as ADLS, Azure Databricks, Spark, Azure Synapse, Cosmos DB, and other big data technologies. 
 2+ years’ experience with Data Modeling, ETL, and Data Warehousing.
 2+ years’ experience implementing data integration techniques such as event / message based integration (Kafka, Azure Event Hub), ETL. 
 2+ years’ experience with Git / Azure DevOps.
 Extensive experience working with various data sources; SQL, Sql Server database, flat files (csv, delimited), Web API, XML.
 Advanced SQL skills; Understanding of relational databases, business data, and the ability to write complex SQL queries against a variety of data sources.
 Strong understanding of database storage concepts; Data Lake, Relational Databases, NoSQL, Graph, Data Warehousing.
 Able to work in a fast-paced agile development environment.
 Recommended 
 Microsoft Azure/similar certifications. 
 Experience delivering data solutions through agile software development methodologies. 
 Experience with PowerShell, Python or similar scripting language. 
 Experience with UC4 Job Scheduler.
 Exposure to the retail industry.
 Excellent verbal and written communication skills.
 BA/BS in Computer Science, Engineering, or equivalent software/services experience.
 Required Documents

Cover Letter


Resume



 California applicants, please click here to review the Costco Applicant Privacy Notice.


 Pay Ranges:
 Level 1 - $75,000 - $110,000
 Level 2 - $100,000 - $135,000
 We offer a comprehensive package of benefits including paid time off, health benefits - medical/dental/vision/hearing aid/pharmacy/behavioral health/employee assistance, health care reimbursement account, dependent care assistance plan, short-term disability and long-term disability insurance, AD&D insurance, life insurance, 401(k), stock purchase plan to eligible employees.
 Costco is committed to a diverse and inclusive workplace. Costco is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or any other legally protected status. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request to IT-Recruiting@costco.com
 If hired, you will be required to provide proof of authorization to work in the United States. Applicants and employees for this position will not be sponsored for work authorization, including, but not limited to H1-B visas."
Data Engineer,StoneX Group,"Chicago, IL 60604 (Loop area)",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=91602f5a67f98e04&fccid=95d5989e745a95bc&vjs=3,"Overview: 
 
 Position Purpose: The Data Platform Team looks to raise the level and productivity of data engineering and data science by building, scaling and supporting our big data infrastructure with an emphasis on simple and efficient solutions on top of complex distributed data stores. As a contributing platform engineer you will assist in architecting, designing and implementing a new, cutting edge, cloud platform expanding our data assets within scalable, elastic systems that can be instantiated on demand, on cloud.
  Responsibilities: 
 
Create cloud and big data technical design recommendations for developing and integrating new software and system technologies – from the physical layer through to the virtual layer – per written specifications; test, evaluate, engineer, implement and support said technologies.
 Review, influence and contribute to new and evolving design, architecture, standards, and methods for operating and contributing to services within our big data ecosystem.
 Add to our existing business and data models. Reviews existing designs and processes to highlight more efficient ways to complete existing workload more effectively through industry perspectives. 
Drive technical innovation and efficiency in infrastructure operations through automation by assisting in improvements to continuous integration, continuous deployment and monitoring 
Create cloud and big data technical design recommendations for developing and integrating new software and system technologies – from the physical layer through to the virtual layer – per written specifications; test, evaluate, engineer, implement and support those technologies
 Collaborates with technical teams and utilizes system expertise to deliver technical solutions, continuously learning and evolving big data skillsets.
 Monitors and evaluates overall strategic data infrastructure; tracks system efficiency and reliability; identifies and recommends efficiency improvements and mitigates operational vulnerabilities. Respond to and resolve emergent service problems. Design solutions using automation and self-repair rather than relying on alarming and human intervention
 Qualifications: 
 
Pursuing a Bachelor’s degree or relevant work experience in Computer Science, Mathematics, Electrical Engineering or related technical discipline.
 Experience developing software in a professional environment (preferably financial services but not required)
 Understanding of Enterprise architecture patterns, Object Oriented & Service Oriented principles, design patterns, industry best practices
 Foundational knowledge of data structures, algorithms, and designing for performance.
 Competent in one of the following programming languages: Java, C# or Python (preferred) and willingness to learn and adopt new languages as necessary
 Experience in database technology like MSSQL and one of key value and document databases like MongoDb, Dynamo Db, Casandra.
 Exposure to containers, microservices, distributed systems architecture, orchestrators and cloud computing.
 Comfortable with core programming concepts and techniques (e.g. concurrency, memory management)
 Enjoys working with algorithms and data structures (e.g. trees, hash maps, queues)
 Data Analytics and Data Science experience will be a plus.
 Good sense of user interaction and usability design to provide an intuitive, seamless end user experience.
 Excellent communications skills and the ability to work with subject matter expert to extract critical business concepts.
 Ability to work and potentially lead in an Agile methodology environment."
Data Engineer,Kraft Heinz Company,"Hybrid remote in Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=7f9fa28f63190c9c&fccid=ef4be98af276034b&vjs=3,"General information 




All posting locations: Chicago, Illinois, United States of America 
Job Function: 16 - Digital 
Date Published: 22-Jun-2023 
Ref #: R-71425 








Description & Requirements 



3+ years of experience working in data engineering or architecture role. Expertise in ELT and data analysis and experience with SQL and at least one programming language (Python/R preferred) Experience developing and maintaining data warehouses in big data solutions e.g.- Snowflake Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred) Experience with cloud service providers including AWS- Azure- or Google. Database development experience using Hadoop- SPARK or Big Query and experience with a variety of relational- NoSQL- and cloud database technologies. Experience with BI tools such as Alteryx- Tableau- Power BI- Looker. Experience and/or knowledge of CI/CD (continuous integration and continuous deployment) practice using GitHub or Azure repos. Conceptual knowledge of data and analytics- such as dimensional modeling- ELT- reporting tools- data governance- data warehousing- structured and unstructured data. Familiarity with the Linux operating system Familiarity with data engineering and workflow management frameworks such dbt. Nice to have exposure to machine learning- data science- computer vision- artificial intelligence- statistics- and/or applied mathematics. An agile learner who brings strong problem-solving skills- and enjoys working as part of a technical- cross functional team to solve complex data problems. Bachelor’s degree required; Computer Science- MIS- or Engineering preferred or equivalent experience.
 Location(s)
 Employee's Home - National








About Us



Kraft Heinz is a global food company with a delicious heritage. With iconic and emerging food and beverage brands around the world, we deliver the best taste, fun and quality to every meal table we touch. We’re on a mission to disrupt not only our own business, but the global food industry. A consumer obsession and unexpected partnerships fuel our progress as we drive innovation across every part of our company. 
Around the world, our people are connected by a culture of ownership, agility and endless curiosity. We also believe in being good humans, who are working to improve our company, communities, and planet. We’re proud of where we’ve been – and even more thrilled about where we’re headed – as we nourish the world and lead the future of food.  





Why Us



We grow our people to grow our business. We champion great people who bring ambition, curiosity, and high performance to the table as the guardians of our beloved and nostalgic brands. Good isn't good enough. We choose greatness every day by challenging the ordinary and making bold decisions. All while celebrating our wins - and our failures – as we work together to lead the future of food. 
Challenging the status quo takes talent. We invest in your purpose and potential by developing skills and nurturing strengths that leave a legacy on our business and a lasting impact on your career. Because great people make great companies, and we’re growing something great here at Kraft Heinz. 





Office Collaboration & Hybrid Work Environment




We believe our office environment fuels our collaboration, connection & community as an organization and allows our employees to grow toward greatness. We also believe providing a more flexible and agile model is essential in today’s workplace. A majority of our office-based employees will be able to work remotely for up to two days each week. Additionally, employees who are subject to this hybrid model will be eligible to work from anywhere for up to six weeks in a rolling 12-month period (in maximum two-week increments and according to benefits and tax guidelines). Some jobs may be required to be performed fully in office depending on the role’s responsibilities and requirements.




Kraft Heinz is an Equal Opportunity Employer that prohibits discrimination or harassment of any type. All qualified applicants are considered for employment without regard to race, color, national origin, age, sex, sexual orientation, gender, gender identity or expression, disability status, protected veteran status, or any other characteristic protected by law. Applicants who require an accommodation to participate in the job application or hiring process should contact NATAI@kraftheinz.com."
Data Engineer,CONAGRA,"Hybrid remote in Chicago, IL 60654",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=e8448f83c885bf9f&fccid=905dc9bf3b9cfe58&vjs=3,"Conagra Brands is on a journey to expand and integrate best-in-class Analytics solutions across the enterprise using a continuous delivery framework. Come help deliver our Enterprise Data and Analytics ambitions in a Data Engineer capacity! The Enterprise Data and Analytics team is accountable for building, shaping, and maintaining analytics across the enterprise, with an initial focus in Supply Chain business domain. This team works with exciting cutting-edge cloud-based technologies like Databricks, Snowflake, Azure cloud stack and other world class tools to deliver solutions. You will use your skills as to demonstrate how to turn this data into concrete value-add for the business. We are looking for a technologically savvy, creative professional to drive new age technologies that enable our digital transformation.

 Reporting to the Director of Advance Analytics, as the Data Engineer, you will be responsible for delivering all aspects of data product development activities. You will first work with solution architect, senior data engineers, data scientists, and business analysts to understand data requirements and priorities. These priorities will then be broken down to workable chunks by the Sr. Data Engineer and assigned to themselves and other data engineering members on the team for delivery.

 You Will (Position Responsibilities)

 Gather, structure, and prepare data for usability including sourcing, filtering, tagging, joining, parsing, and normalizing data sets for use in analytical models.
 Leverage overall data modeling standards, guidelines, best practices, and approved modeling techniques; build conceptual, logical, and physical data models; review and validate data models with key business representatives, data owners, solution architects, and end-users; reviews and maintain technical design documents.
 Develop batch & real-time analytical solutions, prototypes, and proofs of concept for selected solutions.
 Build frameworks and tools to empower our data scientists and analysts.
 Implement complex analytical projects with a focus on collecting, managing, analyzing, and visualizing data.
 Build automations to validate source to target data accuracy during build, testing and support phases.
 Create complex and efficient data pipelines to take data from various operational systems and integrate into cloud platforms for analytics and reporting purposes.
 SQL performance tuning skills- Identification and resolution of performance bottlenecks; join optimization; data model optimization; data pre-processing
 Oversee creation of automated test cases to ensure data values are within expected ranges, complete and within quality parameters.
 Create job schedules to chain together daily, weekly, monthly, or ad-hoc data flow schedules with predecessors and successors.
 Operate within DevOps, DataOps, and MLOps frameworks

 You Have (Position Qualifications)

 Bachelor’s degree in Computer Science, Engineering, Mathematics, or related technical fields.
 2+ years’ experience in software development, with a focus in Data Engineering, Predictive Analytics, AI/ML, and Cloud Services.
 Strong experience in cloud data platforms such as Azure, Databricks, and Snowflake.
 Practical experience with several programming languages: Python, SQL, R, and Spark.
 Experience in several data transformation tools such as Informatica and dbt
 Experience in working with large amounts of data (structured and unstructured), building data pipelines to create data products, and generating insights utilizing Data Science and Advanced Analytics for batch, event-driven and real-time analytics implementations
 Demonstrated knowledge about DevOps, DataOps and MLOps practices
 Experience delivering data and analytics products in matrix organizations under the Scaled Agile Framework (SAFe).
 Experience working in complex product business environments, preferably within Supply Chain, Innovation/R&D, and Manufacturing domains.

 Our Modern Workplace

 Conagra’s culture of collaboration enhances our ability to meet critical business goals, deliver value to customers and consumers and provide you with the flexibility you need to achieve a better work-life balance. We carefully consider each role and how often each team member needs to collaborate in-person. The successful candidate will operate in a hybrid environment in our Chicago office with frequency of time in office tied directly to evolving business needs and moments that matter.


 #LI-MC1
 #LI-Hybrid
 #LI-Associate

 Our Benefits:

 We care about your total well-being and will support you with the following, subject to your location and role:

 Health: Medical, dental and vision insurance, company-paid life, accident and disability insurance
 Wealth: great pay, incentive opportunity, matching 401(k) and stock purchase plan
 Growth: online courses, virtual and classroom development experiences
 Balance: paid-time off, parental leave, flexible work-schedules (subject to your location and role)


 Our Company:

 Conagra Brands is one of North America's leading branded food companies. We have a rich heritage of making great food, and a team that’s passionate about innovation and growth. Conagra offers choices for every occasion through iconic brands, such as Birds Eye®, Marie Callender's®, Banquet®, Healthy Choice®, Slim Jim®, Reddi-wip®, and Vlasic®, and emerging brands, including Angie's® BOOMCHICKAPOP®, Duke's®, Earth Balance®, Gardein®, and Frontera®.
 We pride ourselves on having the most impactful, energized and inclusive culture in the food industry. For more information, visit www.conagrabrands.com.

 Conagra Brands is an equal opportunity employer and considers qualified applicants for employment without regard to sex, race, color, religion, ethnic or national origin, gender, sexual orientation, gender identity or expression, age, pregnancy, leave status, disability, veteran status, genetic information and/or any other characteristic or status protected by national, federal, state or local law."
Data Engineer,HNI Corporation,"Chicago, IL 60606 (Loop area)",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=1c987d61b8f871f7&fccid=281cabfb632997df&vjs=3,"HNI Corporation is a global family of brands for the workplace and home dedicated to enhancing the spaces where we live, work, and gather. We pride ourselves on fostering an environment where we make a positive impact on others; upholding our beliefs in integrity, inclusion and belonging.
 What We Need:
 We are looking for a Data Engineer to join our Decision Science and Business Intelligence team in Chicago, IL.
 In this role, you’ll work within our cloud data infrastructure used by different teams at HNI and see data projects from beginning to end. This role provides opportunities to shape the future of data infrastructure and work on the latest cloud data technologies to develop analytic systems that scale with company growth. You will design, build, and manage scalable data pipelines which provide insights to multiple business partners for data-driven decision making.
 What You Will Do:


 Build, manage, and support ELT data pipelines on Snowflake with SQL
 Ingest data into our enterprise cloud data lake and data warehousing platform, supporting the needs of business intelligence, data science and advanced analytics projects
 Partner and collaborate with the business and members of the analytics teams to design new data solutions
 Optimize existing pipelines to reduce compute time and meet SLA targets
 Brainstorm and contribute ideas to our technology, algorithms, and products

 What You Have:


 4-year degree in a technical field (Computer Science, Data Science, or a related field), or equivalent professional experience
 Hands on experience with Cloud Data environments, preferably with Azure and/or Snowflake
 Excellent communication, teamwork and consulting skills
 Strong analytical and problem-solving skill set

 We look forward to hearing from you!
 
 HNI Corporation (NYSE: HNI) is a manufacturer of workplace furnishings and building products, operating under two segments. The workplace furnishings segment is a leading global designer and provider of commercial furnishings, going to market under multiple unique brands. The residential building products segment is the nation’s leading manufacturer and marketer of hearth products.
 As one of the larger employers in Iowa, HNI Corporation was recognized in 2018, 2019, and 2020 for the diversity of our Board of Directors and was named in 2020, 2021, and #6 in 2022 as one of America's Most Responsible Companies by Newsweek.
 How we act today protects how we live tomorrow. Check out our CSR Report here: https://www.hnicorp.com/social-responsibility
 Diversity, equity, and inclusion (DEI), are not just core beliefs at HNI - they are operational imperatives. We value each other’s differences in experiences and ideas to solve problems and better serve our customers. Take a look at our DEI goals here: https://www.hnicorp.com/diversity-equity-and-inclusion
 We offer Benefits on Day 1, including a new voluntary benefit, Daily Pay! To learn about all the benefits HNI has to offer visit www.HNIbenefits.com.
 We also invite you to visit us at www.HNICorp.com to learn more!"
Data Engineer,Legal & General America,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=8995aa7cddab676d&fccid=ddfa0ad7790bd7c0&vjs=3,"Overview 



As a Data Engineer you will be joining a motivated team of professionals working to engineer solutions for entire breath of the firm, including Data, Portfolio Managers, Analysts, Quants, Marketing, Compliance and Operations. You will gain exposure to a variety of partners at all levels, from Senior Technology leaders to Senior Business partners. In addition, you will obtain exposure and experience in the latest technologies. We are adopting a wide array of technology and approaches from some of the most proven Open-Source projects to tried-and-true enterprise platforms such as Cloudera Data Platform.


 The candidate will be working both in feature teams and sometimes independently. They must be able to build strong relationships with product teams, business stakeholders and end-users to ensure that the data product meets their requirements and expectations.
    



Responsibilities 



Responsibilities

 Building and supporting event-driven solutions using the Cloudera Data Platform (PaaS).
 Contribute to large-scale global data engineering.
 Develop, construct, test and maintain event-driven data architecture.
 Develop data set processes for data modelling, mining, and production
 Employ a variety of languages and tools to marry systems together.
 Recommend ways to improve data reliability, efficiency, and quality.
 Implement large data migration efforts to modern architectures.
 Document data flows, including system integrations and design patterns.


 Competence and Characteristics

 Learning doesn’t stop. You are perpetual student to all aspects of data engineering and methodologies; it is a passion of yours.
 You understand the importance and impact of modern data architectures (e.g. event-driven architectures, data democratization, platform approaches to support ML/AI, stream processing and integrating real-time analytics into business applications).
 You’ll be drawing on all your passion for technology, hands-on experience and knowledge of latest Big Data and Engineering best practices to help you gain the respect and credibility of those around you.
 Possess a passion for data modelling and design from conceptualization to optimization.
 Communication is critical to our success. You must be able to demonstrate excellent verbal and written communication skills and the ability to interact professionally with a diverse group of partners, managers, and subject matter experts.
 You are constantly looking for a new and exciting challenge. You must be able to demonstrate the ability to contribute within the change team to tackle challenging requirements and tight timescales.







Qualifications 



Experience and Background

 3-5 Years of hands-on experience with AWS Data and Analytics Technologies.
 Experience designing and developing ELT/ETL pipelines using AWS Glue, AWS Lambda, Eventbridge, and other supporting AWS Serverless components.
 Experience with AWS Data Storage – AWS S3 and AWS RDS.
 Experience and understanding of standard SQL database products (Postgres, MySQL, SQL Server) and strong SQL skills.
 Experience working within a set of data architecture principles.
 Understand the importance of domain-defined data ownership within an organization.
 Understanding and application of modern data processing technology stacks. Well-versed with Batch and Streaming processes.
 Well-versed with IAM principles of least access in AWS.
 Basic understanding of AWS DevOps and CI/CD methodologies. Should be comfortable in automating Unit and Integration Test cases for Data Pipelines.
 Hands-on experience with AWS Codebuild and Codepipeline preferred.
 Good understanding of Infrastructure-as-code and hands-on experience with AWS Cloudformation.


 Specialist Knowledge & Skills

 Data Ingestion: Apache Spark, AWS Glue
 Event Streaming: Apache Kafka, AWS Glue Streaming
 Data Orchestration: Apache NiFi, UC4, Apache Airflow
 Platform: Cloudera, AWS
 API Approach: Web Sockets, RESTful, SOAP
 Languages: Python, Scala
 Development Methodologies: Agile
 Database: Strong SQL and RDBMS knowledge, NoSQL
 Database Products: Postgres, MYSQL
 Database design: Star Schema (Facts and Dimensions), Data Lake Principles


 Preferred Academic Qualifications

 Bachelor’s Degree in Computer Science or Engineering






EOE Statement 




     As an EOE employer, Legal & General Investment Management America will extend equal opportunity to all employees
      and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity, ancestry,
      national origin, age, disability, medical condition, genetic information, marital status, pregnancy, military status, and/or any
      other characteristic protected under applicable federal, state or local laws governing nondiscrimination in employment. (2020)"
Data Engineer,IMC Financial Markets,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=54b47dfa1c099410&fccid=93998d7f12d61ef7&vjs=3,"LIFE AT IMC AS A DATA ENGINEER
  
 WHO WE ARE AND WHAT WE DO
 IMC is a leading global market maker, using algorithmic trading and advanced technology to buy and sell securities on multiple trading venues worldwide. We provide liquidity to the financial markets, driving efficiencies for buyers and sellers.

 Founded in 1989, we are an ambitious, innovative company and identified early on the importance technology would play in the fast-paced evolution of trading. This entrepreneurial spirit still drives us today and can be found in all of our offices around the world.

 OUR TEAM
 We now operate globally from offices in Europe, the US and Asia Pacific. Our employees work closely together in multidisciplinary teams, making our success possible.

 Technology - At IMC, technology is not a department, it is at the heart of everything we do. Our technologists push the limits of possibility, and then look beyond. In our fast-paced environment, short feedback loops mean projects worked on in the morning can enter production the next day.

 Trading – Although our traders come from many backgrounds they all have one thing in common: they are at their best solving complex problems. Their insight into global events, market shifts and pricing ensure we are trading in the right place, at the right time.

 Business Support - Around the world, IMC’s business support teams are essential for sustaining our success. In our dynamic environment, we have many exciting challenges and multidisciplinary opportunities to shape our operations and make a real impact.

 OUR CULTURE
 Our employees are our greatest asset so we give them lots of responsibility and the support they need to make a difference. Our flat structure fosters a culture of openness and collaboration, encouraging the sharing of ideas and knowledge. It makes no difference if you have been with us for three days or three years, the best idea wins.

 While we work hard, we also have a lot of fun; whether solving complex challenges or in team building, leisure and sporting activities. IMC also enables its employees to contribute towards a better society through our foundation.

 As a data engineer at IMC, you’ll build and administer data workflows in an evolving, modern big data-based environment.

 You’ll also:

 Develop and extend in-house data toolkits based in Python and Java.
 Build data pipelines using common big data tools: Hadoop, Kafka, Spark, AWS.
 Consult with traders and developers on data solutions: assist in identifying solutions which match their problem space and harmonize with our internal data platform.
 Improve the performance of financial analytics platforms built around the big data ecosystem.


 WHAT MAKES IT FUN?

 IMC is on the cutting edge of financial applications of big data, processing terabytes of data daily for mission critical trading systems.
 We operate at the bleeding edge of technology. If something new can bring an advantage we will adopt and incorporate the new technology.
 The landscape is always changing, creating new and exciting challenges. What we focus on today is very different from what we focused on two years ago.
 We really believe in sharing knowledge and technology between the different offices. Much of our technology stack is shared globally between our offices, and we provide opportunities to travel between the regions both for personal growth and to assist where it has the biggest impact.
 Working at IMC is a great way to gain exposure to and learn about financial markets and technology. We know from experience that a lot of people really enjoy learning about a field beyond their immediate area of expertise, it’s one of the things that makes this job more interesting than others.
 We employ a broad range of people with varying backgrounds. What they have in common is their superior technical expertise, their extraordinary smarts and their collaborative approach.


 WHO YOU ARE:

 3+ years of experience working with Hadoop, Spark, and SQL
 2+ years of experience developing streaming data applications using Kafka
 Strong Java, SQL, and Python development skills
 Experience with common data-science toolkits, especially python-based
 Strong statistical analysis skills
 Demonstrated ability to troubleshoot and conduct root-cause analysis
 Unix scripting experience (bash, tcsh, zsh, python, etc)
 Experience with DevOps tools such as TeamCity, Gerrit, JIRA
 Experience with running code in containerized environments is a plus, especially Docker and Kubernetes
 User-focused: driven to deliver a usable product to users, rather than by technology itself

 OUR HIRING PROCESS
 To set you up for success, you can find our hiring process including tips on applying and interviewing with us on our website. Now it’s up to you! Apply today to start an amazing journey with IMC."
Staff Software Engineer - Data Platform,ServiceNow,"Chicago, IL 60607 (West Town area)",Posted 1 day ago,,https://www.indeed.com/rc/clk?jk=76a8284cd48daba0&fccid=7442885bc0fa7c14&vjs=3,"Company Description
 At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
 Job Description
 *Flexible in-office*
 Team:
 As a Staff Data Platform Software Engineer, you will have the opportunity to become a key member of the Cloud Platform Persistence group. The platform persistence group has teams that provide storage API for higher layer applications, build our Time Series capability and/or work to scale our application platforms. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system.
 Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
 What you’ll do and need to know:

 You’ll work toward managing our explosive data growth and ensuring our systems remain available and highly responsive.
 Developing platform technologies at scale.
 Work with relational database developing on, troubleshooting, and optimizing performance.

 To be successful:

 Having aptitude for learning new technologies quickly.
 Demonstrated success completing complex projects, on time.
 Experience with troubleshooting difficult production issues e.g., memory leaks, concurrency issues, locking issues, network problems, intermittent failures etc. across the stack.

 Nice to have:

 Passionate database technologies
 Familiarity with Unix shell
 Knowledge of DevOps environment


 Qualifications


6+ years of software development experience
Experience with core Java development
Advanced-Expert level understanding of best practices for object-oriented and modularized software. Emphasis on Java
Advanced-Expert level of backend platform development
Knowledge and/or experience with relational databases: Oracle, MySQL, MariaDB, MS SQLServer


Additional Information
 ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
 At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
 If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
 For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
 Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
 From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
 Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow."
Associate Data Engineer,HUB International,"Chicago, IL 60684 (Near West Side area)",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=6b03c70eb22873d3&fccid=facab5dee1aa0a96&vjs=3,"Responsibilities:


Intermediate knowledge in SQL, ETL architecture, data modeling, data architecture and BI architecture
Develop and support data model development including architecting table structure, building ETL process, documentation, and long-term preparedness
Analyze, develop, implement, and maintain technical solutions in Azure using data warehouse technologies, including Azure Data Factory, Azure Synapse (aka Azure Data Warehouse), Azure Synapse Analytics, Azure SQL DB, and Azure Power BI Premium
Develop cross validation rules to ensure data accuracy
Meet business requirements of the projects as new data sources are added
Provide production support for existing data pipelines and models
Document steps needed to migrate database objects between various environments including Development, UAT, Staging, and Production
Provide regular project updates to shared team resources and management as needed
Communicate issues, risks, and concerns proactively to management and engage colleagues while working in a hybrid Agile/Scrum process
Document pipelines thoroughly to allow peers to assist with support as needed

Qualifications:


A minimum of 2 + years' experience in progressive data engineering roles
Intermediate knowledge of SQL, PowerShell, DAX, M, and Data Analysis
Bachelor's degree in computer science or related field and five plus years’ experience in information technology or equivalent progressive experience with data engineering and data warehouse technologies with a focus on the Azure platform in the past 2 years to present
Experience with Azure using data warehouse technologies is an advantage, including Azure Data Factory, Azure Synapse (aka Azure Data Warehouse), Azure Synapse Analytics, Azure SQL DB, Azure Logic Apps, and Azure Power BI Premium
Knowledge of T-SQL, relational database technologies and related information technology
Experience in the Kimball method of database design and OLAP technology
Ability to function under close deadlines with minimal supervision and under potentially stressful situations
Good oral and written communication skills; ability to explain complex solutions to non-technical business, process, and solution owner-partners internally, along with corporate executives, directors, managers, staff, and contractors

Preferred skills:


Microsoft Certified Professional in the Azure fundamentals track is strongly preferred
Experience in building Power BI datasets and tabular models, would be strongly preferred
 Department Information Technology 


Required Experience: 2-5 years of relevant experience 


Required Travel: Negligible 


Required Education: Bachelor's degree (4-year degree) 

 HUB International Limited is an equal opportunity and affirmative action employer that does not discriminate on the basis of race/ethnicity, national origin, religion, age, color, sex, sexual orientation, gender identity, disability or veteran's status, or any other characteristic protected by local, state or federal laws, rules or regulations. The EEO is the Law poster and its supplement is available here athttp://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm. 

 EEOAA Policy 

 E-Verify Program 

 We endeavor to make this website accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact the US Recruiting Team toll-free at (844) 300-9193 orUSRecruiting@hubinternational.com. This contact information is for accommodation requests only; do not use this contact information to inquire about the status of applications. 

 Hi, we’re HUB. 

 In a rapidly changing world, we advise businesses and individuals on how to prepare for the unexpected. 

 When you partner with us, you're at the center of a vast network of experts who will help you reach your goals through risk services, claims management, and compliance support. 

 And this gives you the peace of mind that what matters most to you will be protected — through unrelenting advocacy and tailored insurance solutions that put you in control. 

 About HUB International 

 Headquartered in Chicago, Illinois, HUB International Limited (HUB) is a leading full-service global insurance broker providing property and casualty, life and health, employee benefits, investment and risk management products and services. From offices located throughout North America, HUB’s vast network of specialists provides peace of mind on what matters most by protecting clients through unrelenting advocacy and tailored insurance solutions. For more information, please visit hubinternational.com."
Lead Engineer - Data Ops,United Airlines,"Chicago, IL",Posted 27 days ago,,https://www.indeed.com/rc/clk?jk=19e46b43a9895215&fccid=e69f69636a9997cd&vjs=3,"Description

 There’s never been a more exciting time to join United Airlines. We’re on a path towards becoming the best airline in the history of aviation. Our shared purpose – Connecting People, Uniting the World – is about more than getting people from one place to another. It also means that as a global company that operates in hundreds of locations around the world with millions of customers and tens of thousands of employees, we have a unique responsibility to uplift and provide opportunities in the places where we work, live and fly, and we can only do that with a truly diverse and inclusive workforce. And we’re growing – in the years ahead, we’ll hire tens of thousands of people across every area of the airline. Our careers include a competitive benefits package aimed at keeping you happy, healthy and well-traveled. From employee-run ""Business Resource Group"" communities to world-class benefits like parental leave, 401k and privileges like space available travel, United is truly a one-of-a-kind place to work. Are you ready to travel the world?
 We believe that inclusion propels innovation and is the foundation of all that we do. United's Digital Technology team spans the globe and is made up of diverse individuals all working together with cutting-edge technology to build the best airline in the history of aviation. Our team designs, develops and maintains massively scaling technology solutions brought to life with innovative architectures, data analytics, and digital solutions.
 Key Responsibilities:
Overview
 United Airlines is seeking dedicated people to join the Data Engineering team. The organization is responsible for driving data driven insights & innovation to enable the Data Engineering and Machine Learning needs for commercial and operational projects with a digital focus. This role will frequently collaborate with business partners, data scientists and ML engineers. This role will design and enable key subsystems of the Data Platform, optimize operational critical metrics, and establish processes and best practices. As part of the platform team, this role will work in innovative cloud technologies from AWS and other ecosystems, including but not limited to Airflow, OpenTelemetry, OpenLineage, Marquez, Great Expectations, and others.
 Responsibilities

Partner with development teams and other department leaders/stakeholders to provide innovative technical solutions that enable business capabilities.
Participate and lead in design and development of innovative batch and streaming data applications using AWS technologies. Support large scale data pipelines in a distributed and scalable environment. Enable and optimize production AWS environment for data infrastructure and frameworks.
Set up containers and Serverless platform with cloud infrastructure.
Provide the team technical direction and approach to be undertaken and guide them in resolution of queries/issues.

United values diverse experiences, perspectives, and we encourage everyone who meets the minimum qualifications to apply. While having the “desired” qualifications make for a stronger candidate, we encourage applicants who may not feel they check ALL of those boxes! We are always looking for individuals who will bring something new to the table!

 Qualifications

What’s needed to succeed (Minimum Qualifications):

Bachelor’s degree and 8+ years of professional experience
4+ years of professional experience managing infrastructure and data pipelines using Cloud Formation, Terraform, PySpark, Airflow, or similar technologies
2+ years of experience in leading a team that engineers, architects, or support solutions on AWS
Working knowledge of common AWS technologies – EC2, S3, IAM, Lambda, Glue, SNS, others
General awareness of other AWS technologies
Working knowledge with CI/CD tools, SQL, Python, Spark, Version control system, JIRA.
Hands on experience with any object-oriented programming language
Must be legally authorized to work in the United States for any employer without sponsorship.

What will help you propel from the pack (Preferred Qualifications):

AWS Certification – Solutions Architect, DevOps Engineer or similar
Experience with Data Quality tools – Great Expectations, Deequ, or similar
Excellent knowledge and experience in Linux operating system or Windows



 United Airlines is an equal opportunity employer. United Airlines recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, gender identity, sexual orientation, physical ability, age, veteran status and other protected status as required by applicable law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions. Please contact JobAccommodations@united.com to request accommodation.

 Equal Opportunity Employer - Minorities/Women/Veterans/Disabled/LGBT"
Sr. Data Engineer (REMOTE),The Hartford,"Remote in Chicago, IL",Posted 20 days ago,,https://www.indeed.com/rc/clk?jk=a003ff7d5f58dcb2&fccid=25d3835187829237&vjs=3,"You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.
 


   The Hartford is seeking a Senior Data Engineer to join the Actuarial Technology and Innovation team to design, develop, and implement modern and sustainable data assets to fuel machine learning and artificial intelligence solutions across a wide range of strategic initiatives.
 


   The Actuarial Technology and Innovation team is a dynamic mix of Actuarial and Data Science professionals utilizing statistical modeling, machine learning, and advanced data engineering techniques to enhance core Actuarial processes. As a member of the LOB Engineering pillar, you will work directly with our Actuarial partners in building & designing tailor-fit data pipelines & processes. We are a forward-focused organization that fosters collaboration, encourages creative design, and offers abundant opportunities for visibility, allowing candidates to shape innovative solutions and showcase their talents to a wide audience.
 


   As a Senior Data Engineer, you will be at the forefront of driving impactful solutions throughout the entire software development lifecycle, ensuring reliable data delivery. Our team's culture is deeply rooted in embracing emerging technologies and empowering you to select the optimal tools for each unique project, so curiosity and adaptability are highly valued. Strong candidates will also demonstrate a solid foundation in data management, software engineering, and process automation along with an enthusiasm for delivering efficient solutions to partners.
 


   Responsibilities:
 

 Design and develop high quality, scalable software modules for next generation analytics solution suite


 Prototype high impact innovations, catering to changing business needs, by leveraging new technologies
 Consult with cross-functional stakeholders in the analysis of short and long-range business requirements and recommend innovations which anticipate the future impact of changing business needs
 Formulate logical statements of business problems and devises, tests and implements efficient, cost-effective application program solutions
 Identify and validate internal and external data sources for availability and quality. Work with SMEs to describe and understand data lineage and suitability for a use case
 Create data assets and build data pipelines that align to modern software development principles for further analytical consumption. Perform data analysis to ensure quality of data assets.


 Develop code that enables real-time modeling solutions to be ingested into front-end systems
 Produce code artifacts and documentation using GitHub for reproducible results and hand-off to other data science teams



   Minimum Qualifications:
 

 3+ years of relevant experience recommended
 Bachelor’s degree in Computer Science, Engineering, IT, Management Information Systems, or a related discipline


 Proficiency in SQL and R or Python
 Proficiency in ingesting data from a variety of structures including relational databases, Hadoop/Spark, cloud data sources, XML, JSON
 Proficiency in ETL concerning metadata management and data validation


 Proficiency in Unix and Git
 Interest & willingness to deeply understand Insurance & Actuarial business
 Able to communicate effectively with both technical and non-technical teams
 Able to translate complex technical topics into business solutions and strategies as well as turn business requirements into a technical solution
 Experience with leading project execution and driving change to core business processes through the innovative use of quantitative techniques



   Preferred Skills and Experience:
 

 Experience with Machine Learning, Statistical Modeling, or Actuarial Science
 Experience with agile software development
 AWS Certification or experience with AWS Services (S3, EMR, etc.)
 Proficiency in Automation tools (Airflow, Cron, Autosys, etc.)
 Experience with Cloud data warehouses, automation, and data pipelines
 Experience with containerized computing (Docker, Kubernetes, etc.)
 Experience building CICD pipelines or IAC (Infrastructure as Code)



   Compensation
 

   The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
 
 $110,560 - $165,840
 

   Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age"
Software Development Engineer II - Data Pipelines,Groupon,"Chicago, IL 60654 (Goose Island area)",Posted 16 days ago,"$89,600 - $140,800 a year",https://www.indeed.com/rc/clk?jk=0777171db85c4886&fccid=863ad2cc91c92c82&vjs=3,"Can data really help local businesses around the world thrive? 
Are you ready to test your skills using massive amounts of information to make critical business decisions? 
Groupon is an experiences marketplace that brings people more ways to get the most out of their city or wherever they may be. By enabling real-time mobile commerce across local businesses, live events, and travel destinations, Groupon helps people find and discover experiences––big and small, new and familiar––that make for a full, fun, and rewarding life. Groupon helps local businesses grow and strengthen customer relationships––resulting in strong, vibrant communities. With employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking, and celebrates success. Our culture encourages employees to embrace change, adapt to new circumstances, and find creative solutions to the challenges we face. Does that sound like a great way to grow your career? Let’s get into the details: 
The Data Engineering team at Groupon is at the heart of all things “data”, working on designing and building the next-generation data pipelines for data-science/machine learning community users. Our mission is to empower data analysts & data-scientists across all business units to make better business decisions. This role offers a unique combination of skills in computer science (distributed systems, big data), cloud, scalable, and high-performance production systems. 
You’ll spend time on the following: 

Design, and implement the data pipelines providing access to large datasets and transforming power for data across the org 
Write complex but efficient code to transform curated data into business questions oriented datasets and data visualizations. 
Work with big data and distributed systems using technologies such as Spark, AWS/GCP, and Python. 
Actively contribute to the adoption of strong software architecture, development best practices, and new technologies. We are always improving the process of building software; we need you to help contribute. 
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using open sources and GCP big data technologies 
Explore and learn the latest GCP technologies to provide new capabilities and increase efficiency 
Collaborate with Business Users, Infra Engineers, and Data Scientists to recognize and help adopt best practices in data gathering and transforming big data 
Work with the team to discuss the technical design and development needs. 

We’re excited about you if you have: 

Bachelor’s degree in computer science, mathematics, or a related technical field 
3+ years of relevant employment experience in data engineering or a related field 
At least 2 years of SPARK development experience 
At least 1 year of experience with Airflow, NiFi, or Azkaban 
A Clear understanding of testing methodologies and AWS/GCP cloud Best Practices 
Mastery of big data technologies (e.g. Hadoop, Hive, Spark ) 
Excellence in technical communication and experience working directly with stakeholders 
Demonstrated ability to coordinate projects across functional teams, including engineering and product management 
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations 

We value engineers who are: 

Customer-focused: We believe that doing what’s right for the customer is ultimately what will drive our business forward. 
Obsessed with Quality: Your Production code Just Works & scales linearly 
Team players. You believe that more can be achieved together. You listen to feedback and also provide supportive feedback to help others grow/improve. 
Fast learners: We are willing to disrupt our existing business to trial new products and solutions. You love learning how to use new technologies and then rapidly apply them to new problems. 
Pragmatic: We do things quickly to learn what our customers desire. You know when it’s appropriate to take shortcuts that don’t sacrifice quality or maintainability. 
Owners: Engineers at Groupon know how to positively impact the business. 


Groupon’s purpose is to build strong communities through thriving small businesses. To learn more about the world’s largest local ecommerce marketplace, click here for the latest Groupon news. Plus, be sure to check out the values that shape our culture, guide our strategy and make our company a great place to work. And just don’t take our word for it. Hear from real Groupon team members, learn more about our inclusive employee groups, and check out our benefits. If all of this sounds like something that’s a great fit for you, then click apply and let’s see where this takes us.
 Groupon is an Equal Opportunity Employer
 Qualifications for employment, promotion, and other terms and conditions of employment are based upon the ability to perform the job. Equal-employment opportunities are provided to all applicants and employees without regard to race, creed, religion, color, age, national origin, sex, disability, medical condition, sexual orientation, gender identity or expression, genetic information, ancestry, marital status, military discharge status (excluding dishonorable discharge), veteran status, citizenship status, or other legally protected status. We are all responsible for maintaining this policy. Groupon is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may email us at hraccommodations at groupon.com. If you have concerns related to Groupon’s equal employment opportunities, you may contact Groupon’s Ethics Reporting Service Ethicspoint."
Senior Associate Data Engineer,Discover Financial Services,"Riverwoods, IL 60015",,"$70,000 - $118,400 a year",https://www.indeed.com/rc/clk?jk=309b1ad903329ebb&fccid=6ce7e0d9f67a9961&vjs=3,"Discover. A brighter future. 
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine. 

 Come build your future, while being the reason millions of people find a brighter financial future with Discover. 


Job Description:
 The Senior Associate Data Engineer is responsible for designing, developing, maintaining , and testing data solutions for the product using the enterprise framework. This role will apply learned software delivery capabilities and have the desire to learn higher levels of craftmanship. Senior Associate Data Engineers contribute opinions to design decisions and actively participate in agile ceremonies. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management. 

 Responsibilities 

 Independently executes a variety of data integration solutions, recognizes data related patterns, and solicits advice on potential approaches 

 Contributes opinions to design decisions and understands design tradeoffs 

 Develops skills in data warehouse tools, Cloud, agile and other technologies involved in data integration 


Demonstrates and applies knowledge of:
 Data Integration concepts and tools 

 DW Design concepts and Metadata documentation 

 Data Profiling tools 

 Data Security 

 Data Quality 

 Regularly contributes to team agile ceremonies and helps new engineers with onboarding 

 Troubleshoots production issues and defects 

 Identifies and executes test scenarios and shares test results 

 Participates in the on-call rotation for support 

 Minimum Qualifications 


At a minimum, here’s what we need from you:
 Bachelor's Degree in Computer Science or related field 

 1 + years of experience in Data Platform Administration/Engineering 


Internal applicants only: technical proficiency rating of advanced beginner on the Dreyfus engineering scale 

 Preferred Qualifications 


If we had our say, we’d also look for:
 Experience in supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack) 

 ETL/ELT Tools ( AbInitio , DataStage, Informatica) 

 Experience working with relational or no-SQL databases, Cloud Tools 

 Other programming languages (Unix scripting, Python, etc.) 

 Knowledge of cloud platforms (AWS, GCP, Azure) 

 Basic knowledge of DevOps CI/CD framework, Open-Source concepts, key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs 

 External applicants will be required to perform a technical interview. 

 #LI-CM 


Compensation: The base pay for this position generally ranges between $70,000.00 to $118,400.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position. 


Benefits:
 We also offer a range of benefits and programs based on eligibility. These benefits include: 

 Paid Parental Leave 

 Paid Time Off 

 401(k) Plan 

 Medical, Dental, Vision, & Health Savings Account 

 STD, Life, LTD and AD&D 

 Recognition Program 

 Education Assistance 

 Commuter Benefits 

 Family Support Programs 

 Employee Stock Purchase Plan 

 Learn more at MyDiscoverBenefits.com . 

 What are you waiting for? Apply today! 

 All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management. 

 Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)"
Senior Data Engineer,S&P Global,"Remote in Chicago, IL 60602",,"$70,300 - $139,800 a year",https://www.indeed.com/rc/clk?jk=277a4ea956475c53&fccid=b716e44d2c6283e7&vjs=3,"The Role: Senior Data Engineer 


The Team: As a member of the Data Operations team, you will help modernize the extensive data domain of the Issuer Solutions business. 


The Impact: As we redesign and reimagine our client-facing and internal tools, data quality and consistency across multiple tools and platforms will be a key factor in our success, and the Data Engineering team is tasked with ensuring that all data consumers, from developers to business analysts to clients, have tools to access the data they need in the format they need it. 


What’s in it for you:
 Designing and implementing data-ingestion and data-publishing tools for diverse datasets. 
Implementing and maintaining data-monitoring and data-cataloguing tools. 
Implementing and maintaining process-management and data-movement tools for ETL’s. 
Offering guidance and best practices to scrum teams who work with data. 
Evaluating and implementing new data management technology with the goal of continually improving team efficiency and data quality. 
Providing support and guidance for business analysts using data analysis tools such as Alteryx and PowerBI. 


Responsibilities:
 Minimum of 3+ years experience as a software engineer 
Experience as a Data Engineer in a production environment 
Focus on ETL’s, data monitoring, data engineering, etc. 
Python, C#, Docker, MS SQL Server, PostgreSQL 
Experience with AWS and/or Azure DevOps 

AWS tech: Aurora DB, Glue, Lambda 
Alteryx Server 
Infrastructure as code using Terraform/CloudFormation 
Solid understanding of containers and orchestration tools (Docker, CI/CD, etc.) 
AirFlow, DataHub, NiFi and other data-management and process-management tools a plus 
Experience with BI and analytical tools such as PowerBI and Alteryx 

 Flexible Working (optional) 
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. 

 Return to Work 
Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. 


Grade/Level ( relevant for internal applicants only ): 10 


The Location: Florida, Georgia, New York, Virginia, Connecticut, Ohio, Delaware 


Compensation and Benefits Information:
 S&P Global states that the anticipated base salary range for this position is $70,300 - $139,800. Base salary ranges may vary by geographic location. 
In addition to base compensation, this role is eligible for an annual incentive bonus plan. 

 This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit Our Benefits (spgbenefits.com) . 


About Company Statement:
 S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. 

 S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work. 

 ----------------------------------------------------------- 

 Equal Opportunity Employer 
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. 

 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. 


US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 

 ----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group) 


Job ID: 288863 

Posted On: 2023-06-22 

Location: Virtual, North Carolina, United States"
Financial Data Engineer,Hull Tactical Asset Allocation,"Chicago, IL",,,https://www.indeed.com/rc/clk?jk=78ba0c083030713b&fccid=5168e49fe820dfb1&vjs=3,"Hull Tactical is seeking a data manager to join our growing equity options team to build and manage daily data processes. The mission is to curate and analyze fundamental and sentiment data (news, social, Reddit, etc.) to anticipate market movements in US listed companies including “meme” stocks.
 Practical experience managing a “fundamental data” store is necessary for a candidate to be successful.

“Fundamental data” means information about individual US stocks and options that is updated at most daily. Examples are: 
   
Corporate actions, such as dividends and splits
Symbol name changes
Industry sector mapping and changes
Earnings dates

Fundamental data is mostly sourced from vendors such as FactSet, Bloomberg, Thomson Reuters or EOD Historical Data
Some of the fundamental data is derived in-house from intraday data including trading volume, open interest, and aggregated tick data



 Position Location: Chicago, IL
 Required Skills

Experience with fundamental data from vendors such as FactSet, Bloomberg, Thomson Reuters, EOD Historical Data
Experience with basic relational modeling and SQL
Practical experience working with MySQL, PostgreSQL or similar databases
Experience working in a Linux environment 
   
Basic Linux command line skills and familiarity with simple Bash scripts
Python scripting to build and maintain data ingestion pipelines
Experience with Pandas and with Python database scripting

Managing daily recurring data processing jobs with tools such as cron, rundeck, etc.

Desired Skills

Python programming
Experience using git, feature branches and automated testing
Experience with generating data for reporting tools using Python
Prior experience working on a fundamental data team
Ability to identify and correct performance bottlenecks
Bachelor’s or advanced degree in computer science, information technology or related field

WHAT WE OFFER

Competitive financial rewards with further upside tied individual, team, and firm performance
Employee benefits that include exceptional insurance and 401K matching program
Friendly and collegial work environment
Opportunity to learn from successful industry experts



 Please send your CV or Resume to resume@hulltactical.com in PDF format only. Non-PDF files will be rejected!"
Senior Data Engineer,bp,"Hybrid remote in Chicago, IL",,,https://www.indeed.com/rc/clk?jk=95822a3fdabc31d3&fccid=03cacc905f5db444&vjs=3,"Location
   

     United States of America - Illinois - Chicago
   



     Travel required
   

     Negligible travel should be expected with this role
   





     Job category
   

     Digital & technology
   



     Relocation available
   

     This role is eligible for relocation within country
   





     Job type
   

     Professionals
   



     Job code
   

     RQ041200
   





     Experience level
   

     Intermediate
   





Job summary

Entity: Innovation & Engineering
   Job Family Group: IT&S Group
   Job Summary: Data and analytics will play a central role in helping accomplish our net-zero ambition. We are looking for Senior Data Engineers to join us on this amazing journey. Specifically, you will be part of the data & analytics center of excellence (CoE) working on a wide range of data infrastructure and data engineering projects across bp. In addition, the CoE is responsible for setting the data & analytics strategy, best practices and standards across the company and is building learning and development paths for fellow bp employees and data & analytics discipline members.
   Job Description: 
Key Accountabilities 


    Part of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners. 
   

    Architects, designs, implements and maintains reliable and scalable data infrastructure. 
   

    Writes, deploys and maintains software to build, integrate, manage, maintain, and quality-assure data at bp. 
   

    Adheres to and advocates for software engineering best practices (e.g. technical design, technical design review, unit testing, monitoring & alerting, checking in code, code review, documentation), 
   

    Responsible for deploying secure and well-tested software that meets privacy and compliance requirements; develops, maintains and improves CI / CD pipeline, 
   

    Responsible for service reliability and following site-reliability engineering best practices: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments. 
   

    Actively contributes to improve developer velocity. 
   

    Mentors others
   

 Essential Education: 
Bachelor or master’s degree in computer science, Engineering, Informatics, Information Systems or in another quantitative fields
 Essential Experience and Job Requirements: 


    Demonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, Py-spark, C++)
   

     5-7 years relevant experience in data engineering
   

     Deep and hands-on experience (typically 5+ years) designing, planning, productionizing, maintaining and documenting reliable and scalable data infrastructure and data products in complex environments 
   

    Experience designing and implementing large-scale distributed data pipelines on AWS/Azure cloud (preferably AWS) 
   

    Advanced data modeling and dimensional modeling knowledge 
   

    Advanced SQL knowledge 
   

    Deep knowledge and hands-on experience in technologies across all data lifecycle stages 
   

    Prior Software Engineering experience a big plus
   


 Desirable Criteria 


    Strong stakeholder management and ability to lead large organizations through influence 
   

    Continuous learning and improvement mindset 
   

    No prior experience in the energy industry required
   

 Travel Requirement Negligible travel should be expected with this role
   Relocation Assistance: This role is eligible for relocation within country
   Remote Type: This position is a hybrid of office/remote working
   Skills:
 Legal Disclaimer:

 We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. Individuals with disabilities may request a reasonable accommodation related to bp’s recruiting process (e.g., accessing the job application, completing required assessments, participating in telephone screenings or interviews, etc.). If you would like to request an accommodation related to the recruitment process, please contact us to request accommodations.

 If you are selected for a position and depending upon your role, your employment may be contingent upon adherence to local policy. This may include pre-placement drug screening, medical review of physical fitness for the role, and background checks."
Data Engineer/ ETL Developer,SDH Systems,"Chicago, IL 60604 (Loop area)",,"$81,931 a year",https://www.indeed.com/rc/clk?jk=06c68b2321214d33&fccid=4494b8cfea28ee1e&vjs=3,"Location: Chicago, Illinois 60604 Duration: 3 Years Work Schedule: Full Time, 40 Hours/Week Salary: $81,931.00/Annum + Company Standard Benefits
 Job duties:

Create and enhance datasolutions enabling seamless delivery of data and is responsible for collecting, parsing, managing and analyzing large sets of data across different domains for analysis. 
   
Works with various departments in collecting requirements and creates tables to load data based on business requirements. Manages data in Development, QA and PRODUCTION environments ensuring seamless delivery to the customers.





Use different Data warehousing concepts to build a Data warehouse for internal departments of the organization. 
   
Applies Data warehousing concepts such as star and snowflake schema approach while creating tables and maintaining data to ensure data integrity.





Designs and develops data pipelines, data ingestion and ETL processes that are scalable, repeatable and secure for stakeholder needs. 
   
Designs ETL Processes using Informatica tool to extract data from heterogeneous sources and transforms data using complex logic as per business needs and ingests it into our warehouse.





Build Data architecture to support data management strategies to support business intelligence efforts for various stakeholders. 
   
Ensures data stored in the warehouse can be used to create dynamic Business Intelligence reports for complex analysis helping in making business driven decisions.





Leads the design of the logical datamodel and implements the physical database structure and constructs and implements operational data stores and data 
   
Manages access to confidential data by creating database views and data marts for customers and ensures confidential data is shared using company policies.





Support deployed dataapplications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution Data Pipeline Management. 
   
Works with other team members in analyzing the data and advises on how to improve data quality and provide cleaner solutions to business stakeholders.





Develops real-time and batch ETL dataprocesses aligned with business needs, manages and augments data pipeline from raw OLTP databases to data solution structures. 
   
Builds complex ETL process using Informatica to transform the data as per business needs and automated the process capturing real time data and maintaining history for complex analysis.





Documents data flow diagrams, security access, data quality and data availability across all business systems. 
   
Documents all processes of every project using JIRA for reference by any other member on the team and ensures it is always secure.
 

Minimum Education Requirement: This position requires minimum of bachelor’s degree in computer science, computer information systems, information technology, or a combination of education and experience equating to the U.S. equivalent of a Bachelor’s degree in one of the aforementioned subjects."
Data Center Engineer,SDI Presence,"Chicago, IL 60601 (The Loop area)",,,https://www.indeed.com/rc/clk?jk=49336e94c7aab797&fccid=cf4322fd4959e8a2&vjs=3,"Company
 SDI Presence LLC is an IT consultancy and managed services provider (MSP) that leverages its strong team presence to advance our clients to a secure digital enterprise. With a 25-year corporate resume, SDI delivers strategic managed services, IT consulting, and hybrid multicloud infrastructure solutions to optimize our clients’ technology environments. SDI is NMSDC-certified, with a portfolio of clients that includes some of the nation’s largest airports, utilities, commercial real estate portfolios, and government agencies. SDI is backed by Abry Partners, a Boston-based sector-focused private equity firm with $5B under management and more than 30 years of experience in the technology market. Visit us at SDIPRESENCE.COM and connect with us on TWITTER and LINKEDIN.

 Summary
 The Data Center Architect is responsible for the design, architecture, and implementation of technology solutions to support the enterprise infrastructure of an organization. They ensure that all systems are working at optimal levels and support the development of new technologies and system requirements. Infrastructure Architects generally lead and direct a team and report directly to top management.

 Analyze existing systems to ensure they offer adequate security and are effectively meeting the needs of the organization. 
Analyze business requirements to identify where they can integrate new hardware, operating systems, or connectivity solutions and document solution designs, including logical and physical designs
 Serve as the primary point person for the technical solution design and delivery of infrastructure platform solutions related to cloud, server, network, storage, virtualization, data center, backups, application delivery, data protection, and access management

 Lead Design and Review of New Systems

 Lead the design and review processes for new systems
 Develop and document the proposed technical design for the integration and implementation of any new hardware or platform, working across the IT departments
 Create detailed plans for the integration of new systems architecture into existing infrastructure


 Requirements
 Infrastructure

 5+ years of experience in enterprise engineering
 Must have experience with LARGE Data centers and technology transformation projects
 Working knowledge of and management skills for the cloud, server, network, storage, virtualization, data center, backups, end-user devices, application delivery, data protection, backups, middleware, and access management
 Skills analyzing application dependency across multiple servers
 Strong technical understanding of migration of applications and servers to new technologies and environments
 Proven experience in migration Windows and Linux servers to Azure
 Proven experience with backup and migration tools: Commvault, ASR and PowerShell
 AWS migration experience a plus
 Microsoft Certified System Engineer (MCSE) certification preferred, not required
 Strong knowledge of Windows Server 2008 through Windows Server 2019 required
 Experience with Microsoft technologies: Server, Active Directory, Identity and Authentication, SSO/Federation, AD/Azure AD
 Knowledge of Linux operating systems
 Strong knowledge of virtualization technologies including Hyper-V and VMWare required

 General / Other

 Bachelors’ degree or an equivalent combination of education, training, and experience
 A strong leader and communicator
 Strong written and oral communication skills, and the ability to effectively communicate with technical and non-technical audiences
 Experience planning and developing support processes and adhering to best practices
 Ability to provide technical system solutions, determine overall design direction and provide hardware recommendations for complex technical issues
 Ability to quickly comprehend the functions and capabilities of new technologies

 Other Duties Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.
 Equal Opportunity Employer Statement
 SDI Presence is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws. 
This policy applies to all employment practices within our organization, including hiring, recruiting, promotion, termination, layoff, recall, leave of absence, compensation, benefits, training, and apprenticeship. SDI Presence makes hiring decisions based solely on qualifications, merit, and business needs at the time.
 Staffing Firms
 SDI Presence does not seek or accept unsolicited resumes or CVs from recruitment agencies. We are not responsible for, and will not pay, any fees, commissions, or any other payment related to unsolicited resumes or CVs except as required in a written contract between SDI Presence and the recruitment agency or party requesting payment of a fee."
Big Data Engineer,Epsilon,"Chicago, IL 60601 (Loop area)",,,https://www.indeed.com/rc/clk?jk=1564c7fdc7f1e531&fccid=beb2b679d6e2402e&vjs=3,"Job Description


Love cutting-edge tech? We do too.

 At Epsilon, we do more than collect and store data. We help some of the world's biggest brands discover real opportunities inside the data types, delimiters and decimals. For this opening, we're looking for an experienced 
 Big Data Engineer with extensive experience working with Spark or Scala in the big data ecosystem. 
 
 Our ideal candidate must be able to architect and lead teams, while also serving as a key contributor in delivering critical business features. On this team you will be a key contributor in troubleshooting complex production issues and delivering critical business features, making this a perfect role for those with a passion for big data technologies. 
 

What you'll do:


 Build and maintain data processing services
 Continuous improvement of our system, tests, and data quality indicators
 Influence our technical decisions
 Keep yourself informed and up-to-date with technologies
 Encourage the technical growth of your teammates
 Interface with analysts, data scientists, and engineers to enable data oriented solutions
 Build data expertise on subject matter and be able to speak to data warehouse constructs and data architecture.
 Our platform is ever evolving, but currently is a combination of Kafka, Flume, Spark, Scala, Java, Python, NoSQL (HBase, Cassandra and ScyllaDB), MPP RDBMS, Postgres, Hadoop, AWS, AirFlow, Docker and Kubernetes


 About you:


 Owns a problem to the end
 Proud to share in team's success
 Able to do your best work in a team setting and autonomously
 Wants to grow a career with a great company.


 What you'll bring:


 B.S. in Computer Science, Computer Engineering, or related field.
 At least five years of professional experience using Java, Scala, or Spark in project task's
 Ability to understand complex SQL and Python code is critical.
 Ability to troubleshoot production issues and solve for performance bottlenecks
 Expert level skills in data architecture (storage and usability)
 Ability to analyze data and identify business possibilities for better operational processes and business opportunities
 Excellent communication skills and ability to work with the internal analyst community
 Ability to thrive in a collaborative team environment
 You enjoy working with numerous programming languages, relational databases, and distributed systems.
 Internet/Digital Advertising ecosystem knowledge is a plus
 Kafka and Flume are a plus.


 Additional Information


When you're one of us, you get to run with the best. For decades, we've been helping marketers from the world's top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon's best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon has been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. Check out a few of these resources to learn more about what makes Epsilon so EPIC:
 

 Culture: https://www.epsilon.com/us/about-us/our-culture-epsilon
 DE&I: https://www.epsilon.com/us/about-us/diversity-equity-inclusion
 CSR: https://www.epsilon.com/us/about-us/corporate-social-responsibility
 Life at Epsilon: https://www.epsilon.com/us/about-us/epic-blog


 Great People Deserve Great Benefits

 We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.
 
 Epsilon is an Equal Opportunity Employer. Epsilon's policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories.
 
 Epsilon will provide accommodations to applicants needing accommodations to complete the application process.
 
 Applicants with criminal histories are welcome to apply.
 
 #LI-AM1
 
 REF184648E
 Company Description

 Epsilon is the leader in outcome-based marketing. We enable marketing that's built on proof, not promises. Through Epsilon PeopleCloud, the marketing platform for personalizing consumer journeys with performance transparency, Epsilon helps marketers anticipate, activate and prove measurable business outcomes. Powered by CORE ID®, the most accurate and stable identity management platform representing 200+ million people, Epsilon's award-winning data and technology is rooted in privacy by design and underpinned by powerful AI. With more than 50 years of experience in personalization and performance working with the world's top brands, agencies and publishers, Epsilon is a trusted partner leading CRM, digital media, loyalty and email programs. Positioned at the core of Publicis Groupe, Epsilon is a global company with over 8,500 employees in over 40 offices around the world.
 
 For more information, visit epsilon.com. Subscribe to us on YouTube at @EpsilonMktg."
Senior Software Engineer - Data Engineering,PayPal,"Chicago, IL",,,https://www.indeed.com/rc/clk?jk=f529dcf6c7ff39eb&fccid=978d9fd9799d55a8&vjs=3,"At PayPal (NASDAQ: PYPL), we believe that every person has the right to participate fully in the global economy. Our mission is to democratize financial services to ensure that everyone, regardless of background or economic standing, has access to affordable, convenient, and secure products and services to take control of their financial lives.
Job Description Summary: Your way to impact: Merchant reporting is crucial for our Merchants so that they can close their account books timely and accurately with complete payment data in core markets. We are looking for people who have a passion for developing massively scalable, distributed software systems that require high availability to our business. As a member on the Merchant Reporting and reconciliation team, you thrive in a fast-paced environment and enjoy driving innovation through rapid prototyping and iterative development. You will work directly with our Product Owners and Domain Technical Leads to create outstanding solutions and deliver incredible reporting products. You will be involved from ideation to rollout.
Job Description: 

  Your day to day:
  

Work with Product Managers and other business partners to identify opportunities for improvement
Analyze data based on product requirements
Create reports for internal teams and/or external clients
Use graphs, infographics and other methods to visualize data
Structure large data sets to find usable information
Work with a team of analysts and other associates to process information
Create presentations and reports based on recommendations and findings
Define validation queries when needed and how to identify discrepancies in the data as they arise
Write queries for runbooks that automate the discrepancy identification process
Implement the reporting data model
Deliver within schedule in an Agile software development using test-driven development methodologies.
Participate in development life cycle activities like design, coding, testing and production release.
Be proactive with identifying areas for improvement and innovation to improve development productivity



   What do you need to bring:
  

BS in EE/CS or equivalent work experience and successful completion of major projects for which you can show code examples.
3+ years of hands-on data/software engineering experience
Experience working with coding languages—preferably SQL, Java, Spark-SQL, Pyspark, Python
Experience working with SQL and noSQL DataBase
High proficiency in MS Excel, MS powerpoint, GIT, Apache Airflow
Have a passion for quality and writing clean and solid code that scales and performs well.
Strong desire to learn, push the envelope, and share knowledge with others.
Excellent analytical and time management skills
Teamwork skills with a problem-solving attitude




Our Benefits:
 At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.
 We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com 

Who We Are:
 To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx 

PayPal has remained at the forefront of the digital payment revolution for more than 20 years. By leveraging technology to make financial services and commerce more convenient, affordable, and secure, the PayPal platform is empowering more than 400 million consumers and merchants in more than 200 markets to join and thrive in the global economy. For more information, visit paypal.com.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.
 As part of PayPal’s commitment to employees’ health and safety, we have established in-office Covid-19 protocols and requirements, based on expert guidance. Depending on location, this might include a Covid-19 vaccination requirement for any employee whose role requires them to work onsite. Employees may request reasonable accommodation based on a medical condition or religious belief that prevents them from being vaccinated."
Consultant - Data Engineer,Insygnum,"Chicago, IL",,,https://www.indeed.com/rc/clk?jk=54707f4835fac495&fccid=ed94e1a293166c52&vjs=3,"Insygnum needs a Consultant - Data Engineer to help our clients for data analysis, data integration and data quality. Our Chicago-based team is small but growing fast and we need to complement our in-house experts who knows how to tame challenging data. This is a unique opportunity to not only work with cool technology, but also to create a new methodologies and techniques. You'll get in on the ground floor of a new company, help shape its future, and benefit directly from your work.
Why work here

  Joining insygnum now offers several unique opportunities 
  You will receive competitive salary, benefits, and stock options
You will be working on hard, interesting problems
You will help shape the culture of the company as we grow
You will have the opportunity to apply your skills in a meaningful way and have a real-world impact

Responsibilities
You'll help design a new system for capturing, storing, analyzing, and acting on performance, security, and network data. The ideal candidate will have a solid grasp of several different database and data warehousing technologies to help architect ETL for. Technologies to be used may include some combination of relational databases (PostgreSQL, Teradata, Aster, HANA), NoSQL, Hadoop, Object-based stores, and OLAP.

  Specific responsibilities include: 
  Help design an architecture for federated data stores and data fusion
Help design methods for storing data in a way that facilitates extremely fast data parsing and management
Implement ""glue code"" that connects middle tier components with backend components
Implement data management and analytics code utilizing data architecture (e.g. map reduce)
Collaborate with machine learning folks to determine how to analyze various data sets and set up methods for querying data stores
Collaborate with data architects to understand the applications we integrate with and the data they produce
Review requirements for new approaches to big data storage and analytics 
Design methods for caching, paging, and integrating real-time data with historical data stores

Desired Skills and Experience
Requirements

Development knowledge for integrating components and contributing to core code base - Java preferred
Solid understanding of database and data warehousing technologies
Knowledge of SQL as well as NoSQL queries, syntax, and technologies
Knowledge of big data requirements, applications, and technologies such as Hadoop
Knowledge of ETL methods and approaches including triggers, named views, temporary tables, etc.
Linux expertise

Bonus Points

Java is strongly preferred (e.g. for working with map reduce) but not ultimately a requirement if you excel in other areas
Strong SQL skills are highly desirable
OLAP experience
Experience with ETL tools like Informatica, Boomi, Pentaho, AbIntio, Datastage, etc.,"
Test Data Management Engineer,HCSC,"Hybrid remote in Chicago, IL",,,https://www.indeed.com/rc/clk?jk=3cc9d8521b9106df&fccid=430345d982138f73&vjs=3,"At HCSC, we consider our employees the cornerstone of our business and the foundation to our success. We enable employees to craft their career with curated development plans that set their learning path to a rewarding and fulfilling career. 

Come join us and be part of a purpose driven company who is invested in your future! 

Job Summary 

This position is responsible for demonstrating a capable understanding of Test Data Management related to data security, data masking, synthetic data creation and test data strategy planning; working with teams to provide test data; creating synthetic data, perform data conditioning, macro creations for data generation, data masking, provisioning for data and mask data as needed; multi-tasking in an environment of changing priorities. 

This position is responsible for demonstrating a capable understanding of Test Data Management related to data security, data masking, synthetic data creation and test data strategy planning; working with teams to provide test data; creating synthetic data, perform data conditioning, macro creations for data generation, data masking, provisioning for data and mask data as needed; multi-tasking in an environment of changing priorities. Required Job Qualifications: 

Bachelor's degree required or combination of education and 2 years’ experience OR 4 years Information Technology experience 
Preferred Job Qualifications: 

Data Engineering Certification 
Experience with Selenium Automation – novice 
Python experience – capable 
Experience with SQL database queries and programming – capable 
Understanding of data masking concepts, with proven implementation experience. Familiarity with data quality, cleaning, and masking techniques -novice 
Ability to diagnose diverse technical issues in a complex enterprise environment – capable 
Organizational and time management skills, with the ability to manage workload and projects to navigate peaks, prioritize competing commitments, and complete assignments in accordance with established deadlines – capable 
Attention to detail, follow-through, and customer focused orientation – capable 
Analytical, decision making and problem-solving abilities, with demonstrated troubleshooting and debugging skills – capable 
Ability to work independently, as well as collaboratively in a team environment – capable 
Verbal and written communication, presentation, and interpersonal skills – capable 
TDM functions including Data provisioning, sub setting, profiling, Data mining 
Abilities with TDM masking tools 
Macro generation for synthetic data creation 
Scripting experience with Shell, Perl, .bat, VB Script, or any other scripting language experience 
#LI-HYBRID #LI-DR1 

Are you being referred to one of our roles? If so, ask your connection at HCSC about our Employee Referral process! 

HCSC Employment Statement: 
HCSC is committed to diversity in the workplace and to providing equal opportunity and affirmative action to employees and applicants. We are an Equal Opportunity Employment / Affirmative Action employer dedicated to workforce diversity and a drug-free and smoke-free workplace. Drug screening and background investigation are required, as allowed by law. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status."
Data Engineer,CloudRay Inc,"Chicago, IL",,,https://www.indeed.com/rc/clk?jk=e026e89e3ae1149a&fccid=2fc3c63516d3ee12&vjs=3,"Job Description 

 Sinai is seeking a Data Engineer to serve on the Data & Analytics Team. The primary responsibility of this role is to work with our other data engineers, business analysts, data architects, BI developers, and business stakeholders to produce meaningful information from our data warehouse. Produce datasets for consumption by BI developers; produce data extracts for integration with other systems. Validates code and data while providing analytical expertise. Work with DBA on database performance and database planning. 

 Knowledge, Skills, Abilities 



Advanced expertise with T-SQL coding, C#, and other programming languages
Advanced expertise with query development, stored procedures, triggers
Expertise with Microsoft SQL stack: SSRS, SSIS, SSAS
Expertise with Microsoft Visual Studio Professional and package creation
Strong proficiency with Microsoft PowerBI (on-site and cloud-based)
Knowledge of GitHub online
Knowledge of Microsoft Azure platform and components
Knowledge of data science tools
Excellent communication and organization skills
Excellent documentation skills
 Minimum Qualifications 



Bachelor's Degree in computer science or similar degree
5-10 years experience in the same or similar role
Healthcare industry preferred; other regulated industries
Experience with Epic, Meditech, or Allscripts preferred
Must be citizen or permanent resident -- no sponsorships
Chicagoland-based; no relocation assistance (may work remotely during transition phase)"
Data Engineer,Spectrum Communications & Consulting Inc.,"Hybrid remote in Chicago, IL",,,https://www.indeed.com/rc/clk?jk=55dadfebca251344&fccid=11aab4c86aeaacc1&vjs=3,"What do incubators and Spectrum have in common? Well, they’re great for growth, and even better for stability. As an innovative software development and digital marketing company pioneering the field of artificial intelligence, we can offer our newest Data Engineer the best of both words – a high energy, forward-thinking start-up culture, inside of a well-established, profitable, and stable structure . if you’re interested in getting your hands dirty and inciting change into a larger organization with a vision to change the world uses data today, then please read on.
 Responsibilities
Beyond working with state of the art technology you will have many different fantastic projects to work on as a Data Engineer at Spectrum. Here are just a few different responsibilities you can expect off the bat:

Design, build and maintain both new and existing data infrastructures using tools including (but not limited to) Microsoft SQL Server, Azure Tables, Azure Blobs, and Azure Cosmos
Determine the right database system for a provided data set
Drafting database/table schemas
Properly index tables when applicable to ensure query performance
Create data pipelines for transforming new datasets into consistent, reliable data systems that are usable across multiple platforms
Identify optimizations and improvements in existing data pipelines
Create solutions for data validation to ensure data integrity, accuracy, and consistency
Ensure data is readily available for analysis and development usage
Shifting existing big data pipelines
Come up with data validation solutions for both initial data imports as well as results
Audit the automation process to make sure there are no gaps, redundancies, or faults in the data pipeline that would cause damage to data integrity
Planning query efficient data store schemas with respect to the data requirements of our internal data warehouse
Communicate with data scientists and other software engineers to build proper data pipelines for efficient and cost-effective querying
Develop, construct, test, and maintain architectures with the help and feedback of software engineers
Determine and implement proper data schemas that align with Spectrum’s and Spectrum’s client’s business objectives
Recommend and implement ways to optimize data reliability, efficiency, and quality
Consult and suggest different technologies for our team to test and utilize together
Incorporate the business objectives of key stakeholders in the architecture of our data warehouse
Research new and interesting data acquisition opportunities

Some Characteristics That Define You
 We understand that as a Data Engineer for Spectrum, you have many different professional goals and personal interests. As such here are just a few different things that typically define our team members on the Data Science team:

Self-Starter. Building a data warehouse is no simple task. You will need to come in with a self-starter attitude to not only make this data engineering role what you want it to be, but make a stellar and efficient data warehouse while you’re at it.
Analytical. In order to solve problems and build innovative new digital marketing campaigns, it is essential that you know how to take an idea and analyze it from all of its angles.
Developer. In the ever changing world of artificial intelligence, it’s not enough just to build models. You bring to the table an eye for data patterns along with a knack for relational database engineering.
Patient. As a data engineer, you know that you work with extremely large data sets on a daily basis. As such we are looking for someone who is not only meticulous, but patient enough to sit and sift through that data in a thorough way.
Creative. Beyond just analyzing data sets, you are an explorer and a puzzle solver. Pulling insights out of your data and understanding how those insights can better shape our tools is something that you live to do.
Student. More so than most industries, the field of data science is always changing and evolving. As such, you are always looking to learn new things and gain new skills.

Required Skills and Experience
 On top of the many intangible skills you bring to the table, there are many skills that can help improve the efficiencies and success of your work at Spectrum. Here are a few of those required skills and experience that you will come in with as a Data Engineer on our team:

A bachelor’s degree/pursuing a bachelor’s degree in computer science, mathematics, statistics, information systems, or a related field
Experience with statistical modeling
1-3 years working experience with Python and/or SAS languages
1-3 years working experience with SQL databases and database querying languages
1-3 years working experience with C#/.NET
Familiarity with Microsoft Azure
Familiarity with Graph database structures
Experience with both RDBMS and TDMS
Experience with data mining and data cleaning
Experience with data visualization and reporting techniques
Written and verbal expression

Benefits
 As a Data Engineer at Spectrum there are a ton of fantastic perks and benefits that come along with your work. Here are just a few of the benefits you can expect when joining the Spectrum family:

Comprehensive medical & dental insurance
Retirement planning & company matching
Generous PTO, including sick days & holidays
Coworking space access for remote and hybrid work options
Year-round gym memberships
Paid continuing education
Hybrid work from Home , meetings a few times a month to strategize new projects 

About Us
 Our mission at Spectrum has always been the same— growth. Whether that be helping our customers find quality new business, developing and challenging our team members, or evolving our products and services with advancements in technology and best practices, we have always been looking towards bettering ourselves for the future. Now as we continue to grow, we find ourselves as not only the nation’s leading digital marketing and software provider for the home services industry, but an innovator and ground-shaker for the world of artificial intelligence as well. From marketing automation software powered by AI, to top notch digital marketing services via those same AI insights, we love what we do and are excited to continue to innovate for the future together. INDSPCI 
   Responsibilities

    Design, build and maintain both new and existing data infrastructures using tools including (but not limited to) Microsoft SQL Server, Azure Tables, Azure Blobs, and Azure Cosmos
  

   Determine the right database system for a provided data set
  

   Drafting database/table schemas
  

   Properly index tables when applicable to ensure query performance
  

   Create data pipelines for transforming new datasets into consistent, reliable data systems that are usable across multiple platforms
  

   Identify optimizations and improvements in existing data pipelines
  

   Create solutions for data validation to ensure data integrity, accuracy, and consistency
  

   Ensure data is readily available for analysis and development usage
  

   Shifting existing big data pipelines
  

   Come up with data validation solutions for both initial data imports as well as results
  

   Audit the automation process to make sure there are no gaps, redundancies, or faults in the data pipeline that would cause damage to data integrity
  
Beyond working with state of the art technology you will have many different fantastic projects to work on as a Data Engineer at Spectrum. Here are just a few different responsibilities you can expect off the bat:

Planning query efficient data store schemas with respect to the data requirements of our internal data warehouse
Communicate with data scientists and other software engineers to build proper data pipelines for efficient and cost-effective querying
Develop, construct, test, and maintain architectures with the help and feedback of software engineers
Determine and implement proper data schemas that align with Spectrum’s and Spectrum’s client’s business objectives
Recommend and implement ways to optimize data reliability, efficiency, and quality
Consult and suggest different technologies for our team to test and utilize together
Incorporate the business objectives of key stakeholders in the architecture of our data warehouse
Research new and interesting data acquisition opportunities

Some Characteristics That Define You
 We understand that as a Data Engineer for Spectrum, you have many different professional goals and personal interests. As such here are just a few different things that typically define our team members on the Data Science team:

Self-Starter. Building a data warehouse is no simple task. You will need to come in with a self-starter attitude to not only make this data engineering role what you want it to be, but make a stellar and efficient data warehouse while you’re at it.
Analytical. In order to solve problems and build innovative new digital marketing campaigns, it is essential that you know how to take an idea and analyze it from all of its angles.
Developer. In the ever changing world of artificial intelligence, it’s not enough just to build models. You bring to the table an eye for data patterns along with a knack for relational database engineering.
Patient. As a data engineer, you know that you work with extremely large data sets on a daily basis. As such we are looking for someone who is not only meticulous, but patient enough to sit and sift through that data in a thorough way.
Creative. Beyond just analyzing data sets, you are an explorer and a puzzle solver. Pulling insights out of your data and understanding how those insights can better shape our tools is something that you live to do.
Student. More so than most industries, the field of data science is always changing and evolving. As such, you are always looking to learn new things and gain new skills.

Required Skills and Experience
 On top of the many intangible skills you bring to the table, there are many skills that can help improve the efficiencies and success of your work at Spectrum. Here are a few of those required skills and experience that you will come in with as a Data Engineer on our team:

A bachelor’s degree/pursuing a bachelor’s degree in computer science, mathematics, statistics, information systems, or a related field
Experience with statistical modeling
1-3 years working experience with Python and/or SAS languages
1-3 years working experience with SQL databases and database querying languages
1-3 years working experience with C#/.NET
Familiarity with Microsoft Azure
Familiarity with Graph database structures
Experience with both RDBMS and TDMS
Experience with data mining and data cleaning
Experience with data visualization and reporting techniques
Written and verbal expression

Benefits
 As a Data Engineer at Spectrum there are a ton of fantastic perks and benefits that come along with your work. Here are just a few of the benefits you can expect when joining the Spectrum family:

Comprehensive medical & dental insurance
Retirement planning & company matching
Generous PTO, including sick days & holidays
Coworking space access for remote and hybrid work options
Year-round gym memberships
Paid continuing education
Hybrid work from Home , meetings a few times a month to strategize new projects 

About Us
 Our mission at Spectrum has always been the same— growth. Whether that be helping our customers find quality new business, developing and challenging our team members, or evolving our products and services with advancements in technology and best practices, we have always been looking towards bettering ourselves for the future. Now as we continue to grow, we find ourselves as not only the nation’s leading digital marketing and software provider for the home services industry, but an innovator and ground-shaker for the world of artificial intelligence as well. From marketing automation software powered by AI, to top notch digital marketing services via those same AI insights, we love what we do and are excited to continue to innovate for the future together. INDSPCI
  



   Hours
  

   40"
SAP BW Data Engineer,Molex,"Lisle, IL 60532",,,https://www.indeed.com/rc/clk?jk=854601a2b43edbe0&fccid=de113fe345574782&vjs=3,"Your Job
 Molex has a new opportunity as a SAP BW Data Engineer to support the technical/functional development and support of SAP BW/HANA IT applications. This role will allow you to utilize your communication, analytical and problem-solving skills to help identify, communicate, and resolve systems issues to maximize the benefit of IT systems investments.
 This role is not open to immigration sponsorship
 Our Team
 This role is a part of Molex's Enterprise Data Platform team and will be part of larger teams requiring excellent communication and collaboration skills with other technical groups as well as business leaders. This position will work closely with data architects, data analysts to design bespoke databases using a mixture of conceptual, physical, and logical data models.
 What You Will Do

 Knowledge of S/4 Extraction, Data Modeling, BW-ABAP(AMDP.), BEx Queries and Analysis office Workbooks(input sheets) experience. 
Exposure to latest SAP HANA Database version, Experience in creating HANA views and Stored Procedures using HANA studio and/or Eclipse. 
Hands-on experience on SAP advanced ABAP programming & HANA SQL script and modeling knowledge 
Experienced in SAP BW development lifecycle from development to post go-live support and designed BW overall data architecture, data flow and BW landscape. 
Technical skills in all areas of the ABAP workbench including BW User-Exits & Customer is plus. 
Enhancements Performance Tuning; ABAP Objects; Analyzing ABAP logs/dumps; Researching SAP Notes and SAP script. 
SAP functional knowledge of OTC, Finance, COPA, P2P, MM, SD etc. is valuable. 

Who You Are (Basic Qualifications)  

Experience developing front-end analytics using tools such as SAP Business Objects, SAP Analysis for Office, SAP Webi, Administering CMC and Tableau or PowerBI reporting solutions. 
Experience in SAP BW/HANA version 2.0 or earlier 
BI Reporting experience with tools such as ASBex, SAP Business Objects or similar reporting tools 
Experience in data modelling 

What Will Put You Ahead  

Bachelor's Degree in computer science, Information Technology, or other relevant fields 
Relevant SAP certifications 
Data modelling experience based on the BW on HANA concept 
Experience with SAP ECC/BW/HANA//SLT/ABAP 
Knowledge or experience building the modern composable architecture. 
Experience in working with multi-vendor, multi-culture, distributed offshore and onshore development teams in dynamic and complex environment. 
Experience with Cloud Environment. 

At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.

 Hiring Philosophy
 All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .

 Who We Are
 As a Koch company, Molex is a leading supplier of connectors and interconnect components, driving innovation in electronics and supporting industries from automotive to health care and consumer to data communications. The thousands of innovators who work for Molex have made us a global electronics leader. Our experienced people, groundbreaking products and leading-edge technologies help us deliver a wider array of solutions to more markets than ever before.
 At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.

 Our Benefits
 Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
 #LI-KB3
 Equal Opportunities 
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf"
Data Engineer,SPR,"Chicago, IL 60606 (The Loop area)",,,https://www.indeed.com/rc/clk?jk=b8d1f83a83b931c7&fccid=6d075cd02552081a&vjs=3,"Data Engineer
 

  Information Technology
 
 




Job Number: 

     4061 
    






City : 

     Chicago 
    






State : 

     IL 
    







DATA ENGINEER

 WHO IS SPR?

 SPR helps companies implement the right technology that helps them balance users’ expectations today while planning for tomorrow’s business demands. A technology modernization firm, SPR works together with clients to develop or modernize digital products and platforms.

 We’re 200+ strategists, developers, designers, architects, consultants, thinkers, and doers in Chicago and Milwaukee. We work with 150 mid- to enterprise-size clients across industries like professional services and manufacturing. We think about the end users and rigorously apply the latest technologies and frameworks to address our clients’ needs. Specializing in custom software development, cloud, data, and user experience solutions, SPR promises to Deliver Beyond the Build by providing proactive advice, sharing knowledge, responding to change in an agile way, and investing time to deeply understand our clients’ business.

 We operate in a fun, casual work environment and have great benefits including competitive salary, bonuses, generous vacation time, big fitness incentives, and medical/dental/vision insurance. By joining the SPR team, you’ll be problem solving, working hard and making an impact through your projects – and you’ll be part of a unique culture and rewarded for it.

 WHAT IS THE POSITION?

 As a Data Engineer at SPR, you must have experience building and operating data pipelines (both streaming and batch, utilizing both ETL and ELT architectures). You will be building data pipeline solutions by designing, adopting and applying big data strategies and architectures. You must be experienced in scalable system implementations with a focus on complex data processing and analytics pipelines. You must demonstrate an understanding of data integration best practices, and expertise in data integration, data transformation, data modeling and data cleansing. The Data Engineer must be able to demonstrate innovative approaches to complex problems which deliver industry-leading experiences for our clients.

 RESPONSIBILITIES

 ï Design and develop datasets with intent to facilitate consistency and efficiency
 ï Work in tandem with analysts and other stakeholders to develop and execute necessary processes and controls around the flow of data to ensure dependability
 ï Innovate scalable solutions and optimize efficiency of data infrastructure
 ï Collaborate with clients to understand and develop on business needs/issues
 ï Test/troubleshoot problems and conduct root cause analysis
 ï Understands and provides input into data governance to enable integrated and consistent application systems
 ï Verifies accuracy of table changes and data transformation processes
 ï Ability and delivery of fully-tested code prior to prod-deployment when appropriate
 ï Recommend and implement enhancements that streamline processes and improve data integrity
 ï Additional duties as assigned to ensure client and company success

 PROFESSIONAL QUALIFICATIONS

 ï Motivated, self-starter with ability to learn quickly
 ï SQL, python skills (R is a strong plus)
 ï Experience in designing and implementing innovative data integration solutions, utilizing Python with Spark clusters, 
ï Familiarity with architectural patterns for data-intensive solutions
 ï Expertise in real-time streaming and migrating batch-style data processing to streaming and micro-batch solutions
 ï Knowledge of the RDBMS core principles; set up, tune, design, as well as newer unstructured data tools 
ï Familiarity with consulting and traditional application design
 ï Excellent written and verbal communication skills
 ï Display sound problem-solving abilities in the face of challenges
 ï Must be a hands-on individual who is comfortable leading by example 
ï Experience with Agile Methodology 
ï Possess excellent interpersonal and organizational skills
 ï Able to manage your own time and work well both independently and as part of a team

 TECHNOLOGIES WE USE
 Cloud (Azure, AWS, Cloud Foundry, Heroku, Mesos, DC/OS) / RDBMS (SQL Server, PostgreSQL, Oracle, DB2) / NoSQL (Mongo, Raven, DocumentDB, Cassandra, Maria, Riak) / Python (including Databricks) / / Big Data (Cloudera & Hortonworks Hadoop distributions, including Hive, Pig, Sqoop, Spark) / Integration Tools (Apache Nifi, Cloudera Streamsets, Azure Data Factory, AWS Glue, Talend) / ELK (ElasticSearch, Logstash, Kibana) / Microsoft PowerShell / AWS SDK

 EDUCATION & EXPERIENCE

 ï Bachelor’s Degree, preferably in Data Science, Analytics, Computer Science, Engineering or Science / Technology-based disciplines
 ï 3-5 years of professional experience

 If this sounds like the kind of challenge you would be up for every day, we would love to hear from you. We are an Equal Opportunity Employer, including disability and veteran."
Remote Data Engineer (Clearance Required),Deloitte,"Remote in Chicago, IL",,,https://www.indeed.com/rc/clk?jk=328da88376b7eabd&fccid=9e215d88a6b33622&vjs=3,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.
 

Work you'll do

 The Data Engineer will design future-state, modern data architecture for transformation at the enterprise level using advanced architectural principles. Using tools such as Snowflake and/or Databricks, they will also work with cutting-edge DevOps technologies, develop advanced analytics products, and apply data and statistical programming tools to enterprise data to advance and enable key mission outcomes within environments (GCP, AWS, Azure).
 

The team 

 Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.
 
 The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.
 
 Qualifications
 
 Required:
 


Minimum Active Top Secret Level Security Clearance



5+ years of professional experience in data engineering (SQL).



5+ years of experience designing and developing real time ETL architecture for real time predictive analytics.



5+ years of experience with Databricks, Snowflake, or AWS



Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field

 Preferred:
 


3+ years of relevant consulting or industry experience



Creativity and innovation - desire to learn and apply new technologies, products, and libraries



Prior professional services or federal consulting experience

 How you'll grow
 
 At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
 
 The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,000 to $181,000
 
 #LI-MG1"
"Manager, Data Engineer & ETL Processing",Spark Foundry,"Chicago, IL (The Loop area)",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=32f972957c1aa277&fccid=65e65a4212c7f0fe&vjs=3,"Company Description
  About Spark Foundry:
 Spark Foundry is a global media agency that exists to bring HEAT – Higher Engagement, Affinity, and Transactions – to brands. By combining flawless media fundamentals with aggressive innovation, Spark inspires consumers to pay more attention, to care more about our clients’ brands, and to buy more products and services from them.
 Balancing the nimble spirit of a startup with the powerhouse soul of Publicis Media, Spark Foundry delivers the best of both worlds to a client roster that spans some of the world’s best and most beloved brands and companies. We combine boutique-caliber insights and service with the buying clout and first-look access of a global leader, bringing the heat to challenger brands that want to act like giants, and to giant brands that want to act like challengers.
 With a bottom-up culture that celebrates diversity and aims for all voices to be heard, Spark has become a magnet for the industry’s best talent, with one of the best retention rates in the industry. And by applying a whole-person approach to professional and personal development, Spark develops a workforce that is well prepared for today’s challenges, and also poised to create meaningful careers in the years to come.
 Because we know that heat arises the intersection of complementary forces, our professionals come from myriad disciplines and backgrounds: data, analytics, and insights, content and creative production, communications and strategy, finance and marketing, and sociology, psychology, and other liberal arts disciplines.



 Job Description
  Overview: 
The Manager, Data Engineering & ETL Development is a key driver to build data platform leveraging best in class ETL practice and is also a strategic thinker and a talented data visualization expert with emphasis on dashboard reporting. The primary responsibility will be developing business intelligence platform to support media and marketing data for our clients. This position will allow you to be a significant contributor as part of the team to support easy access of data and visualizations to fuel stronger insights and media optimizations.
 This position requires strong technical and tactical skill sets with an eye for numbers, intellectual curiosity, proficiency at problem solving, and a critical understanding of online media. The candidate must have a proven track record in managing ETL’s, APIs and business intelligence platforms. Candidate should be a team player. A “roll up the sleeves” approach is mandatory and a “get it done” attitude is a must. Specific responsibilities include coordination between the research, analytics & media teams ensuring high quality data projects are effectively delivered.
 Successful candidates will be multi-dimensional ‘rising-stars’ who are able to employ complex problem solving skills, and are able to communicate these succinctly to a broad client and media stakeholder audience.
 Role Objectives:

 Responsible for loading and validating data into the data warehouse from various source systems
 Analyze, develop, fix, test, review and deploy functionality, and bug fixes in ETL data pipelines
 Query tuning, diagnosis, and resolution of performance issues leveraging ELT and push-down if required
 Building Data mappings between Source to Target systems
 Provides support for technical issues and ensuring system availability
 Work with business customers to identify and develop additional data and reporting needs
 Understand how business intelligence platform/data technologies work and offer the ability to explain technical concepts in ordinary terms (be technically savvy - understand the opportunities and limitations)
 Establish and manage data integrations utilizing a taxonomy nomenclature to make recommendations for data visualization to showcase media performance through the use of Datorama or Tableau
 Perform regular quality assurance/quality control checks on assigned client campaigns to ensure the data is processing accurately
 Design and build backend data streams and processes to automate reporting capability with data visualization tools
 Contribute to client status and reporting calls, including presentation of reporting as required
 Develop subject matter expertise in ETL, API development, and Business Intelligence platforms
 Clearly define project deliverables, timelines, and dependencies for junior team members, internal stakeholders and clients
 Collaborate on an inclusive team, where members openly communicate and collectively problem-solve
 Strong ability to evaluate new technologies and present findings to team
 Contribute to knowledge sharing efforts and mentorships
 Complete other duties as assigned.




 Qualifications
 

 Bachelor’s degree or combination of education, and equivalent work experience is preferred in the field of computer science, management information systems or Information Technology
 3+ years’ related experience ETL development and business intelligence platform management
 Understanding of BI/ETL development in the IT industry with recent development, system administration, application tuning and debugging experience.
 3+ plus years’ development experience with database engines including Presto, Mongo db and Hadoop.
 3+ years’ experience in ETL development, Strong Database (Modeling, SQL), SQL Server, Hadoop, AWS Redshift, Qubole.
 Experience managing team of 2 or more associates/analysts preferred
 Strong database modeling and SQL skills. Ability to write complex SQL statement, Procedures and data automation programs
 Knowledge of ETL tools like Airflow, AWS Glue, Alteryx, SSIS, Qubole/Spark is a must
 Knowledge of Python or similar programming languages required
 Proficiency with Datorama, Tableau, or other data visualization tools is preferred
 Experience working with AWS or other cloud technologies
 Advanced user Microsoft Office Suite and reporting tools
 Demonstrated expertise in core MS Excel functions (vlookup, pivot tables, data visualization)
 Experience in designing jobs that can be easily promoted from one (Dev) environment to another (Test or Prod) seamlessly, without modification.
 Strong analytical and problem-solving skills
 Strong verbal/written communication and interpersonal skills is required
 Self-starter with ability to thrive in a fast-paced environment and able to function independently while providing status updates to a team of analysts
 Cooperative, flexible, conscientious, dependable, resourceful, self-motivated, and team-oriented
 Problem solving, time management, and critical thinking skills with a professional and positive attitude
 Ability to work independently and as part of an agile team, participating in daily stand-ups, sprint planning and sprint review


 Character: 
The following qualities help drive success as member of the Spark Data and Analytics team:

 Entrepreneurial, engaging, resourceful, curious, and self-directed spirit
 Willing and easily roll sleeves up or down; love the nitty-gritty and the strategy
 Collaborative approach to building cohesive, strong teams
 Loving and living the intersections between brands, people, media, communications
 Relentlessly passionate and resolute
 Planning and time management excellence.
 Embrace challenges
 Proactive, especially in pushing for new opportunities, approaches, and ideas.
 Keenly focused on action and solutions; thrives with deep critical thinking and analysis.
 Pioneering insight attitude and research in-the-know.
 Resourcefulness, flexibility and adaptability, strong ability to pivot when the need arises.
 Inspired to be part of the insight journey/revolution with a growing, dedicated team

 Additional Information
  All your information will be kept confidential according to EEO guidelines.
 23-2795"
Staff Data Engineer,Grindr,"Remote in Chicago, IL 60625",Posted 30+ days ago,"$190,000 - $250,000 a year",https://www.indeed.com/rc/clk?jk=be2b1d9070760b9e&fccid=7c4356358e0da7c8&vjs=3,"We are seeking candidates for this fully remote role who are based in the greater Chicago area. Grindr employees living and working in the greater Chicago area are encouraged, but not required, to join the Engineering Team in the West Loop Chicago satellite office a few times per month.
 What's so interesting about this role?
 The big data space is growing rapidly at Grindr and we're looking to add a staff-level Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. Beyond the data pipeline, you will also be instrumental in bringing the data-driven products and features to life and helping build the future of Grindr.
 In this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, deliver analysis to further improve engagement in existing features, and empower our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.
 What's the job?

Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.
Solve technical problems of the highest scope and complexity
Exert significant influence on the company's analytical long-range goals and data architecture
Define and extend our internal standards for style, maintenance, and best practices for a high-scale data platform
Provide mentorship for all on your team to help them grow in their technical responsibilities
Propose ideas to improve the scale, performance, and capabilities of the Data Platform
Moving implementation to ownership of real-time and batch processing and data governance and policies.
Maintain and enforce the business contracts on how data should be represented and stored.
Stay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users
Implementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.
Work closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.

What we'll love about you

7+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field
7+ years experience using Python
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Significant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases
Experience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Experience with dimensional data modeling and schema design in Data Warehouses
Familiar with ETL (managing high-quality reliable ETL pipelines)
Be familiar with legal compliance (with data management tools) data classification, and retention


What you'll love about us

Mission and Impact: Grindr is the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We currently have offices in LA, NYC, and Chicago, and are hiring someone for this role to be based ideally in Los Angeles, San Francisco, New York City, or Chicago
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events

About Grindr
 Grindr is the world's largest dating app for gay, bi, trans, and queer people. With around 13 million monthly active users, Grindr has become a fundamental part of the global LGBTQ community, and we take pride in empowering our users to connect, express themselves, and discover the queer world around them.
 Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we're blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.
 With a track record of strong financial performance and plans for continued headcount growth, we're looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us. 
Grindr is an equal-opportunity employer
 To learn more about how we handle the personal data of applicants, visit our Employee and Candidate Privacy Policy.


 #LI-Remote



 Grindr is committed to fair and equitable compensation practices. This base pay range is for the U.S. and is not applicable to locations outside of the U.S. The actual base pay is dependent upon many factors, such as training, transferable skills, work experience, business needs, location, and market demands. The base pay range is subject to change and may be modified in the future. This role will also be eligible for equity, benefits, and a company bonus program.

 Base Pay Range

    $190,000—$250,000 USD"
Software Development Engineer II - Data Pipelines,Groupon,"Chicago, IL 60654 (Goose Island area)",Posted 16 days ago,"$89,600 - $140,800 a year",https://www.indeed.com/rc/clk?jk=0777171db85c4886&fccid=863ad2cc91c92c82&vjs=3,"Can data really help local businesses around the world thrive? 
Are you ready to test your skills using massive amounts of information to make critical business decisions? 
Groupon is an experiences marketplace that brings people more ways to get the most out of their city or wherever they may be. By enabling real-time mobile commerce across local businesses, live events, and travel destinations, Groupon helps people find and discover experiences––big and small, new and familiar––that make for a full, fun, and rewarding life. Groupon helps local businesses grow and strengthen customer relationships––resulting in strong, vibrant communities. With employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking, and celebrates success. Our culture encourages employees to embrace change, adapt to new circumstances, and find creative solutions to the challenges we face. Does that sound like a great way to grow your career? Let’s get into the details: 
The Data Engineering team at Groupon is at the heart of all things “data”, working on designing and building the next-generation data pipelines for data-science/machine learning community users. Our mission is to empower data analysts & data-scientists across all business units to make better business decisions. This role offers a unique combination of skills in computer science (distributed systems, big data), cloud, scalable, and high-performance production systems. 
You’ll spend time on the following: 

Design, and implement the data pipelines providing access to large datasets and transforming power for data across the org 
Write complex but efficient code to transform curated data into business questions oriented datasets and data visualizations. 
Work with big data and distributed systems using technologies such as Spark, AWS/GCP, and Python. 
Actively contribute to the adoption of strong software architecture, development best practices, and new technologies. We are always improving the process of building software; we need you to help contribute. 
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using open sources and GCP big data technologies 
Explore and learn the latest GCP technologies to provide new capabilities and increase efficiency 
Collaborate with Business Users, Infra Engineers, and Data Scientists to recognize and help adopt best practices in data gathering and transforming big data 
Work with the team to discuss the technical design and development needs. 

We’re excited about you if you have: 

Bachelor’s degree in computer science, mathematics, or a related technical field 
3+ years of relevant employment experience in data engineering or a related field 
At least 2 years of SPARK development experience 
At least 1 year of experience with Airflow, NiFi, or Azkaban 
A Clear understanding of testing methodologies and AWS/GCP cloud Best Practices 
Mastery of big data technologies (e.g. Hadoop, Hive, Spark ) 
Excellence in technical communication and experience working directly with stakeholders 
Demonstrated ability to coordinate projects across functional teams, including engineering and product management 
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations 

We value engineers who are: 

Customer-focused: We believe that doing what’s right for the customer is ultimately what will drive our business forward. 
Obsessed with Quality: Your Production code Just Works & scales linearly 
Team players. You believe that more can be achieved together. You listen to feedback and also provide supportive feedback to help others grow/improve. 
Fast learners: We are willing to disrupt our existing business to trial new products and solutions. You love learning how to use new technologies and then rapidly apply them to new problems. 
Pragmatic: We do things quickly to learn what our customers desire. You know when it’s appropriate to take shortcuts that don’t sacrifice quality or maintainability. 
Owners: Engineers at Groupon know how to positively impact the business. 


Groupon’s purpose is to build strong communities through thriving small businesses. To learn more about the world’s largest local ecommerce marketplace, click here for the latest Groupon news. Plus, be sure to check out the values that shape our culture, guide our strategy and make our company a great place to work. And just don’t take our word for it. Hear from real Groupon team members, learn more about our inclusive employee groups, and check out our benefits. If all of this sounds like something that’s a great fit for you, then click apply and let’s see where this takes us.
 Groupon is an Equal Opportunity Employer
 Qualifications for employment, promotion, and other terms and conditions of employment are based upon the ability to perform the job. Equal-employment opportunities are provided to all applicants and employees without regard to race, creed, religion, color, age, national origin, sex, disability, medical condition, sexual orientation, gender identity or expression, genetic information, ancestry, marital status, military discharge status (excluding dishonorable discharge), veteran status, citizenship status, or other legally protected status. We are all responsible for maintaining this policy. Groupon is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may email us at hraccommodations at groupon.com. If you have concerns related to Groupon’s equal employment opportunities, you may contact Groupon’s Ethics Reporting Service Ethicspoint."
Lead Engineer - Data Ops,United Airlines,"Chicago, IL",Posted 27 days ago,Full-time,https://www.indeed.com/rc/clk?jk=19e46b43a9895215&fccid=e69f69636a9997cd&vjs=3,"Description

 There’s never been a more exciting time to join United Airlines. We’re on a path towards becoming the best airline in the history of aviation. Our shared purpose – Connecting People, Uniting the World – is about more than getting people from one place to another. It also means that as a global company that operates in hundreds of locations around the world with millions of customers and tens of thousands of employees, we have a unique responsibility to uplift and provide opportunities in the places where we work, live and fly, and we can only do that with a truly diverse and inclusive workforce. And we’re growing – in the years ahead, we’ll hire tens of thousands of people across every area of the airline. Our careers include a competitive benefits package aimed at keeping you happy, healthy and well-traveled. From employee-run ""Business Resource Group"" communities to world-class benefits like parental leave, 401k and privileges like space available travel, United is truly a one-of-a-kind place to work. Are you ready to travel the world?
 We believe that inclusion propels innovation and is the foundation of all that we do. United's Digital Technology team spans the globe and is made up of diverse individuals all working together with cutting-edge technology to build the best airline in the history of aviation. Our team designs, develops and maintains massively scaling technology solutions brought to life with innovative architectures, data analytics, and digital solutions.
 Key Responsibilities:
Overview
 United Airlines is seeking dedicated people to join the Data Engineering team. The organization is responsible for driving data driven insights & innovation to enable the Data Engineering and Machine Learning needs for commercial and operational projects with a digital focus. This role will frequently collaborate with business partners, data scientists and ML engineers. This role will design and enable key subsystems of the Data Platform, optimize operational critical metrics, and establish processes and best practices. As part of the platform team, this role will work in innovative cloud technologies from AWS and other ecosystems, including but not limited to Airflow, OpenTelemetry, OpenLineage, Marquez, Great Expectations, and others.
 Responsibilities

Partner with development teams and other department leaders/stakeholders to provide innovative technical solutions that enable business capabilities.
Participate and lead in design and development of innovative batch and streaming data applications using AWS technologies. Support large scale data pipelines in a distributed and scalable environment. Enable and optimize production AWS environment for data infrastructure and frameworks.
Set up containers and Serverless platform with cloud infrastructure.
Provide the team technical direction and approach to be undertaken and guide them in resolution of queries/issues.

United values diverse experiences, perspectives, and we encourage everyone who meets the minimum qualifications to apply. While having the “desired” qualifications make for a stronger candidate, we encourage applicants who may not feel they check ALL of those boxes! We are always looking for individuals who will bring something new to the table!

 Qualifications

What’s needed to succeed (Minimum Qualifications):

Bachelor’s degree and 8+ years of professional experience
4+ years of professional experience managing infrastructure and data pipelines using Cloud Formation, Terraform, PySpark, Airflow, or similar technologies
2+ years of experience in leading a team that engineers, architects, or support solutions on AWS
Working knowledge of common AWS technologies – EC2, S3, IAM, Lambda, Glue, SNS, others
General awareness of other AWS technologies
Working knowledge with CI/CD tools, SQL, Python, Spark, Version control system, JIRA.
Hands on experience with any object-oriented programming language
Must be legally authorized to work in the United States for any employer without sponsorship.

What will help you propel from the pack (Preferred Qualifications):

AWS Certification – Solutions Architect, DevOps Engineer or similar
Experience with Data Quality tools – Great Expectations, Deequ, or similar
Excellent knowledge and experience in Linux operating system or Windows



 United Airlines is an equal opportunity employer. United Airlines recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, gender identity, sexual orientation, physical ability, age, veteran status and other protected status as required by applicable law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions. Please contact JobAccommodations@united.com to request accommodation.

 Equal Opportunity Employer - Minorities/Women/Veterans/Disabled/LGBT"
Senior Data Engineer,IHI Terrasun Solutions Inc.,"Remote in Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=b82da85d4e50bde8&fccid=dd616958bd9ddc12&vjs=3,"At IHI Terrasun, we are at the forefront of changing the world with green energy solutions. To build on our incredible success, we need a driven, curious, and collaborative people to join our growing team.
 We know our most important assets are our people, and your role will be critical to our future success.

 Position Summary
 This position is responsible for the development, implementation, and maintenance of data systems for both data in motion and data at rest to monitor and control battery storage systems. In this role, you'll work with setting up systems to capture hardware metrics and track their performance for outage tracking and compliance for one of the largest collections of industrial automation data worldwide.


 What you'll be doing

Create services to receive, translate, and send data in motion to data stores via APIs and query languages.
Developing and deploying data pipelines using docker/containerization, Jenkins and Kubernetes.
Participate in the entire software development lifecycle of a product from ideation, wireframing/prototyping, development, testing, deployment, commissioning, and long-term support.
Own automated testing and deployment for products that you create.



 The ideal candidate would have the following experience:

Developing in Python including libraries like pandas, the SciPy stack, request, and data tools in the context of data processing workflows, scripts, and services.
Working in every stage of the data lifecycle from converting business specifications/requirements to technical solutions through deployment, and maintenance.
Integrating software and services, including developing adaptors between different data protocols (e.g., MQTT to Prometheus exposition format)
Creating scalable and performant systems.


Analyzing messaging protocols using tools like tcpdump, WireShark, and custom data producers and consumers.
Reading, writing, and converting data formats like json, yaml, csv, pandas dataframes, and relational databases.
Working with Prometheus, PromQL, and Grafana.
Developing and deploying Docker workflows.
Working in a Linux environment including basic shell scripting and system monitoring.


Participating in Agile development including scrum ceremonies, ticket management, GIT version control, unit testing, code reviews, and documentation.
Experience in compiled languages like Go, Rust, or C++ are a plus but not required.



 Qualifications

5+ years experience in data engineering
BS, MS or PhD in CS, Engineering, Math, Physical Sciences or equivalent real-world experience.
Ability to work independently, with a development team, and within large multi-team projects.
Excited to learn and grow with new technologies and adaptability to handle evolving requirements.
Has a shared sense of responsibility and ownership both in your code and the larger system that it operates in.
Ability to communicate issues openly and honestly even when difficult.
Previous Energy Storage System experience is preferred, power industry or military systems experience is a plus



 Work Environment

IHI has its main office in Chicago, IL, however this position can be remotely located. Those in the Chicago-land area have the flexible option of working from the office or remotely from home.
Limited travel may be required for company All-Hands or other meetings. Travel expectations for this position are up to 5% within the US.



 The above job description identifies the essential job functions and skills needed by the person or persons assigned to this position. These job functions and skills are not intended to be a complete and exhaustive list of all responsibilities, duties and skills required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions. The information contained herein is subject to change at the company's discretion.

 About IHI Terrasun Solutions:
 IHI Terrasun Solutions is a subsidiary of IHI Corporation, a 165-year-old, $15 Billion organization with deep energy industry experience. IHI Terrasun Solutions is a solar + storage systems integration and lifecycle services provider with highly integrated hardware and software capabilities.
 The robust software and top tier energy storage solutions are developed by the expert team at IHI Terrasun Solutions. Employees have extensive industry knowledge and experience, and enthusiastically seek to build on IHI's advanced product offerings. 
To design systems, IHI Terrasun Solutions uses proprietary software that operates on the same algorithm later used to deploy the system in real-time. This end-to-end algorithm structure coupled with the support offered by a well-established parent organization enables IHI Terrasun Solutions to provide an advanced warranty to customers, reducing project risk and increasing clarity on system scheduling and deployment. 
With solar + storage expertise, robust service offerings, and technology-agnostic solutions, IHI Terrasun Solutions develops efficient and streamlined systems to achieve your energy storage goals.
 IHI Terrasun has over 480MWh of projects currently installed, contracted, and in construction with over 1GWh of projects in advanced phase of contracting.


 Benefits:
 Not only do our employees get the chance to work in a rapidly growing energy business with global impact, they also have access to some of the best benefits in the industry, including:

100% employer paid health, dental, and vision insurance for our premium Anthem Blue Cross PPO plan
401(k) plan contribution matching
Employer sponsored Life, AD&D, Short-Term and Long-Term Disability Insurance
Tuition and continuing education stipend
Fantastic employee culture"
Sr. Data Engineer (REMOTE),The Hartford,"Remote in Chicago, IL",Posted 20 days ago,Full-time,https://www.indeed.com/rc/clk?jk=a003ff7d5f58dcb2&fccid=25d3835187829237&vjs=3,"You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.
 


   The Hartford is seeking a Senior Data Engineer to join the Actuarial Technology and Innovation team to design, develop, and implement modern and sustainable data assets to fuel machine learning and artificial intelligence solutions across a wide range of strategic initiatives.
 


   The Actuarial Technology and Innovation team is a dynamic mix of Actuarial and Data Science professionals utilizing statistical modeling, machine learning, and advanced data engineering techniques to enhance core Actuarial processes. As a member of the LOB Engineering pillar, you will work directly with our Actuarial partners in building & designing tailor-fit data pipelines & processes. We are a forward-focused organization that fosters collaboration, encourages creative design, and offers abundant opportunities for visibility, allowing candidates to shape innovative solutions and showcase their talents to a wide audience.
 


   As a Senior Data Engineer, you will be at the forefront of driving impactful solutions throughout the entire software development lifecycle, ensuring reliable data delivery. Our team's culture is deeply rooted in embracing emerging technologies and empowering you to select the optimal tools for each unique project, so curiosity and adaptability are highly valued. Strong candidates will also demonstrate a solid foundation in data management, software engineering, and process automation along with an enthusiasm for delivering efficient solutions to partners.
 


   Responsibilities:
 

 Design and develop high quality, scalable software modules for next generation analytics solution suite


 Prototype high impact innovations, catering to changing business needs, by leveraging new technologies
 Consult with cross-functional stakeholders in the analysis of short and long-range business requirements and recommend innovations which anticipate the future impact of changing business needs
 Formulate logical statements of business problems and devises, tests and implements efficient, cost-effective application program solutions
 Identify and validate internal and external data sources for availability and quality. Work with SMEs to describe and understand data lineage and suitability for a use case
 Create data assets and build data pipelines that align to modern software development principles for further analytical consumption. Perform data analysis to ensure quality of data assets.


 Develop code that enables real-time modeling solutions to be ingested into front-end systems
 Produce code artifacts and documentation using GitHub for reproducible results and hand-off to other data science teams



   Minimum Qualifications:
 

 3+ years of relevant experience recommended
 Bachelor’s degree in Computer Science, Engineering, IT, Management Information Systems, or a related discipline


 Proficiency in SQL and R or Python
 Proficiency in ingesting data from a variety of structures including relational databases, Hadoop/Spark, cloud data sources, XML, JSON
 Proficiency in ETL concerning metadata management and data validation


 Proficiency in Unix and Git
 Interest & willingness to deeply understand Insurance & Actuarial business
 Able to communicate effectively with both technical and non-technical teams
 Able to translate complex technical topics into business solutions and strategies as well as turn business requirements into a technical solution
 Experience with leading project execution and driving change to core business processes through the innovative use of quantitative techniques



   Preferred Skills and Experience:
 

 Experience with Machine Learning, Statistical Modeling, or Actuarial Science
 Experience with agile software development
 AWS Certification or experience with AWS Services (S3, EMR, etc.)
 Proficiency in Automation tools (Airflow, Cron, Autosys, etc.)
 Experience with Cloud data warehouses, automation, and data pipelines
 Experience with containerized computing (Docker, Kubernetes, etc.)
 Experience building CICD pipelines or IAC (Infrastructure as Code)



   Compensation
 

   The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
 
 $110,560 - $165,840
 

   Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age"
Senior Associate Data Engineer,Discover Financial Services,"Riverwoods, IL 60015",PostedJust posted,"$70,000 - $118,400 a year",https://www.indeed.com/rc/clk?jk=309b1ad903329ebb&fccid=6ce7e0d9f67a9961&vjs=3,"Discover. A brighter future. 
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine. 

 Come build your future, while being the reason millions of people find a brighter financial future with Discover. 


Job Description:
 The Senior Associate Data Engineer is responsible for designing, developing, maintaining , and testing data solutions for the product using the enterprise framework. This role will apply learned software delivery capabilities and have the desire to learn higher levels of craftmanship. Senior Associate Data Engineers contribute opinions to design decisions and actively participate in agile ceremonies. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management. 

 Responsibilities 

 Independently executes a variety of data integration solutions, recognizes data related patterns, and solicits advice on potential approaches 

 Contributes opinions to design decisions and understands design tradeoffs 

 Develops skills in data warehouse tools, Cloud, agile and other technologies involved in data integration 


Demonstrates and applies knowledge of:
 Data Integration concepts and tools 

 DW Design concepts and Metadata documentation 

 Data Profiling tools 

 Data Security 

 Data Quality 

 Regularly contributes to team agile ceremonies and helps new engineers with onboarding 

 Troubleshoots production issues and defects 

 Identifies and executes test scenarios and shares test results 

 Participates in the on-call rotation for support 

 Minimum Qualifications 


At a minimum, here’s what we need from you:
 Bachelor's Degree in Computer Science or related field 

 1 + years of experience in Data Platform Administration/Engineering 


Internal applicants only: technical proficiency rating of advanced beginner on the Dreyfus engineering scale 

 Preferred Qualifications 


If we had our say, we’d also look for:
 Experience in supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack) 

 ETL/ELT Tools ( AbInitio , DataStage, Informatica) 

 Experience working with relational or no-SQL databases, Cloud Tools 

 Other programming languages (Unix scripting, Python, etc.) 

 Knowledge of cloud platforms (AWS, GCP, Azure) 

 Basic knowledge of DevOps CI/CD framework, Open-Source concepts, key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs 

 External applicants will be required to perform a technical interview. 

 #LI-CM 


Compensation: The base pay for this position generally ranges between $70,000.00 to $118,400.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position. 


Benefits:
 We also offer a range of benefits and programs based on eligibility. These benefits include: 

 Paid Parental Leave 

 Paid Time Off 

 401(k) Plan 

 Medical, Dental, Vision, & Health Savings Account 

 STD, Life, LTD and AD&D 

 Recognition Program 

 Education Assistance 

 Commuter Benefits 

 Family Support Programs 

 Employee Stock Purchase Plan 

 Learn more at MyDiscoverBenefits.com . 

 What are you waiting for? Apply today! 

 All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management. 

 Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)"
Senior Data Engineer,S&P Global,"Remote in Chicago, IL 60602",Posted 25 days ago,"$70,300 - $139,800 a year",https://www.indeed.com/rc/clk?jk=277a4ea956475c53&fccid=b716e44d2c6283e7&vjs=3,"The Role: Senior Data Engineer 


The Team: As a member of the Data Operations team, you will help modernize the extensive data domain of the Issuer Solutions business. 


The Impact: As we redesign and reimagine our client-facing and internal tools, data quality and consistency across multiple tools and platforms will be a key factor in our success, and the Data Engineering team is tasked with ensuring that all data consumers, from developers to business analysts to clients, have tools to access the data they need in the format they need it. 


What’s in it for you:
 Designing and implementing data-ingestion and data-publishing tools for diverse datasets. 
Implementing and maintaining data-monitoring and data-cataloguing tools. 
Implementing and maintaining process-management and data-movement tools for ETL’s. 
Offering guidance and best practices to scrum teams who work with data. 
Evaluating and implementing new data management technology with the goal of continually improving team efficiency and data quality. 
Providing support and guidance for business analysts using data analysis tools such as Alteryx and PowerBI. 


Responsibilities:
 Minimum of 3+ years experience as a software engineer 
Experience as a Data Engineer in a production environment 
Focus on ETL’s, data monitoring, data engineering, etc. 
Python, C#, Docker, MS SQL Server, PostgreSQL 
Experience with AWS and/or Azure DevOps 

AWS tech: Aurora DB, Glue, Lambda 
Alteryx Server 
Infrastructure as code using Terraform/CloudFormation 
Solid understanding of containers and orchestration tools (Docker, CI/CD, etc.) 
AirFlow, DataHub, NiFi and other data-management and process-management tools a plus 
Experience with BI and analytical tools such as PowerBI and Alteryx 

 Flexible Working (optional) 
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. 

 Return to Work 
Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. 


Grade/Level ( relevant for internal applicants only ): 10 


The Location: Florida, Georgia, New York, Virginia, Connecticut, Ohio, Delaware 


Compensation and Benefits Information:
 S&P Global states that the anticipated base salary range for this position is $70,300 - $139,800. Base salary ranges may vary by geographic location. 
In addition to base compensation, this role is eligible for an annual incentive bonus plan. 

 This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit Our Benefits (spgbenefits.com) . 


About Company Statement:
 S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. 

 S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work. 

 ----------------------------------------------------------- 

 Equal Opportunity Employer 
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. 

 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. 


US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 

 ----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group) 


Job ID: 288863 

Posted On: 2023-06-22 

Location: Virtual, North Carolina, United States"
"Lead Data Engineer – Snowflake, Informatica, AWS – Rosemont, IL 44602","PRIMUS Global Services, Inc","Hybrid remote in Rosemont, IL",Posted 1 day ago,,https://www.indeed.com/rc/clk?jk=975ee437904e2996&fccid=fab19a82e69a8358&vjs=3,"We have an immediate long-term opportunity with one of our key clients for a position of Lead Data Engineer, to work in Rosemont, IL.  Required Qualifications and Skills:

  Experience working on Snowflake. Experience developing technical solutions for Cloud data warehouses and data lakes. Exposure to Python is a plus. Experience working on Informatica Cloud (IICS) and on AWS data environments (S3, EMR, Lambda, SQS, etc.)
 

 For immediate consideration, please contact:  Aman PRIMUS Global Services Direct: 972-853-8927 Desk: 972-753-6500 Ext: 417 Email: jobs@primusglobal.com"
Senior Data Engineer,Chicago Public Media,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=9dfbd52ebf247e36&fccid=8fc3aaf2b4404bce&vjs=3,"About Chicago Public Media
 Home to WBEZ and the Chicago Sun-Times, Chicago Public Media is the largest local non-profit news organization in the country. WBEZ and the Chicago Sun-Times serve more than 2 million people weekly across broadcast, print, and digital platforms. As a mission-driven organization, we aspire to become the essential and most trusted news source that Chicago turns to each day for understanding the people, events, and ideas that shape our community.
 WBEZ is home to local and national news programming as well as a growing portfolio of popular podcasts. WBEZ serves the community with fact-based, objective news and information, and its award-winning journalists ask tough questions, dig deep for answers and expose truths that spark change and foster understanding. WBEZ is supported by more than 86,000 members, hundreds of corporate sponsors and major donors. In 2022, WBEZ received more than 20 awards for its journalism, including two prestigious National Edward R. Murrow Awards.
 Chicago Sun-Times is Chicago's oldest continuously published daily newspaper serving Chicago and is known for its hard-hitting investigative reporting, in-depth political coverage, timely behind-the-scenes sports analysis, and insightful entertainment and cultural coverage. Chicago Sun-Times is the winner of eight Pulitzer Prizes and countless other awards. In recent years, the Sun-Times has focused on a digital transformation to deliver its news and content to a growing digital audience. Most recently, the Sun-Times dropped the paywall on suntimes.com to expand access to its journalism, and shifted to a community-funded digital membership program supported by voluntary member donations.
 Chicago Public Media believes independent journalism is essential to a well-functioning democracy and access to fact-based, objective news and information is a right of every citizen. We serve the public interest by creating diverse, compelling content that informs, inspires, and enriches. We connect diverse audiences and help them make a difference in the community, the region and the world. And, we employ 300+ staff who want to belong to an organization that inspires, supports, and challenges them to do their best work.
 For more information, please see the Chicago Public Media Annual Report.

 The Opportunity
 Chicago Public Media seeks an experienced engineer to own the end-to-end data operations that help us better understand and serve our community. Chicago Public Media is expanding its use of data to drive top-level organizational strategy, and this role plays a foundational role in expanding our organization's data capacities across audience, content and revenue teams. As of 2022, Chicago Public Media is the home of the Chicago Sun-Times, WBEZ, and Vocalo. In this role, you will be responsible for maintaining, developing and improving the data systems and models that inform our work across news, revenue, and audience development goals across all brands. You will create and maintain data pipelines, integrate new data sources, maintain and extend data warehouses, and collaborate with Product and Analytics leads to ensure that users across the organization have ready access to data, through methods that could include reports, dashboards, and internal research tools.
 General Responsibilities

Own core audience data operations for CPM, including content/product performance and revenue
Design and maintain data integrations and data quality framework
Work closely with all business units and engineering teams to develop strategy and design for long-term data platform architecture and specify appropriate tools and technologies to support strategic goals.
Develop and maintain scalable data pipelines, building out new integrations to support continuing increases in data volume and complexity.
Collaborate with Product, Revenue, and Audience Insights teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Write unit/integration tests, provide documentation, and ensure business continuity for all critical systems.

Qualifications

5+ years of data engineering experience
Experience running and supporting production of enterprise data platforms
Experience in building infrastructure required for optimal extraction, transformation and loading of data from various resources
Experience creating internal tools that combine content and audience data preferred
Knowledge of JavaScript, Python, Bash and SQL
Ability to build data pipelines with tools and cloud-based data services like Google's BigQuery, AWS, Dataproc and Pub/Sub
Strong statistics skills
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service


 Working at Chicago Public Media
 At Chicago Public Media, we care deeply about our employees as we know attracting, developing, and growing talent is key to our success and enhancing our impact. Our culture is one where collaboration, ideas, and innovation are encouraged. We value colleagues who will enhance our culture by bringing new ideas, diverse experiences, and talents to our dynamic workplace.
 Chicago Public Media's dedication to promoting diversity and inclusion is reflective across our brands, WBEZ 91.5 FM, Chicago Sun-Times, and Vocalo 91.1 FM, in our staff and in our work. We are fully focused on equality of opportunity and believe deeply in diversity of race, gender, sexual orientation, religion, ethnicity, national origin, experience, and all other fascinating characteristics that make us different.
 At Chicago Public Media we believe dedication to a great workplace includes supporting our employees and their families. As a result, we provide a broad and generous benefits package for you at hire and in the years to come.
 Our benefits include:

6 weeks fully paid family leave
High quality Medical, Dental, and Vision plans at an affordable cost
A 403(b)retirement plan with a company match
Generous paid time off, including starting with 3 weeks' vacation and 4 personal days.

The essential functions described above are not all-inclusive and may change periodically to meet the needs of Chicago Public Media (CPM). The information contained in this job description is not intended to create any contractual or other legal commitment. Chicago Public Media may change the content or format of this job at any time in its sole and exclusive discretion without notice.  Chicago Public Media is an Equal Opportunity Employer, and we actively seek and welcome people from all backgrounds, orientations, and life experiences to join our team."
Financial Data Engineer,Hull Tactical Asset Allocation,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=78ba0c083030713b&fccid=5168e49fe820dfb1&vjs=3,"Hull Tactical is seeking a data manager to join our growing equity options team to build and manage daily data processes. The mission is to curate and analyze fundamental and sentiment data (news, social, Reddit, etc.) to anticipate market movements in US listed companies including “meme” stocks.
 Practical experience managing a “fundamental data” store is necessary for a candidate to be successful.

“Fundamental data” means information about individual US stocks and options that is updated at most daily. Examples are: 
   
Corporate actions, such as dividends and splits
Symbol name changes
Industry sector mapping and changes
Earnings dates

Fundamental data is mostly sourced from vendors such as FactSet, Bloomberg, Thomson Reuters or EOD Historical Data
Some of the fundamental data is derived in-house from intraday data including trading volume, open interest, and aggregated tick data



 Position Location: Chicago, IL
 Required Skills

Experience with fundamental data from vendors such as FactSet, Bloomberg, Thomson Reuters, EOD Historical Data
Experience with basic relational modeling and SQL
Practical experience working with MySQL, PostgreSQL or similar databases
Experience working in a Linux environment 
   
Basic Linux command line skills and familiarity with simple Bash scripts
Python scripting to build and maintain data ingestion pipelines
Experience with Pandas and with Python database scripting

Managing daily recurring data processing jobs with tools such as cron, rundeck, etc.

Desired Skills

Python programming
Experience using git, feature branches and automated testing
Experience with generating data for reporting tools using Python
Prior experience working on a fundamental data team
Ability to identify and correct performance bottlenecks
Bachelor’s or advanced degree in computer science, information technology or related field

WHAT WE OFFER

Competitive financial rewards with further upside tied individual, team, and firm performance
Employee benefits that include exceptional insurance and 401K matching program
Friendly and collegial work environment
Opportunity to learn from successful industry experts



 Please send your CV or Resume to resume@hulltactical.com in PDF format only. Non-PDF files will be rejected!"
Data Engineer/ ETL Developer,SDH Systems,"Chicago, IL 60604 (Loop area)",Posted 30+ days ago,"$81,931 a year",https://www.indeed.com/rc/clk?jk=06c68b2321214d33&fccid=4494b8cfea28ee1e&vjs=3,"Location: Chicago, Illinois 60604 Duration: 3 Years Work Schedule: Full Time, 40 Hours/Week Salary: $81,931.00/Annum + Company Standard Benefits
 Job duties:

Create and enhance datasolutions enabling seamless delivery of data and is responsible for collecting, parsing, managing and analyzing large sets of data across different domains for analysis. 
   
Works with various departments in collecting requirements and creates tables to load data based on business requirements. Manages data in Development, QA and PRODUCTION environments ensuring seamless delivery to the customers.





Use different Data warehousing concepts to build a Data warehouse for internal departments of the organization. 
   
Applies Data warehousing concepts such as star and snowflake schema approach while creating tables and maintaining data to ensure data integrity.





Designs and develops data pipelines, data ingestion and ETL processes that are scalable, repeatable and secure for stakeholder needs. 
   
Designs ETL Processes using Informatica tool to extract data from heterogeneous sources and transforms data using complex logic as per business needs and ingests it into our warehouse.





Build Data architecture to support data management strategies to support business intelligence efforts for various stakeholders. 
   
Ensures data stored in the warehouse can be used to create dynamic Business Intelligence reports for complex analysis helping in making business driven decisions.





Leads the design of the logical datamodel and implements the physical database structure and constructs and implements operational data stores and data 
   
Manages access to confidential data by creating database views and data marts for customers and ensures confidential data is shared using company policies.





Support deployed dataapplications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution Data Pipeline Management. 
   
Works with other team members in analyzing the data and advises on how to improve data quality and provide cleaner solutions to business stakeholders.





Develops real-time and batch ETL dataprocesses aligned with business needs, manages and augments data pipeline from raw OLTP databases to data solution structures. 
   
Builds complex ETL process using Informatica to transform the data as per business needs and automated the process capturing real time data and maintaining history for complex analysis.





Documents data flow diagrams, security access, data quality and data availability across all business systems. 
   
Documents all processes of every project using JIRA for reference by any other member on the team and ensures it is always secure.
 

Minimum Education Requirement: This position requires minimum of bachelor’s degree in computer science, computer information systems, information technology, or a combination of education and experience equating to the U.S. equivalent of a Bachelor’s degree in one of the aforementioned subjects."
Big Data Engineer,Epsilon,"Chicago, IL 60601 (Loop area)",Posted 9 days ago,Full-time,https://www.indeed.com/rc/clk?jk=1564c7fdc7f1e531&fccid=beb2b679d6e2402e&vjs=3,"Job Description


Love cutting-edge tech? We do too.

 At Epsilon, we do more than collect and store data. We help some of the world's biggest brands discover real opportunities inside the data types, delimiters and decimals. For this opening, we're looking for an experienced 
 Big Data Engineer with extensive experience working with Spark or Scala in the big data ecosystem. 
 
 Our ideal candidate must be able to architect and lead teams, while also serving as a key contributor in delivering critical business features. On this team you will be a key contributor in troubleshooting complex production issues and delivering critical business features, making this a perfect role for those with a passion for big data technologies. 
 

What you'll do:


 Build and maintain data processing services
 Continuous improvement of our system, tests, and data quality indicators
 Influence our technical decisions
 Keep yourself informed and up-to-date with technologies
 Encourage the technical growth of your teammates
 Interface with analysts, data scientists, and engineers to enable data oriented solutions
 Build data expertise on subject matter and be able to speak to data warehouse constructs and data architecture.
 Our platform is ever evolving, but currently is a combination of Kafka, Flume, Spark, Scala, Java, Python, NoSQL (HBase, Cassandra and ScyllaDB), MPP RDBMS, Postgres, Hadoop, AWS, AirFlow, Docker and Kubernetes


 About you:


 Owns a problem to the end
 Proud to share in team's success
 Able to do your best work in a team setting and autonomously
 Wants to grow a career with a great company.


 What you'll bring:


 B.S. in Computer Science, Computer Engineering, or related field.
 At least five years of professional experience using Java, Scala, or Spark in project task's
 Ability to understand complex SQL and Python code is critical.
 Ability to troubleshoot production issues and solve for performance bottlenecks
 Expert level skills in data architecture (storage and usability)
 Ability to analyze data and identify business possibilities for better operational processes and business opportunities
 Excellent communication skills and ability to work with the internal analyst community
 Ability to thrive in a collaborative team environment
 You enjoy working with numerous programming languages, relational databases, and distributed systems.
 Internet/Digital Advertising ecosystem knowledge is a plus
 Kafka and Flume are a plus.


 Additional Information


When you're one of us, you get to run with the best. For decades, we've been helping marketers from the world's top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon's best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon has been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. Check out a few of these resources to learn more about what makes Epsilon so EPIC:
 

 Culture: https://www.epsilon.com/us/about-us/our-culture-epsilon
 DE&I: https://www.epsilon.com/us/about-us/diversity-equity-inclusion
 CSR: https://www.epsilon.com/us/about-us/corporate-social-responsibility
 Life at Epsilon: https://www.epsilon.com/us/about-us/epic-blog


 Great People Deserve Great Benefits

 We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.
 
 Epsilon is an Equal Opportunity Employer. Epsilon's policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories.
 
 Epsilon will provide accommodations to applicants needing accommodations to complete the application process.
 
 Applicants with criminal histories are welcome to apply.
 
 #LI-AM1
 
 REF184648E
 Company Description

 Epsilon is the leader in outcome-based marketing. We enable marketing that's built on proof, not promises. Through Epsilon PeopleCloud, the marketing platform for personalizing consumer journeys with performance transparency, Epsilon helps marketers anticipate, activate and prove measurable business outcomes. Powered by CORE ID®, the most accurate and stable identity management platform representing 200+ million people, Epsilon's award-winning data and technology is rooted in privacy by design and underpinned by powerful AI. With more than 50 years of experience in personalization and performance working with the world's top brands, agencies and publishers, Epsilon is a trusted partner leading CRM, digital media, loyalty and email programs. Positioned at the core of Publicis Groupe, Epsilon is a global company with over 8,500 employees in over 40 offices around the world.
 
 For more information, visit epsilon.com. Subscribe to us on YouTube at @EpsilonMktg."
Remote Data Engineer (Clearance Required),Deloitte,"Remote in Chicago, IL",Posted 28 days ago,Full-time,https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DIXU_djF9v0NrX_xbLRwj6RWFeuMEgTY6VvwKgvleOVKv2ag2Qg1tPUWJjUAFC1lcA-fJGonFnLZrmpDYDVUIhhD-RJWLpsoNofZSklM8F5vyzn1gHec83e5k4Q8Rle4Z0O2QFrOjtNiMRWZFhMhitDyUYH_dAmdTtJti2tF7qHmENGC2ajhF_DY26zBz9Rk4fhH1qYsEpn13xbDHw4un2lS9CDMvHeH5-YubSbMz2SwpxCqaN9kA1HodB0Yi8YiK_2xcHgfVB3b9256SaUs8m2QC8ZAfuCXEOJCRyuyVlQJooxpNhBqGJe35Thl88OebC5llRo146LhFrUW8afYPzZiVVmh99YUoHI0UnlDYoc03ljLloPoEeL6aevrvYh5xGmSZMj2Q0QWGhMnHGI8vDg-e-l9-NPwimAvrlP3IF7J214g5aKlPVciESYz3f08v9xVomtcypt3rMpXO1uzbLOCYsPn-J-24VNVtKRIa4ByH-Bca85s_0IJN-g7IrFX9T8_DVz3HS2ErEMxs8ANvPF-HFUUKbIj2503e92eZciQKL6PdNsOOMRlkhuq3_GREqunKNoDYGP2KFoDezQe8w&xkcb=SoDK-_M3MLy68vQdmp0GbzkdCdPP&p=13&fvj=0&vjs=3,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.
 

Work you'll do

 The Data Engineer will design future-state, modern data architecture for transformation at the enterprise level using advanced architectural principles. Using tools such as Snowflake and/or Databricks, they will also work with cutting-edge DevOps technologies, develop advanced analytics products, and apply data and statistical programming tools to enterprise data to advance and enable key mission outcomes within environments (GCP, AWS, Azure).
 

The team 

 Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.
 
 The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.
 
 Qualifications
 
 Required:
 


Minimum Active Top Secret Level Security Clearance



10+ years of professional experience in data engineering (SQL).



10+ years of experience designing and developing real time ETL architecture for real time predictive analytics.



5+ years of experience with Databricks, Snowflake, or AWS



Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field

 Preferred:
 


3+ years of relevant consulting or industry experience



Creativity and innovation - desire to learn and apply new technologies, products, and libraries



Prior professional services or federal consulting experience

 How you'll grow
 
 At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
 
 The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,000 to $181,000
 
 #LI-MG1"
Sr Big Data Engineer Designer,"Information Resources, Inc","Chicago, IL 60601 (Loop area)",Posted 28 days ago,"$110,000 a year",https://www.indeed.com/rc/clk?jk=13fe2ac26c9a0a9c&fccid=90e4e44116124fe2&vjs=3,"Let’s be unstoppable together!
 Circana (formerly IRI and NPD) is the leading advisor on the complexity of consumer behavior. Through unparalleled technology, advanced analytics, cross-industry data and deep expertise, we provide clarity that helps almost 7,000 of the world’s leading brands and retailers take action and unlock business growth. At Circana, we are fueled by our passion for continuous learning and growth, we seek and share feedback freely, and we celebrate victories both big and small in an environment that is flexible and accommodating to our work and personal lives. Join our inclusive, committed team to be a challenger, own outcomes, and stay curious together. Learn more at www.circana.com.
 At CIRCANA, we deliver growth to clients based on big data—our predictive analytics and forward-thinking insights help CPG, OTC, health care, retailers, and media companies remain relentlessly relevant, capture marketing share, connect with consumers, and deliver market-leading growth. The convergence of our proprietary, on-demand cloud-based technology and our client-focused colleagues leads to a seismic shift in drivers of success in all industries.
 For CIRCANA colleagues, we focus on the moments that matter. From meaningful work and impact to continuous improvement we challenge ourselves to grow both professionally and personally. You’ll feel a true sense of connection and purpose in your work and will craft the direction of your career in a highly personalized way. No matter the department you join, you’ll find yourself constantly growing and developing the skills of the future to deliver client growth. We believe in the undeniable strength that diverse people, culture, thought, and skill brings to our business, our clients, our people, and our communities. We are committed to nurturing a dynamic culture that embraces and celebrates growth, feedback, recognition, flexibility, belonging, and wellbeing for all.
 As a Sr Big Data Engineer Designer, you will be responsible for leading the development of client-specific implementations that will run in the client’s cloud environment leveraging the industry’s leading BI/Analytics solutions, Circana Liquid Data (LD). This is an end-to-end business intelligence solution that involves highly complex data transformations flowing into the LD Whitebox-powered data layer, and the LD Unify reporting application.
 You will interface with the client to understand requirements and translate the requirements into technical design. You will then manage and co-develop complex, fully automated data ingestion processes that meet the client's needs. You will also be responsible to debugging and resolving all the data issues that arises during the course of the project.
 Job Responsibilities

 Design the data loading pipeline which satisfies the business requirements and also extremely performant and fault tolerant
 Work with Product management team and client data ingestion teams to thoroughly understand all the datasets and ensure that it meets the business requirements
 Attend daily scrum calls with clients and provide feedback on the progress of all the data ingestion work
 Lead the offshore and onshore teams and explain the business requirements and design and ensure all data ingestion tasks are delivered on time
 Help the team in tuning the performance of the data ingestion jobs to ensure all jobs complete within the stipulated SLA time
 Co-develop all the complex data ingestion jobs and understand all the internal framework utilities and also build reusable code

Requirements

Bachelor of Science Degree in Computer Science, Data Analytics, or equivalent
 10+ years of Business intelligence industry experience
 5+ years of Big Data (Hadoop ecosystem) experience
 2+ years of experience leading client-facing projects
 Extensive experience in Linux or Unix OS Big Data scripting languages (Python, Spark, bash)
 Extensive experience aligning data from disparate sources with varying granularity
 2+ years of Azure cloud experience. Databricks experience is a plus
1+ years Amazon S3 experience
 Experience working with third-party job schedulers (Control-M, Airflow a plus)
 Eagerness to learn and adapt to evolving Hadoop tooling advancements
 Strong track record in kick-starting, executing, and advancing client-focused projects
 Experience leading offshore development teams
 Strong communication and leadership skills required

About Us As one of the original innovators in Big Data, CIRCANA integrates the world’s largest set of otherwise disconnected purchase, media, social, causal and loyalty data to help CPG, retail, over-the-counter health care and media companies grow their businesses. We combine this data with predictive analytics to uncover new consumer insights and integrate them on the most technologically advanced, cloud-based visualization platform. Learn more about us
 Our Benefits We offer a comprehensive benefit package (health, paid time off, 401(k), etc.) with additional unconventional offerings such as volunteer time off, flexible work arrangements, virtual doctor access, etc., along with the unrivaled benefit of working with our people - the best in the business.
 The below range reflects the range of possible compensation for this role at the time of this posting. We may ultimately pay more or less than the posted range. This range may be modified in the future. An employee’s position within the salary range will be based on several factors including, but not limited to, relevant education, qualifications, certifications, experience, skills, seniority, geographic location, performance, shift, travel requirements, sales or revenue-based metrics, any collective bargaining agreements, and business or organizational needs. The salary range for this role is $110,000.00 to $Y190,000.00.
 This job is also eligible for bonus pay.
 We offer a comprehensive package of benefits including paid time off, medical/dental/vision insurance and 401(k) to eligible employees.
 You can apply for this role through our Careers website link and/or Intranet site for internal candidates.

 Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
 The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Senior Data Engineer,The University of Chicago,"Chicago, IL 60637 (Woodlawn area)",Posted 6 days ago,Full-time,https://www.indeed.com/rc/clk?jk=32815a724015282d&fccid=5cb727313a823dd6&vjs=3,"Department
 
 F&A ITS - Business Intelligence Solutions
 
 About the Department
 
 IT Services collaborates with campus partners to support the mission of the University of Chicago through the consistent delivery of high-quality solutions and services.
 


We provide secure, stable, and reliable infrastructure and applications to support the mission of the University.
We support and enable faculty research and teaching with the effective use of technology.
We simplify the technology experience for faculty, students, alumni, and staff, and we ensure technology is mobile-friendly and accessible.
We identify, manage, and mitigate the technology risks of the University.


 Job Summary
 
 The Senior Data Engineer is the technical lead on projects to design, develop, and QA Data Warehouse (DW) and extract/transform/load (ETL) environments, and other database environments, to enable analytics. This role follows the prescribed project and development methodology. Under the direction of a Project Manager, this role will work closely with the Lead Architect, BI Lead, DW developers, source application developers, and subject matter experts (SMEs). The Senior Data Engineer will support, maintain, and enhance these environments to achieve a cross-functional, integrated reporting and analysis environment for University users.
 

   Responsibilities
 

 Works closely with business analysts and subject matter experts to understand data analysis requirements, data definitions, and to develop data mappings, data rules, and data transformations for reporting related to a particular data warehouse and/or analytic subject area.
 Finalizes the conceptual data models developed by the BI Lead, most often a dimensional model with facts and dimensions. Documents and communicates model design to project team.
 Leads development of logical data models. Documents, communicates, and maintains model design for the project team.
 Leads design and implementation of physical databases including index definitions, partitioning, parallelism, tuning, and space management.
 Utilizes database design and documentation tools to document, analyze, and communicate database information.
 Designs DW security.
 Implements test and QA strategies and prepares for rollout, including assuring data validation and integrity.
 Coordinates development resources to ensure that project timelines are met.
 Leads the design of ETL processing modules based on transformation rules, mapping rules, processing requirements and database model.
 Leads the design of ETL auditing steps to ensure data integrity and completeness of the ETL process.
 Leads the design of ETL process flow including module dependencies and parallel processing opportunities.
 Provides documentation for and works with job scheduling team to automate ETL processing.
 Leads the design of programming specifications for each ETL component.
 Leads the design of testing plans for each phase of the development process. Plans must ensure accuracy and quality of program code as well as thorough data validation procedures.
 Develops efficient code that meets analysis and design criteria.
 Coordinates ETL development resources to ensure that project timelines are met.
 Provides break/fix support and communicates outages as defined by IT Services standards.
 Troubleshoots and tunes DW and analytic systems.
 Coordinates testing of software patches and upgrades.
 Works closely with BIS colleagues to implement DW best practices, supporting integration of information from different subject areas.
 Promulgates DW, ETL and related development standards, processes, and best practices throughout BIS.
 Participates in the selection of DW, ETL and related enabling tools, including software and consulting.
 Deep expertise in DW, ETL and analytic systems best practices and emerging trends is imperative
 Works with users to ensure deliverables are meeting or exceeding expectations. Provides support and communicates issues to users as defined by IT standards.
 Plans, tests and guides roll-out of patches and upgrades to the BI and analytic software. Solves problems in the development and interpretation of BI and analytics system standards and procedures.
 Performs other related work as needed.


 Minimum Qualifications
 

 Education:
  Minimum requirements include a college or university degree in related field.
 
   -
   Work Experience:
  Minimum requirements include knowledge and skills developed through 5-7 years of work experience in a related job discipline.
 
   -
   Certifications:
 

   -
 


   Preferred Qualifications
 


   Education:
 

 Bachelor's degree.
 Advanced study or professional certifications in database, data management, DW, or ETL disciplines.



   Experience:
 

 Four years experience designing and building ETL using ODI.
 Four years experience designing and building Data Warehouse systems using Oracle and VPD.
 One year of experience building MuleSoft applications.
 Five to seven years of database and application development experience with a formal software development life cycle.
 Three years Hadoop experience with Cloudera Apache Hadoop Ecosystem (Nifi, Zeppelin, Oozie, Spark, Impala, Kafka, et al).
 A minimum of five years of data warehouse development experience including expert knowledge of data warehousing methodologies (e.g. Kimball).
 A minimum of four years of experience designing and building dimensional data warehouses with Oracle db, Oracle Stored Procedures and Packages.
 A minimum of four years or more designing and developing ETL processes for data warehouse implementations using Oracle OWB or equivalent ETL tools.
 Experience as lead DW/ETL designer on two successful enterprise data warehouse initiatives, using both formal software lifecycle development and project management.
 Two years experience working within the ITIL framework including incident, service, problem, and change management processes and procedures.



   Technical Skills or Knowledge:
 

 Programming environments, languages, and systems built using (Java, Python, R).
 AI/ML and predictive analytic algorithms.
 Knowledge of reporting and analytic systems based on current-generation ERP systems.
 Familiarity with Business Objects, Tableau or OBIA/OBIEE.
 Oracle Cloud Financials.
 Familiarity with higher education administrative systems and data.
 Working knowledge of Java Applications.
 Expertise with data query, analysis, reporting techniques, and OLAP.
 Expertise in Database Design and tools (e.g. Power Designer or Erwin).
 Expertise to develop and administer UNIX-based relational database architectures (ODBC, JDBC, Perl DBI, shell scripting, PL/SQL, SQL Developer, SQL Plus, SQL Loader, TOAD, Java).
 Expert skills in data profiling, source-target mapping, implementation of transformations and business rules.
 Superior ETL design and development skills including maps, process flows, auditing, and scheduling using vendor tools (OWB, ODI, Data Stage, or Informatica).
 Expertise in SQL coding techniques, performance monitoring and tuning.
 Working with Unix Server, and Windows Workstation and Server environments.
 Microsoft Office application suite, especially Excel.



   Preferred Competencies
 

 Excellent analytic skills to quickly synthesize technical, functional, and user inputs, and manage problem-solving to issue resolution.
 Leads joint design sessions, documenting the results using business process design tools.
 Strong oral and written communication skills, including developing standards and procedures, and presenting technical concepts to non-technical audiences.
 Commitment to working and sharing expertise in a collaborative team environment.
 Strong sense of accountability for completing work within defined scope and timeline, with ability to multi-task effectively.
 Very high attention to detail and accuracy.



   Working Conditions
 

 Standard office environment.
 On-call responsibilities.



   Application Documents
 

 Resume/CV (required)
 Cover Letter (required)









 When applying, the document(s) MUST be uploaded via the My Experience page, in the section titled Application Documents of the application.
        








 Job Family
 
 Information Technology
 
 Role Impact
 
 Individual Contributor
 
 FLSA Status
 
 Exempt
 
 Pay Frequency
 
 Monthly
 
 Scheduled Weekly Hours
 
 37.5
 
 Benefits Eligible
 
 Yes
 
 Drug Test Required
 
 No
 
 Health Screen Required
 
 No
 
 Motor Vehicle Record Inquiry Required
 
 No
 
 Posting Statement
 

 The University of Chicago is an 
  
   Affirmative Action/
  

   Equal Opportunity/Disabled/Veterans Employer
   and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the 
  
   University's Notice of Nondiscrimination.
  



 Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via 
  
   Applicant Inquiry Form.
  



 We seek a diverse pool of applicants who wish to join an academic community that places the highest value on rigorous inquiry and encourages a diversity of perspectives, experiences, groups of individuals, and ideas to inform and stimulate intellectual challenge, engagement, and exchange.
 


 All offers of employment are contingent upon a background check that includes a review of conviction history. A conviction does not automatically preclude University employment. Rather, the University considers conviction information on a case-by-case basis and assesses the nature of the offense, the circumstances surrounding it, the proximity in time of the conviction, and its relevance to the position.
 


 The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: 
  
   http://securityreport.uchicago.edu
  . Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637."
Sr. Data Engineer (Remote),Chamberlain Group,"Remote in Oak Brook, IL 60523",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=a610b156bb3cf745&fccid=969ac0c32a4ed39d&vjs=3,"Chamberlain Group is a global leader in access solutions with top brands, such as LiftMaster and Chamberlain, found in millions of homes, businesses, and communities worldwide.
 


   As a leader in the Smart Home industry, we boast one of the largest IoT install bases, with innovative products consisting of cameras, locks, card readers, garage door openers, gates and more, all powered by our myQ digital ecosystem.
 


   This role is responsible for providing technical expertise and leadership to design and deliver end-to-end data engineering solutions to support advanced analytics capabilities and drive innovation and decision-making
   across Chamberlain.
 


   Essential Duties and Responsibilities
 



     Build and maintain real-time and batch data pipelines across the advanced analytics platform.
   


     Design, develop and orchestrate highly robust and scalable ETL pipelines.
   


     Design and implement Dimensional and NoSQL data modelling as per the business requirements.
   


     Develop highly optimal codebase and perform Spark optimizations for Big Data use cases.
   


     Design, develop and deploy optimal monitoring and testing strategy for the data products.
   


     Collaborate with stakeholders and advanced analytics business partners to understand business needs and translate requirements into scalable data engineering solutions.
   


     Collaborate with data scientists to prepare data for model development and production.
   


     Collaborate with data visualization and reporting application developers to ensure the sustainability of production applications and reports.
   


     Collaborate with data architects on the enhancement of Chamberlain’s enterprise data architecture and platforms.
   


     Provide leadership to third-party contractors.
   


     Comply with health and safety guidelines and rules.
   


     Protect CGI’s reputation by keeping information confidential.
   


     Maintain professional and technical knowledge by attending educational workshops, professional publications, establishing personal networks, and participating in professional societies.
   



   Minimum Qualifications
 

   Education/Certifications:
 



     Bachelor’s degree in computer science or related quantitative field of study
   


   Experience:
 



     4+ years of professional experience
   


   Knowledge, Skills, and Abilities:
 



     Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic.
   


     Proficient in Spark or Databricks, Cloud Data Engineering Services preferably Azure, Streaming frameworks like Event Hubs or Kafka.
   


     Proficient in Microsoft Office.
   


     Familiarity with modern Machine Learning Operationalization techniques.
   


     Agile methodologies.
   


     Familiarity with Data visualization tools, such as Qlik or Power BI.
   



   Preferred Qualifications
 

   Education/Certifications:
 



     Master’s degree in computer science or related quantitative field of study
   


   Experience:
 



     4+ years of professional experience
   


     2+ years of professional experience delivering engineering for advanced analytics or data science solutions
   


   Knowledge, Skills, and Abilities:
 



     Agile methodologies
   


     Experience with IoT Data Architecture.
   


     Machine Learning Operationalization (MLOps) proficiency.
   


     REST API design and development.
   


     Proficiency with streaming design patterns.
   



 #LI-Hybrid
 


   We're an organization who values its human capital and provides support to assist its employees succeed.
 

 Chamberlain Group is proud to be an Equal Opportunity Employer. You will be considered for this position based upon your experience and education, without regard to race, color, religion, sex, national origin, age, sexual orientation, ancestry; marital, disabled or veteran status. We are committed to creating and maintaining a workforce environment that is free from any form of discriminations or harassment.
 


 Persons with disabilities who anticipate needing accommodations for any part of the application process may contact, in confidence 
  
   Recruiting@Chamberlain.com
  .
 

 NOTE: Staffing agencies, headhunters, recruiters, and/or placement agencies, please do not contact our hiring managers via email or phone or other methods."
Advanced Data Engineer,Wintrust Financial,"Hybrid remote in Rosemont, IL 60018",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=2c840ed6f587e4a2&fccid=bd3a202af4b1346d&vjs=3,"Wintrust is a financial holding company with approximately $50 billion assets under management and traded on the NASDAQ:WTFC. Built on the ""HAVE IT ALL"" model, Wintrust offers sophisticated technology and resources of a large bank while focusing on providing service-based community banking to each and every customer. Wintrust operates fifteen community bank subsidiaries with over 170 banking locations in the greater Chicago and southern Wisconsin market areas. Additionally, Wintrust operates various non-bank business units including commercial and life insurance premium financing, short-term accounts receivable financing, out-sourced administrative services, mortgage origination and purchase, wealth management services and qualified intermediary services for tax-deferred exchanges.

 Why join us?

 An award-winning culture! We are rated a Top Workplace by the Chicago Tribune (past 8 years) and Employee Recommended award by the Globe & Mail (past 6 years)
 Competitive pay and discretionary or incentive bonus eligible
 Comprehensive benefit package including medical, dental, vision, life, a 401k plan with a generous company match and tuition reimbursement to name a few


 Why join this team? 

We hold ourselves accountable to high standards, share wins, operate ethically, and have fun
 Data Management team members play a key part in the Wintrust Digital Journey supporting enterprise applications including CRM, Digital Banking, Account Opening Platform, LOS etc.


 Position Summary
 The Advanced Data Engineer is responsible for the design, development, test and implementation of best-in-class Data Processing solutions for the organization, including Data Modeling, Data Loading, Data delivery, Data availability, Performance and Security. This is an advanced role in Data Management – Data Architecture team and the ideal candidate will be engaged in all phases of the Data Enablement lifecycle, and will be called upon to mentor less experienced team members as necessary. Successful candidate will have a proven track record demonstrating in-depth technical and business knowledge.

 What You’ll Do

 Design, development and continuous improvement of complex data systems.
 Build processes supporting data transformations, data structures, metadata, dependency and workload management.
 Plan and execute unit test to ensure the developed code is free of functional defects.
 Design systems that reliably and efficiently provide interactive query performance on large amounts of multi-modal data.
 Ensure data governance policies are followed by implementing and validating data lineage, quality checks, classification etc.
 Support/enhance/create Daily/Monthly ETL/ELT processes to ensure business continuity, ensuring all related data pipelines meets best-in-class standards offering high performance.
 Support and maintain existing data solutions for DW, MDM and Middleware systems for operational and analytical applications.
 Implement DevOps for all Data Solutions, participates in all types of testing, including unit testing, p2p testing, end-to-end testing and UAT.
 Create enterprise data sets for analytics and data scientist team members for advanced analytics.
 Work in other areas of Data Enablement lifecycle, including batch and real time processes using SQL Server, SSIS ETL/ETL, as needed.
 Analyze the requirements and prepare technical specifications.
 Create Conceptual/Logical/Physical Data Models for all data solutions.
 Conduct research and provide technology solutions.
 Participate in code reviews.
 Support and guide junior team members.
 Serve as resource to internal and third-party team members on escalated issues and analyzing and designing specifications for less experienced team members.
 Pursue self-development and effective relationships with others by sharing resources, information, and knowledge with coworkers and customers.
 Seek opportunities to deliver continuous process improvement, automating manual processes and optimizing data delivery.


 Qualifications

 Bachelor’s degree with 5+ years’ experience in Computer Science, Engineering, Statistics, Mathematics, or other quantitative field.
 3+ years’ experience in programming and data analysis with a concentration in data analytics, data science, or related field.
 At least 4 years of experience in a Data Analyst role or similar where strong analytical and problem solving skills were required.
 3+ years working experience with statistical applications, such as SQL or SAS
 At least 2 years’ experience working with large data sets and complex databases
 Experience as a Data Analyst, in interpreting, analyzing and reconciling data obtained from variety of sources.
 Experience in preparing Functional Requirement document (FRD) based on business requirements, and data profiling and data analysis.
 Experience with working on Actimize Transaction Monitoring system, AML (Anti-Money Laundering) is a huge plus.
 Proficient in T-SQL development (complex queries, stored procedures and user defined functions) and performance tuning.
 Strong understanding of database and data warehouse concepts and structures.
 Has experience working with Data Warehouse, Data Governance, MDM and BI systems.
 Has experience building ETL pipelines to load data from various sources into DW.
 Strong quantitative skills with a proven ability to translate analysis into meaningful insights.
 Experience in working with Traditional and Distributed ecosystems.
 Proficient in Power BI and MS Office products (Excel, Word, PowerPoint including Pivot, Graph and Slicer techniques).


 #LI-HYBRID
 #LI-VB1

 From our first day in business, Wintrust has been proud to serve a variety of unique communities and people from all walks of life. To be Chicago’s Bank® and Wisconsin's Bank®, we need to reflect that diversity both in all the communities we serve, the people we employ, the organizations we work with, and our banking and lending practices. Wintrust Financial Corporation, including community banking and financial services subsidiaries, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran or any other characteristic protected by law."
Principal Data Engineer,Aspen Dental,"Chicago, IL 60607 (West Town area)",Posted 30+ days ago,"$147,000 - $195,000 a year",https://www.indeed.com/rc/clk?jk=fbfc4107ab8872de&fccid=8fbd2fb43ca6132e&vjs=3,"The Aspen Group (TAG) is one of the largest and most trusted retail healthcare business support organizations in the U.S. and has supported over 16,000 healthcare professionals and team members at more than 1,200 health and wellness offices across 46 states in four distinct categories: Dental care, urgent care, medical aesthetics, and animal health. Working in partnership with independent practice owners and clinicians, the team is united by a single purpose: to prove that healthcare can be better and smarter for everyone. TAG provides a comprehensive suite of centralized business support services that power the impact of five consumer-facing businesses: Aspen Dental, ClearChoice Dental Implant Centers, WellNow Urgent Care, Chapter Aesthetic Studio, and AZPetVet. Each brand has access to a deep community of experts, tools and resources to grow their practices, and an unwavering commitment to delivering high-quality consumer healthcare experiences at scale.

 Our continued growth has created an opportunity to join our as Principal Data Engineer.

 As a principal data engineer, you will join one of our teams focused on helping data scientist architect and deploy AI models. You will also work alongside developers modernizing our legacy systems by developing new services using cloud-native GCP technologies.

 Responsibilities

 Architect and build core components of the Machine Learning Platform infrastructure
 Work multi-functionally with data scientists, data engineers, IT teams, and business partners to design, develop, deploy, and integrate high-performance machine learning solutions and data intensive workflows
 Partner with data scientists and data engineers to build high-performance, efficient feature pipelines from backend data sources to train models and serve features to machine learning applications
 Partner with data platform and operations teams to solve complex data ingestion, pipeline, and governance problems for machine learning solutions
 Partner with Business Teams to understand workflow and implement optimized solutions.
 Take ownership of production systems with a focus on delivery, continuous integration, and automation of machine learning workloads
 Provide technical mentorship, guidance, and quality-focused code review to data scientists and engineers.


 Experience

 Technical education in Computer Science, Data Science, Engineering, or equivalent experience (Master’s degree or higher preferred)
 5+ years of Data Engineering experience (ML-focused highly preferred)
 1+ years of experience developing cloud-native solutions (GCP preferred)
 Familiarity with the practical aspects of machine learning and experience with common technologies and frameworks such as pandas, NumPy, PyTorch, TensorFlow, Spark, scikit-learn.
 Strong experience with Java, Python or other object oriented programming language.
 Strong desire to learn new technologies and stay aligned with the latest developments in the machine learning engineering community.
 Experience building real-time stream processing solutions with technologies such as Kafka, Flink, and Spark a bonus
 Experience with Kubernetes a bonus

 Salary: $147,000 - 195,000
 If you are an applicant residing in California, please view our privacy policy here:
 https://careers.aspendental.com/us/en/tag-privacy-policy-for-california-employees"
Data Science & Technology Integration - Engineer,Allstate,"Chicago, IL",Posted 30+ days ago,"$113,400 - $156,150 a year",https://www.indeed.com/rc/clk?jk=95894d7e94a7b669&fccid=3a71a4d2f7990a25&vjs=3,"The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.

 You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.

 Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For more than 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection.

 We are the Good Hands. We don’t follow the trends. We set them.



 Job Summary:



 This position is on the Modeling & Major Initiatives team within Pricing Analytics & Actuarial Services, and is responsible for delivering technical expertise, education, and solutions at the intersection of actuarial, data science, and technology in support of the teams developing Allstate’s insurance pricing solutions. This includes a strong foundation in contemporary actuarial and data science techniques, and an in-depth knowledge of current and emerging technologies supporting analytics, to discover innovative ways to drive efficiency, automation, and accessible advanced capabilities for predictive modeling, data engineering, and actuarial pricing teams. The role works closely with leadership and analysts on actuarial, data science, and technology platform teams to develop, execute, and support innovative solutions to bridge the gap between technology and analytics.





 Key Responsibilities:




 Develops, stays up to date with, and continuously seeks to improve a deep understanding of the following in the context of possible applications in the system of pricing workflows:
       
 Analytical techniques (predictive algorithms, actuarial methodologies, geospatial, machine learning, optimization)
 Analytical software/programming languages (R, Python, Spark, SQL, H2O, XGBoost, Shiny, other emerging software)
 Technology infrastructure (linux, k8s, docker, computing techniques, CICD)

 Establishes and implements best practices, processes, documentation, and education for efficient onboarding, application, and automation of analytical technologies in pricing teams
 Delivers customized technical support and develops tailored tools/solutions to address unique needs of pricing users
 Engages with and actively supports actuarial and data science teams, leveraging subject matter expertise to advocate for their needs in collaboration with technology teams on platform solutions and future capabilities
 Works closely with technology teams to enhance platform capabilities, drive efficiencies, and resolve issues through effective communication and collaboration
 Foresees and addresses potential risks in future platform changes, using systems thinking to develop and execute mitigation strategies, ensuring seamless pricing operations and analytics
 Ensures compliance with professional standards, regulatory requirements, and company policies related to the use of technology in pricing
 Leads the pricing department through technology transitions by managing a team of analysts responsible for supporting analytical technology use, developing customized solutions and education, enhancing user efficiency and capabilities, and adapting to evolving technological landscapes
 Fosters a culture of curiosity, innovation, knowledge sharing, continuous improvement, and servant leadership within team and across the department


 Supervisory Responsibilities:

 This job does not immediately have supervisory responsibilities but will in the future






 Preferred Qualifications:



 Education and Experience

 Bachelor’s degree in a related field of study such as math/applied math, statistics/applied statistics, computer science/network engineering. Master’s degree is preferred.
 5+ years of related experience within the fields of data science/analytics and technology


 Certificates, Licenses, Registrations

 None


 Functional Skills

 Technical proficiency in data science and/or data engineering tools: R, Python, SQL, Spark, Bash
 Background in or capability to develop an understanding of technology infrastructure (compute frameworks, servers and networking, virtualization)
 Problem-solving and analytical skills, with a systems thinking approach to identifying opportunities for optimizing workflows and improving efficiency through technology integration, while considering the interdependencies and potential impact on the broader organizational ecosystem
 Advanced project management skills to independently handle concurrent high complexity projects, sometimes across multiple-year time horizons
 Advanced communication skills, including the ability to effectively communicate and translate across varied disciplines and organizational levels, with a focus on conveying complex technical topics in an understandable manner
 Adaptable mindset with the ability to navigate and excel in both tactical and strategic situations, considering existing constraints while pushing boundaries to achieve innovative and forward-thinking solutions for the organization
 Strong leadership skills with the ability to mentor, motivate, and develop a team of analysts, fostering a culture of collaboration, innovation, and continuous improvement





 Compensation offered for this role is $113,400.00-$156,150.00 per year and is based on experience and qualifications.
 The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

 Good Work. Good Life. Good Hands®.

 As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life - including a generous paid time off policy. For a full description of Allstate’s benefits, visit allstate.jobs/benefits/

 Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

 Allstate generally does not sponsor individuals for employment-based visas for this position.

 #LI-JB1

 Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

 For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance. For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

 To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs

 To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.

 It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment."
Senior Data Engineer I,Kirkland and Ellis,"Hybrid remote in Chicago, IL 60654",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=087f42c1c85a2834&fccid=ab6107103bdfe9b4&vjs=3,"About Kirkland & Ellis 
At Kirkland & Ellis, we are united in our ambition and drive to move forward. We share core values that help us achieve excellence: collaboration, talent empowerment, service, inclusion, respect and gratitude. Our people are our greatest asset, and we invest in the brightest talent and encourage a diversity of perspectives and strengths to create dynamic teams that operate at the pinnacle of their field. Our talented professionals show up every day knowing they will engage in meaningful work, continuous learning and professional development.  As one of the world's leading law firms, we serve a broad range of clients with market-leading practices in private equity, M&A and other complex corporate transactions; investment fund formation and management; restructurings; high-stakes litigation and trials; and government, regulatory and internal investigations. We handle the most complicated and sophisticated legal matters because we don't just meet industry standards, we create them. We bring innovation and entrepreneurialism to every engagement and, as a result, have long-standing client relationships with leading global corporations and financial sponsors. With 6,500 employees (including 3,500+ lawyers) operating from 19 offices across the United States, Europe and Asia, we are one of the largest law firms in the world and a top financial performer.
 Essential Job Functions 

Owns and drives Kirkland & Ellis data integration solutions in terms of design, build and deployment, DevOps with best-in-class data models, data quality and data architecture standards 
Possesses strong data capabilities in terms of data analysis, data models, and hands on expertise in crafting and deploying data pipes using Azure data platform and tools, as well as enterprise ETL tool Talend, leveraging its DQ, DI and Data Catalogue features. 

Essential Functions: (This list is not exhaustive and may be supplemented and changed as necessary.)

 Accountable for the technical leadership regarding the data integration solutions and delivery. Ensuring a sound and best in class design, with enterprise implementation, deployment and operational meets the technical quality standards
 Responsible for planning and coordinating in carving out the needed dev/test environments, as well as defining and managing code branching/config strategies supporting concurrent releases 
Works with Data and Enterprise architecture team to define the data integration design/coding/deployment/operational standards and technology stack
 Responsible for data operations, in terms of scheduling, successful execution, and reconciliation of the data pipes in production 
Works collaboratively with other dev teams to guide and review their deliverables against the set standards 
Works collaboratively with Data Analytics, applications, DBA, and cloud operations teams to ensure end to end integrity and usage of data assets. 
Provides inputs in shaping K&E DevOps and DataOps practices
 Partners with internal and external data experts to infuse innovation with focus on cross training and upskilling the existing teams. 

Other Functions: (This list is not exhaustive and may be supplemented and changed as necessary. Delete if not applicable.) 
Fosters and promotes heathy working relationships across the board to propagate end-to-end value of data
 Qualifications & Requirements 
Education, Work Experience, Skills:

 Bachelor's degree in data, computer science or relevant discipline.
 8+ years of experience in ETL, ELT and data engineering 
At least 3+ years of working experience on Azure data platforms
 Experience working in agile delivery, Jira usage and other agile delivery best practices
 Data architecture, Data Modeling, and data visualization experience is a plus
 Ability to interact with business, other teams to create data mapping documents, ETL architecture/design artifacts, performance improvements, improve delivery & operational excellence.

 Technologies/Software

 8+ years of end-to-end implementation experience of deploying enterprise data warehouse, data mart and data lake solutions
 3+ years of working experience with Azure data solutions including but not limited to ADLS, Data Bricks, ADF, Synapse etc 
Azure ADLS/Databricks administration experience 
5+ years of Implementation and maintenance experience with Talend DI, DQ capabilities 
Demonstrable understanding of Data Governance, and enabling technical tools and technologies 

Certificates, Licensures, Registrations:

 Certification in Azure cloud stack, Talend Data Integration Certified Administrator/Developer will be a plus 

How to Apply 
Thank you for your interest in Kirkland & Ellis LLP. To complete an application and submit your resume, please click ""Apply Now.""
 Equal Employment Opportunity 
All employment decisions, including the recruiting, hiring, placement, training availability, promotion, compensation, evaluation, disciplinary actions, and termination of employment (if necessary) are made without regard to the employee's race, color, creed, religion, sex, pregnancy or childbirth, personal appearance, family responsibilities, sexual orientation or preference, gender identity, political affiliation, source of income, place of residence, national or ethnic origin, ancestry, age, marital status, military veteran status, unfavorable discharge from military service, physical or mental disability, or on any other basis prohibited by applicable law.
 Closing Statement 
The www.kirkland.com job postings and recruiting mailbox are for candidates only. If you are a recruiter, search firm or employment agency, and do not have a signed contract with Kirkland & Ellis LLP (""K&E"") and have not been asked specifically to submit candidates, you will not be compensated in any way for your referral of a candidate even if K&E hires the candidate. Direct contact with K&E employees in an attempt to present candidates is inappropriate and will be a factor in determining any future professional relationship with the Firm. #LI-Hybrid #LI-LC1"
Python Software Engineer (Data Driven Platforms),Egen Solutions,"Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=c92472a25e3fc18d&fccid=85e9354e0dd85c02&vjs=3,"Egen is a data engineering and cloud modernization firm helping industry-leading companies achieve digital breakthroughs and deliver for the future, today. We are catalysts for change who create digital breakthroughs at warp speed. Our teams of cloud and data engineering experts are trusted by top clients in pursuit of the extraordinary. An Inc. 5000 Fastest Growing Company 7 times, and recently recognized on the Crain’s Chicago Business Fast 50 list, Egen has also been recognized as a great place to work 3 times.
  


 Our Python Cloud Application team tech stack is based on Python (Flask) and RESTful web services. We typically build and deploy applications as microservices in cloud-native environments (GCP, AWS, or Azure) and integrate with scalable technologies such as Kafka in Docker-based container environments. Our developers work in an agile process to efficiently deliver high-value applications and product packages.
  




 Required Experience:


 Have contributed to technical analysis & design, evaluating tradeoffs, and incorporated best practices
 Have solved challenging software problems through data-driven, iterative software development
 Built distributed and event-based products and applications and understand their challenges and rewards.
 Built and run scalable resilient cloud-native data pipelines and microservices in production.
 You value the importance of defining data contracts and have experience writing specifications including REST APIs.
 Cloud Environments: GCP (preferred), AWS, or Azure
 An established background working in fast-paced agile environments and comfortable iterating quickly.






Nice to have's (but not required)


 Strong understanding and production experience of microservice architecture.
 Strong understanding and production experience working with Docker container environments
 Strong understanding and production experience working with Kafka 
Experience or exposure to frontend (React Javascript) development in addition to your backend Python experience."
DATA ENGINEER-JAVA API,"Hyatt Corporate Office, Chicago","Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=886696ac2a6561cd&fccid=dd616958bd9ddc12&vjs=3,N/A
Senior Data Engineer (Remote),Enova International,"Remote in Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=11f383f0c2e1f86f&fccid=da5a2426fca0c292&vjs=3,"We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas or take over sponsorship at this time.
 Enova is currently accepting candidates for remote positions in the following eligible states: AL, AK, AR, AZ, CT, GA, IA, ID, IL, IN, KY, LA, MA, ME, MD, MN, MO, MS, NC, ND, NE, NH, NV, NJ, NM, OH, OK, OR, PA, RI, SC, SD, TN, UT, VT, WI, WV, WY.
 About the role:
 The Data Services Team builds data strategy and provides data solutions across the organization. We integrate, transform, and improve volumes of data at the project or enterprise level for streamlined processes, greater efficiencies, and smarter, more informed decision-making. This team is eager, dynamic and in a business-critical domain space. This role is an opportunity to make a difference in the data space, and we need experienced people eager to bring in solutions, and make that happen.
 Responsibilities:

Support the data needs of Software Engineering, Strategy, Product, Compliance, Operations, Technology and Analytics teams
Opportunity to lead technical projects by architecting the solution and collaborating with team members and peers to implement the solution
Architect, implement and maintaining multi-layered SQL and Python processes
Enhance the tooling and Python Frameworks to support complex Extract Transform Load (ETL) or Extract Load Transform (ELT) processes
Troubleshoot discrepancies in existing databases, data pipelines, warehouses, and reporting
Work as a ""full-stack"" Data Engineer contributing to each phase of the SDLC, building a new pipeline between two data sources or working with the business to design and develop a new dashboard

Requirements:

3+ years of experience in data engineering with a focus on database related technologies
1+ years of hands-on experience working with Python and object-oriented programming methodologies and design patterns.
Hands-on experience of SQL and database related technologies, particularly PostgreSQL.
2+ years of experience working with Cloud Data Warehouse Technologies such as Snowflake or Redshift.
Experience working with AWS RDS, Aurora, Lambda, S3, Apache Kafka is desirable.
Experience with relational database modeling principles and techniques.
Exposure to architecting, designing, and implementing ETL or ELT solutions with peers and stakeholders.
Experience with ANSI SQL, SQL Server, Talend, Jenkins, GIT, Pentaho, JavaScript, bash/Linux, various non-relational / NoSQL database management systems.
Ability to work off-hours as needed

#BI-Remote

 Benefits & Perks:

Flexible work schedule (In-office T/W/Th and remote M/F for hybrid-eligible roles)
Health, dental, and vision insurance including mental health benefits
401(k) matching plus a ROTH option (U.S. Based employees only)
PTO & paid holidays off
Sabbatical program (for eligible roles)
Summer hours (for eligible roles)
Paid parental leave
DEI groups (B.L.A.C.K. @ Enova, HOLA @ Enova, Women @ Enova, Pride @ Enova, South Asians @ Enova, APEX @ Enova, and Parents @ Enova)
Employee recognition and rewards program
Charitable matching and a paid volunteer day…Plus so much more!

About Enova
 Enova International is a leading financial technology company that provides online financial services through our AI and machine learning-powered Colossus™platform. We serve non-prime consumers and businesses alike, while offering world-class technology and services to traditional banks—in order to create accessible credit for millions.
 Being a values-driven organization is at the core of Enova's success. We live our values by listening to our customers, challenging assumptions, thinking big, setting high expectations, and hiring and developing the best. Through our values and our commitment to making Enova an awesome place to work, we maintain an environment of inclusion and culture where our employees can thrive. You can learn more about Enova's values and culture here.
 It is our policy to provide equal employment opportunity for all persons and not discriminate in employment decisions by placing the most qualified person in each job, without regard to any other classification protected by federal, state, or local law. California Applicants: Click here to review our California Privacy Policy for Job Applicants."
Data Center Critical Facility Engineer,Equinix,"Elk Grove Village, IL 60007",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=c14c5e484a72485a&fccid=e15d9e27876d9dc3&vjs=3,"Data Center Critical Facility Engineer
  Equinix is the world’s digital infrastructure company, operating 245+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, complex infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.

 We are a fast-growing global company with 70+ quarters of growth. Through our innovative portfolio of high-performance products and services, we have created the largest, most active global ecosystem of 10,000+ companies, including 2,000+ networks and 3,000 cloud and IT service providers in 32 countries spanning six continents.

 Joining our operations team means that you will be at the forefront of all we do, maintaining critical facilities infrastructure as part of a close-knit team delivering best-in-class service to our data center customers. We embrace diversity in thought and contribution and are committed to providing an equitable work environment. that is foundational to our core values as a company and is vital to our success.

 Job Summary
 Data Centers are considered Critical Facilities. This means that we support hospitals, laboratories, public safety centers. Simply put - We cannot go dark. In this crucial role, you will complete repairs, corrective maintenance, and routine installations of Critical Facility infrastructure.

 Responsibilities

 You will perform site inspections and supervise the building and Data Center alarms
 Performs preventative maintenance of on-site infrastructure (e.g. maintenance of primary infrastructures), or leads vendors
 Undertake repairs and corrective maintenance
 Extensive knowledge of critical infrastructure i.e. UPS, generator, BMS, chillers, life safety systems
 Completion of site logs and data gathering issuing for basic permits, such as MOPs and scripts
 Respond to all on-site incidents and acts as the need arises
 Completes routine work requests and circuit installations
 Provide assistance during critical maintenance activities
 You are able to effectively collaborate within the department and provide recommendations to peers for general maintenance activities
 Carry out basic infrastructure projects
 24/7 Operation - Your flexibility to work any assigned shift, off-schedule, workmate, respond to emergencies, etc.


 Qualifications

 A natural curiosity and strong troubleshooting skills
 Experience working in a critical facility
 Strong system-level mechanical or electrical proficiency
 You are capable of lifting up to 50 lbs. and are agile in manual dexterity (climb, stoop, et.) with or without an accommodation.
 3+ years' experience


 Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you need assistance in applying for an open position, you may send an email to Staffing@equinix.com. Please provide your contact information and let us know how we can assist you.

 Equinix is an Equal Employment Opportunity and Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to unlawful consideration of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy / childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political / organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law. (Equal Opportunity / AA / Disabled / Veterans Employer)."
"Senior Software Engineer, Data Engineering",S&P Global,"Chicago, IL 60602 (Loop area)",Posted 30+ days ago,"$68,300 - $140,000 a year",https://www.indeed.com/rc/clk?jk=eaffff33a6ce21e1&fccid=b716e44d2c6283e7&vjs=3,"The Role: Data Engineer 

Location: Team is in Boston, but is available for remote or on-site throughout the US. 

GL (for internal use only): 10 

 Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe. 

 Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy! 
Job Description 
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment. 

 You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets. 

 You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use. 
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry. 

 Responsibilities 
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets 
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models 
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers 
Optimizing slow-running database queries and data pipelines 
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently 
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency 
Qualifications 
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience 
4+ years of experience working with data-at-scale in a production environment 
Experience designing and implementing large-scale, distributed systems 
Experience in multi-threaded software development (or some form of parallelism) 
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.) 
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale 
Strong understanding of relational databases and proficiency with SQL 
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript) 
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go) 
Experience developing software on Linux-based operating systems 
Experience with distributed version control systems 
Nice-to-Haves 
Familiarity with relational database internals (especially PostgreSQL) 
Proficiency with cloud computing platforms, specifically AWS 
Working knowledge of probability & statistics 
Contributions to open-source software 
Experience building customer-centric products 


Compensation/Benefits Information:
 S&P Global states that the anticipated base salary range for this position is $68,300 to $140,000 . Base salary ranges may vary by geographic location. 
This role is eligible to receive S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires . 

 About S&P Global 
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. 

 S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work. 
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. 

 ----------------------------------------------------------- 

 Equal Opportunity Employer 
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. 

 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. 


US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 

 ----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning) 


Job ID: 266145 

Posted On: 2023-05-25 

Location: Cambridge, Massachusetts, United States"
Data Loss Prevention Engineer,Gallagher,"Rolling Meadows, IL 60008",PostedToday,Full-time,https://www.indeed.com/rc/clk?jk=cfa297e53e5febf5&fccid=e082683e6e0bb617&vjs=3,"About Us: 
 
   Gallagher is a global leader in insurance, risk management and consulting services. We help businesses grow, communities thrive and people prosper. We live a culture defined by The Gallagher Way, our set of shared values and guiding tenets. A culture driven by our people, over 45,000 strong, serving our clients with customized solutions that will protect them and fuel their futures.
 




  At Gallagher, you can build a career whether it’s with our brokerage division, our benefits and HR consulting division, or our corporate team. 
 Overview: 
  Role Description:
 Gallagher Information Security is seeking a highly skilled and motivated Microsoft Cloud and Purview Engineer to join our dynamic team. The engineer will help protect Gallagher sensitive information by supporting the design, implementation, administration, and troubleshooting utilizing Microsoft Azure and Purview technologies. The individual in this role will mature the Data Security Programs use of technologies including telemetry, alerting, and response management. Responsibilities: 
  Responsibilities:

 Design, deploy, and configure Data Loss Prevention/Protection technologies
 Collaborate and partner with key stakeholders to understand DLP requirements and translate into technical requirements
 Manage improvements for policies and their implementation for enterprise-wide Data Loss Prevention (DLP) solutions
 Performs testing (including walkthroughs), takes ownership to complete clear and well-organized assessments for the policies in DLP framework
 Troubleshoot and Support operational issues associated with Data Protection technologies and associated process
 Provide Data Protection Consulting on translating business requests to protect sensitive data into practical technical solutions and configurations
 Evaluating and testing of new data protection technologies
 Support DLP capabilities in M365 and other third party DLP solutions
 Create run books , procedure documents, and standard operating procedures
 Take responsibility for deployment, integration, and configuration of DLP solutions to protect sensitive data
 Follow technical protocols defined be senior engineers and leaders to effectively deliver on tasks
 Analyze, Develop, and Report on technical variances based on Data Security health monitoring processes
 Engage with senior engineers to learn about implementing new technologies and capabilities
 Research and consult publicly available information sources to deliver on assignments
 Produce and maintain technical documentation associated with assignments to enhance the overall knowledge of Security Engineering team
 Keep up to date with new features and functions around Data protection technologies
 Assist with audits and gap analysis
 Collaborate with cross-functional teams to gather requirements and design scalable, secure, and reliable cloud-based solutions on the Microsoft Azure platform.
 Implement cloud security best practices, conduct regular security assessments, and ensure compliance with industry standards and company policies.
 Stay up-to-date with the latest Microsoft Azure and Purview offerings, emerging technologies, and industry trends. Recommend and implement improvements to enhance system performance and efficiency.


 Qualifications: 
  Requirement:

 Hands-on experience building, developing, and testing DLP policies both on premise and cloud
 Experience deploying and operating systems in Azure, AWS and/or GCP
 Bachelor Degree with minimum 5 years of experience
 4-6 years substantive experience as a DLP administrator/engineer
 Knowledge of HIPAA, PCI, SOX, ISO27000 and NIST Cybersecurity Frameworks
 Familiarity with networks and enterprise architecture
 Familiarity with encryption products
 Detailed oriented and ability to work in collaborative team environments
 Strong ability to multi-task and manage varying priorities and projects
 Excellent interpersonal, verbal, and written communication skills with the ability to communicate security risk and compliance related concepts to a broad range of technical and non-technical staff
 Ability to successfully interact with non-technical business contacts
 Familiarity with data classification concepts and processes
 Experienced in a wide variety of technical solutions focused on data protection and cyber security
 Experience with data loss prevention, encryption, document labeling and/or data discovery products


 Desired Skills:

 Bachelor’s degree in Computer Science or Computer Information Systems or related
 CCSP, CySA+, CASP+ or CISSP certifications
 Understanding of data query tools and techniques
 4 years of experience in an information security discipline



 #LI-NP1
  Additional Information: 
 
   Click Here to review our U.S. Eligibility Requirements
 


 We offer competitive salaries and benefits, including: medical/dental/vision plans, life and accident insurance, 401(K), employee stock purchase plan, educational expense reimbursement, employee assistance program, flexible work hours (availability varies by office and job function), training programs, matching gift program, and more."
Financial Applications Data Engineer,Mayer Brown LLP,"Chicago, IL 60606 (The Loop area)",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=860bbd16c7449a24&fccid=608e732c8fd8b5ce&vjs=3,"Overview: 
 
   Mayer Brown LLP is a leading global law firm with offices in 27 key business centers across the Americas, Asia, Europe and the Middle East. We are a collegial, collaborative, and diverse firm where highly motivated individuals with an unwavering commitment to excellence receive the opportunity, support, and development they need to grow, thrive, and realize their greatest potential.
 


 If you enjoy working with team members whose defining characteristics are achievement, initiative, professionalism, responsiveness, and adaptability, you may be the person we are seeking to join our Information technology department in our Chicago office as the Financial Applications Data Engineer.
 

 The Financial Applications Data Engineeris responsible for the support and development of the Finance & Accounting department’s data analysis, dashboarding & reporting needs. The Data Engineer will move and transform data so that it can be easily analyzed, visualized and worked upon by the business user community. They will guide both business and technical users through the process of identifying and locating the data they need to solve their business needs and to ensure that the users are able to securely access that data. The Data Engineer will partner with existing analytic & reporting Finance & Accounting staff.

 Responsibilities: 
  Essential Functions:

 Rapidly builds and maintains an understanding of the firm’s “data landscape” – the key systems and databases used across the firm, how they are used, their data, data models and data integrations, with a specific focus on Finance & Accounting data
 Works with the Data Architecture team, develops scalable, reliable pipelines and ETL processes to manage the flow of data into, out of, and between these systems in order to:
   
 Acquire and feed systems with the data they require
 Maintain data cleanliness and accuracy
 Join and relate data from disparate systems
 Prepare data for modelling, reporting, visualization and analysis
 Generate a variety of reporting outputs, leveraging Microsoft Power BI and other tools

 Works with our Enterprise Data Architect in the design and implementation of new data models that may pertain to Finance & Accounting
 Designs and build sSQL queries, views, functions and stored procedures
 Develops and implements various Finance & Accounting and related dashboards
 Provides technical assistance and guidance to others, both within and outside of IT, helping them to locate and access the data they need
 Works with our Enterprise Data Architect and Data Engineers in other functions to build a strong community of expertise that supports the development and delivery of the firm’s data strategy
 Designs, builds and tests data structures and reporting process/systems
 Accountable for software support related to department’s customized or packaged financial applications
 Participates in rotational 24 x 7 application support ensuring that the application portfolio uptime is maintained according to defined SLA’s
 Participates in the evaluation of new financial products/applications deemed to be appropriate for the Firm’s business
 Develops and reviews data design, interface, user, functional and technical design documentation 
Performs relevant support for financial applications supported by the Firm


 Qualifications: 
 
 Education/Training/Certifications:


Bachelor’s degree in Computer Sciences. An equivalent combination of education and/or experience may be considered in lieu of the degree when the experience has been directly related to the functions of the job
 Data engineering certifications (e.g. Azure Certified Data Engineer) are a plus



 Professional Experience:


 Minimum 2 year previous professional experience as a Data Analyst or similar role required
 Experience working with organizational data warehouses, including the creation and management of the data residing within them required
 Experience developing relationships with key business stakeholders to understand business requirements and support the adoption of new data and reporting solutions



 Technical Skills:


 Proficiency in Microsoft Office products
 Experience with Enterprise Relational Database Technologies, including but not limited to:
   
 Microsoft SQL Server (on-premises)
 Azure SQL (cloud)

 Experience with Enterprise Data Management Technologies, including but not limited to:
   
 Microsoft SQL Server Integration Services (SSIS)
 Microsoft SQL Server Reporting Services (SSRS)Microsoft Power Platform experience
 Experience with Enterprise Data Warehousing Technologies, including but not limited to:
 Azure SQL Data Warehouse / Azure Dedicated Pools
 Iridium Dashboards experience a plus
 Cognos Analytics experience a plus




 Performance Traits
: 


Strong written and verbal communication skills, able to communicate effectively and in a professional manner with all levels of the Firm and outside vendors
 Strong analytical and problem-solving skills with an ability to investigate and assess complex systems to propose technical solutions
 Strong organization and time management skills, priority-setting, and troubleshooting, especially when responding to unanticipated business requirements
 Ability to work in a diverse team environment and effectively support the demanding needs of the Firm
 Able to effectively communicate and influence others outside the direct chain of reporting
 Ability to work under pressure, meet deadlines with shifting priorities
 Must be a self-starter with a high level of initiative
 Strong customer service skills, able to anticipate needs and exercise independent judgment
 Strong attention to detail, organizational skills and the ability to handle multiple projects 
Maintains confidentiality and exercises discretion
 Willing to challenge the status quo



 Physical Requirements:


May require occasional lifting of up to 20 lbs.
 May require travel to other offices as needed



 The above is a general description of the essential duties associated with this position and does not represent an exhaustive or comprehensive list of all duties.
 


 The Firm may modify and amend this job description at any time at its sole discretion. Nothing herein creates a contract of employment or otherwise modifies the at-will nature of employment.
 


 We offer competitive compensation and comprehensive benefits, including medical/dental/vision/life/and AD&D insurance, 401 (k) savings plan, back-up childcare and eldercare, generous paid time off (PTO), as well as opportunities for professional development and growth. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran."
Distinguished Data Engineer,Capital One,"Chicago, IL",Posted 6 days ago,,https://www.indeed.com/rc/clk?jk=fb89790409b672c2&fccid=b85c5070c3d3d8c8&vjs=3,"Locations: Sales - IL - Chicago, United States of America, Chicago, Illinois
  Distinguished Data Engineer
 



















 Distinguished Engineers are individual contributors who strive to be diverse in thought so we visualize the problem space. At Capital One, we believe diversity of thought strengthens our ability to influence, collaborate and provide the most innovative solutions across organizational boundaries. Distinguished Engineers will significantly impact our trajectory and devise clear roadmaps to deliver next generation technology solutions.

 Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices
 Thorough knowledge of software engineering and data engineering best practices, patterns, modern architecture practices
 Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates
 Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community
 Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities


 Responsibilities:

 Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in
 Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team
 Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible
 Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization
 Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner
 Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent


 Basic Qualifications:

 Bachelor’s Degree
 At least 7 years of experience in Data Engineering

 Preferred Qualifications:

 Masters’ Degree
 9+ years of experience in Data Architecture
 9+ years of experience in creating production applications (Java, Scala, Python, Apache Spark, Snowflake, Kafka, Rest APIs, microservices, CICD, Jenkins, AWS solutions)
 9+ years of experience in software engineering or data engineering best practices, patterns and modern architecture practices.


 Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.




















 Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
 No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
 
 If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

 For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

 Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

 Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC)."
Data Engineer,Aspen Dental,"Chicago, IL 60607 (West Town area)",Posted 14 days ago,Full-time,https://www.indeed.com/rc/clk?jk=5036e2b3aa4f5fba&fccid=8fbd2fb43ca6132e&vjs=3,"The Aspen Group (TAG) is one of the largest and most trusted retail healthcare business support organizations in the U.S. and has supported over 16,000 healthcare professionals and team members at more than 1,200 health and wellness offices across 46 states in four distinct categories: Dental care, urgent care, medical aesthetics, and animal health. Working in partnership with independent practice owners and clinicians, the team is united by a single purpose: to prove that healthcare can be better and smarter for everyone. TAG provides a comprehensive suite of centralized business support services that power the impact of five consumer-facing businesses: Aspen Dental, ClearChoice Dental Implant Centers, WellNow Urgent Care, Chapter Aesthetic Studio, and AZPetVet. Each brand has access to a deep community of experts, tools and resources to grow their practices, and an unwavering commitment to delivering high-quality consumer healthcare experiences at scale.

 Our continued growth has created an opportunity to join our as Data Engineer.

 As a data engineer, you will join one of our teams focused on helping data scientist architect and deploy AI models. You will also work alongside developers modernizing our legacy systems by developing new services using cloud-native GCP technologies.

 Responsibilities:

 Design, build and improve our ETL platform and pipelines and modernize the data warehouse
 Ensure standards for engineering excellence, scalability, reliability, and reusability
 Debug production issues across services and multiple levels of the stack
 Partner with the insights and data science teams to automate processes to improve data sets for analytical and reporting needs
 Write test cases, code coverage, perform QA and participate with stakeholders on UAT
 Participate in an on-call rotation to mitigate any data pipeline failures
 Focus on development/improvement of framework to support repeatable and scalable solutions
 Take initiative to recommend/develop innovative approaches to getting things done
 Work as a team player and encourage collaboration


 Minimum Qualifications:

 Bachelor's Degree in computer science or equivalent experience
 3+ years experience building data pipelines using Airflow, Spark or Kafka Streams
 Excellent problem solving skills
 Proficiency in Python, Java, or other similar languages
 Familiarity with architecture of event collection pipelines and analytical data stores such as Snowflake
 Strong programming/scripting knowledge in building and maintaining ETL using Java, SQL, Python, Bash, Go
 In-depth hands-on knowledge of public clouds - GCP(preferred)/AWS, PostgreSQL (version 9.6+), ElasticSearch, MongoDB, MySQL/MariaDB, bigQuery
 Ability to work in a fast-paced, rapidly changing environment
 Understanding of Agile and its implementation for Data Warehouse Development
 Excellent communication and interpersonal skills; able to communicate clearly and concisely


 Preferred Qualifications:

 Strong experience with event/streaming based systems
 Experience with Docker, Kubernetes
 Develop and deploy CICD pipelines for Data Engineering
 Experience and knowledge of optimizing database performance and capacity utilization to provide high availability and redundancy
 Proficiency with high volume OLTP Databases and large data warehouse environments"
Senior Data Center Critical Facility Engineer,Equinix,"Elk Grove Village, IL 60007",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=883c9271ca872b74&fccid=e15d9e27876d9dc3&vjs=3,"Senior Data Center Critical Facility Engineer
 





       Job Description
      





Equinix is the world’s digital infrastructure company, operating 245+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, complex infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.

We are a fast-growing global company with 70+ quarters of growth. Through our innovative portfolio of high-performance products and services, we have created the largest, most active global ecosystem of 10,000+ companies, including 2,000+ networks and 3,000 cloud and IT service providers in 32 countries spanning six continents.

Joining our operations team means that you will be at the forefront of all we do, maintaining critical facilities infrastructure as part of a close-knit team delivering best-in-class service to our data center customers. We embrace diversity in thought and contribution and are committed to providing an equitable work environment. that is foundational to our core values as a company and is vital to our success.

Job Summary
 Data Centers are considered Critical Facilities. This means that we support hospitals, laboratories, public safety centers. Simply put - We cannot go dark. In this crucial role, you will complete repairs, corrective maintenance, and routine installations of Critical Facility infrastructure.

Responsibilities

You will perform site inspections and supervise the building and Data Center alarms
 Performs preventative maintenance of on-site infrastructure (e.g. maintenance of primary infrastructures), or leads vendors
 Undertake repairs and corrective maintenance
 Extensive knowledge of critical infrastructure i.e. UPS, generator, BMS, chillers, life safety systems
 Completion of site logs and data gathering issuing for basic permits, such as MOPs and scripts
 Respond to all on-site incidents and acts as the need arises
 Completes routine work requests and circuit installations
 Provide assistance during critical maintenance activities
 You are able to effectively collaborate within the department and provide recommendations to peers for general maintenance activities
 Carry out basic infrastructure projects
 24/7 Operation - Your flexibility to work any assigned shift, off-schedule, workmate, respond to emergencies, etc.


Qualifications

A natural curiosity and strong troubleshooting skills
 Experience working in a critical facility
 Strong system-level mechanical or electrical proficiency
 You are capable of lifting up to 50 lbs. and are agile in manual dexterity (climb, stoop, et.) with or without an accommodation.
 4+ years experience
 High School Diploma


Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you need assistance in applying for an open position, you may send an email to Staffing@equinix.com. Please provide your contact information and let us know how we can assist you.

Equinix is an Equal Employment Opportunity and Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to unlawful consideration of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy / childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political / organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law. (Equal Opportunity / AA / Disabled / Veterans Employer)."
Sr Test Engineer - Big Data,HCSC,"Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=d01d7da4256b803b&fccid=430345d982138f73&vjs=3,"At HCSC, we consider our employees the cornerstone of our business and the foundation to our success. We enable employees to craft their career with curated development plans that set their learning path to a rewarding and fulfilling career. 

Come join us and be part of a purpose driven company who is invested in your future! 

Job Summary 

This Position Is Responsible For Developing Frameworks For Test Scripting, Automation And Troubleshooting. 

Required Job Qualifications: 

Bachelor Degree and 4 years Information Technology experience OR Technical Certification and/or College Courses and 6 year Information Technology experience OR 8 years Information Technology experience. 
Experience in technologies testing. 
Experience in application and infrastructure integration. 
Experience in SDLC Methodology - Agile / Scrum / Iterative Development. 
Experience in ITIL. 
Experience in code versioning / code merge. 
Experience in Iterative / Agile / Scrum development. 
Experience in mobile testing. 
Experience in ALM/SQL/SDM. 
Experience in Performance Center. 
Experience in HP LoadRunner, QualityCenter and other QA and testing tools. 
Experience in web technologies - HTML/CSS/Java/ASP.Net/PHP/Ruby/C#. 
Experience in scripting languages - BASH / PERL / PYTHON / RUBY. 
Experience in traditional app technology – C++, COBOL, Perl, SAP, etc. 
Experience in test automation tools. 
Testing methodologies. 
Ability to tie together solutions across systems. 
Continuous improvement. 
Problem Management / RCA. 
Detail oriented. 
Interpersonal and communication skills. 
Problem solving and analytical thinking. 
Teamwork and collaboration. 
Preferred Job Qualifications: 

Bachelor Degree in Computer Science or Information Technology. 
ISEB System Testing Foundation Cert. or similar. 
Experience in Azure. 
Experience in Scala Programming. 
We encourage people of all backgrounds and experiences to apply. Even if you don’t think you are a perfect fit, apply anyway - you might have qualifications we haven’t even thought of yet. 

Are you being referred to one of our roles? If so, ask your connection at HCSC about our Employee Referral process! 

HCSC Employment Statement: 
HCSC is committed to diversity in the workplace and to providing equal opportunity and affirmative action to employees and applicants. We are an Equal Opportunity Employment / Affirmative Action employer dedicated to workforce diversity and a drug-free and smoke-free workplace. Drug screening and background investigation are required, as allowed by law. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status."
"Lead, Data Engineer",Bain & Company,"Chicago, IL",Posted 30+ days ago,"$157,500 - $189,500 a year",https://www.indeed.com/rc/clk?jk=6dae521099b73ae2&fccid=48270b2eee62c2c6&vjs=3,"WHAT MAKES US A GREAT PLACE TO WORK 

 We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are a Glassdoor Best Place to Work and we have maintained a spot in the top four since its founding in 2009. We believe that diversity, inclusion and collaboration are key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally. 

 WHO YOU’LL WORK WITH 

 Working alongside our generalist consultants, Bain's Advanced Analytics Group (AAG) helps clients across industries solve their biggest problems using our expertise in data science, customer insights, statistics, machine learning, data management, supply chain analytics and data engineering. Stationed in our global offices, AAG team members hold advanced degrees in computer science, engineering, AI, data science, physics, statistics, mathematics, and other quantitative disciplines, with backgrounds in a variety of fields including tech, data science, marketing analytics and academia. 

 WHAT YOU’LL DO 

 As a member of the growing Cloud, Apps and Data Engineering team in Bain’s Advanced Analytics Group, you will: 



Partner with Data Science, Machine Learning, and Platform Engineering teams to develop and deploy production quality code
Develop and champion modern Data Engineering concepts to technical audience and business stakeholders
Implement new and innovative deployment techniques, tooling, and infrastructure automation within Bain and our clients.
Travel is required (30%)
 ABOUT YOU 


Master’s degree in Computer Science, Engineering, or a related technical field.
3+ years at Senior or Staff level, or equivalent
3+ years of experience programming with Python, Scala, C/C++, Java, C#, Go, or similar programming language.
3+ years of experience with SQL or NoSQL databases: PostgreSQL, SQL Server, Oracle, MySQL, Redis, MongoDB, Elasticsearch, Hive, HBase, Teradata, Cassandra, Amazon Redshift, Snowflake.
Experience in deploying serverless data pipelines through containerization and terraform orchestration
Industry level experience of working with public cloud environments (AWS, GCP, or Azure), and associated deep understanding of failover, high-availability, and high scalability
Scaling and optimizing schema and performance tuning SQL and ETL pipelines in data lake and data warehouse environments.
Strong computer science fundamentals in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance.
Data ingestion using one or more modern ETL compute and orchestration frameworks (e.g. Apache Airflow, Luigi, Spark, Apache Nifi, and Apache Beam).
Version control and git workflows
Strong interpersonal and communication skills, including the ability to explain and discuss complex mathematical and machine learning technicalities with colleagues and clients from other disciplines at their level of cognition
Curiosity, proactivity and critical thinking
 ABOUT US 

 Bain & Company is a global consultancy that helps the world’s most ambitious change makers define the future. 

 Across 64 cities in 39 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition, and redefine industries. We complement our tailored, integrated expertise with a vibrant ecosystem of digital innovators to deliver better, faster, and more enduring outcomes. Our 10-year commitment to invest more than $1 billion in pro bono services brings our talent, expertise, and insight to organizations tackling today’s urgent challenges in education, racial equity, social justice, economic development, and the environment. We earned a gold rating from EcoVadis, the leading platform for environmental, social, and ethical performance ratings for global supply chains, putting us in the top 2% of all companies. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry. 


U.S. Compensation and Benefit Information:
 Compensation for this role includes base salary, annual discretionary performance bonus, 401(k) plan with an annual employer contribution based on years of service and Bain’s best in class benefits package (details listed below). 

 Some local governments in the United States require a good-faith, reasonable salary range be included in job postings for open roles. The estimated annualized compensation for this role is as follows: 

 In New York City, the good-faith, reasonable annualized full-time salary range for this role is between $157,500 - $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 In California state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 In Washington state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 For all other U.S. locations, the good-faith, reasonable annualized full-time salary range for this role is commensurate with competitive geographic market rates for this role and will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 Annual discretionary performance bonus 

 This role may also be eligible for other elements of discretionary compensation 

 4.5% 401(k) company contribution, which increases after 3 years of service and is 100% vested upon start date 

 Bain & Company's comprehensive U.S. benefits and wellness program is designed to help employees achieve personal independence, protection and stability in the areas most important to you and your family."
Data Engineer Senior Consultant (Clearance Required),Deloitte,"Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=0279e7a7a548037d&fccid=9e215d88a6b33622&vjs=3,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.
 

Work you'll do

 The Data Engineer will design future-state, modern data architecture for transformation at the enterprise level using advanced architectural principles. Using tools such as Snowflake and/or Databricks, they will also work with cutting-edge DevOps technologies, develop advanced analytics products, and apply data and statistical programming tools to enterprise data to advance and enable key mission outcomes within environments (GCP, AWS, Azure).
 

The team 

 Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.
 
 The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.
 
 Qualifications
 
 Required:
 


Minimum Active Top Secret Level Security Clearance



5+ years of professional experience in data engineering (SQL).



5+ years of experience designing and developing real time ETL architecture for real time predictive analytics.



5+ years of experience with Databricks, Snowflake, or AWS



Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field

 Preferred:
 


3+ years of relevant consulting or industry experience



Creativity and innovation - desire to learn and apply new technologies, products, and libraries



Prior professional services or federal consulting experience

 How you'll grow
 
 At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
 
 The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,000 to $181,000
 
 #LI-JRK"
"Lead, Cyber Security Engineer - Data Protection",Northern Trust Corp.,"Chicago, IL 60603 (The Loop area)",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=c67c7de5f1cfed44&fccid=659d7ed1b53f4cd4&vjs=3,"About Northern Trust:
 Northern Trust provides innovative financial services and guidance to corporations, institutions and affluent families and individuals globally. With 130 years of financial experience and nearly 20,000 partners, we serve the world’s most sophisticated clients using leading technology and exceptional service.


 As a Northern Trust employee (Partner), you will be part of a flexible and collaborative work culture, which has a strong history of financial strength and stability. Movement within the organization is encouraged, senior leaders are accessible, and you can take pride in working for a company that is committed to strengthening the communities we serve.


 Northern Trust is committed to working with and providing adjustments to individuals with health conditions and disabilities. If you would benefit from adjustments for any part of the employment process, please inform the recruiter to discuss your individual requirements.


 We recognize the value of inclusion and diversity in culture, in thought, and in experience, which is why Forbes ranked us the top employer for Diversity in 2018.

 
Role/ Department:


 The job uses best practices and knowledge to develop and implement data protection control standards and guidance around implementation. The Associate will assist in the data discovery scanning, identification, notification, remediation tracking, and remediation guidance of sensitive data across the NT environment. The Security Architect will play a crucial role in executing Northern Trust’s security monitoring model, contributing to a resilient and unified team that improves NT’s ability to protect and defend its networks and information.


 Responsibilities
 Under general supervision responsible for detection, remediation, and prevention of security threats in the NT environment and work with consultants and management for additional analytics on security threats.

 

Configures and executes data discovery scanning with DLP technologies




Conducts data protection analysis, coordination, and interaction across the network and infrastructure components


 

Interacts with data owners to provide recommendations and steps for remediation of data discovery results




Reviews and refines scanning logic to improve accuracy of scans




Conducts data analysis and data quality checks to support DLP processes




Assists with reporting of KRIs and KPIs to multiple levels of leadership, including Executive and Senior Executive.




Develops, implements, &/or maintains end to end processes related to DLP




Assists with RCSA & PRCI efforts supporting the Data Protection Program




Qualifications/Experience

Minimum of 5+ years of experience working in an information security monitoring & response role in a large, complex environment.


 

Bachelor’s degree and/or relevant proven work experience in Computer Science or other IT related field.


 

Minimum 2 years’ experience developing and implementing end-to-end processes related to data security and data loss prevention activities


 

Experience answering questions and providing demonstrations for internal and external audits, to include Regulatory inquiries.




Ability to conduct detailed analysis using various data loss prevention technologies


 

Experience with technologies to support Agile &/or Scrum methodologies




Experience with query languages such as SQL, KQL, etc.




Self-motivated, proactive and able to work independently.


 

Strong communication skills.



 Preferred Qualifications/Experience

Industry certification such as CISSP, CISM, CISA, GIAC, etc.



 Working with Us:
 We’d love to learn more about how your interests and experience could be a fit with one of the world’s most admired and ethical companies. In return, we will support you with your personal and career goals in a number of ways:
 Financial – Life Assurance, Disability Plan, Pension/ Gratuity, Annual Pay Review


 Work Life Balance – Flexible Work Options, Incremental Annual Leave, Community Volunteer Days


 Health & Wellbeing – Private Medical Insurance, Active Sports & Social clubs (lunchtime and after-work groups), Employee Assistance Program


 Professional Development – Clear Career Path, Education Assistance, Recognition Programme, NT University (wide range of online, virtual & in-house training options) and employee-led Business Resource Councils dedicated to diversity and inclusion initiatives.


 And Finally 
 We hope you’re excited about the role and the opportunity to work with us.
 We value an inclusive workplace and understand flexibility means different things to different people.
 Apply today and talk to us about your flexible working requirements and together we can achieve greater."
Principal Data Platform Engineer,WALGREENS,"Deerfield, IL 60015",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=c8e1d1265c45df7d&fccid=fefd75f5326e1589&vjs=3,"Job Summary :

 Implements data and analytics capabilities and platforms including the data management and integration capabilities, enterprise reference data, and analytics platforms across WBA. This position will play a key role in the design and implementation of new and existing platforms to drive and realize data strategy.
 

Job Responsibilities:

 Leads in the design and development of complex software that processes, stores and serves data for use by others.
 Designs and develops complex and large scale data structures and pipelines to organize, collect and standardize data to generate insights and addresses reporting needs.
 Writes complex ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real time and offline analytic processing.
 Ensures that data pipelines are scalable, repeatable and secure. Improves data consistency and integrity.
 Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards. Designs data infrastructure for scalability, availability, reliability
 Participates in developing technical / business approaches and new or enhanced technical tools. Recommends the right tool and technology to deliver solutions objectively. Evaluates new technologies for continuous improvement.
 Interacts with internal and external peers and management to share highly complex information related to areas of expertise and/or to gain acceptance of new or enhanced technology / business solutions.
 Create technical design documents and supporting materials
 Provides thought leadership to embrace modern data science and data analytics as a critical enabler for business decisions
 Guides and mentors a wide range of audiences.

 About Walgreens and WBA :

 Walgreens (www.walgreens.com) is included in the U.S. Retail Pharmacy and U.S. Healthcare segments of Walgreens Boots Alliance, Inc. (Nasdaq: WBA), an integrated healthcare, pharmacy and retail leader with a 170 year heritage of caring for communities. WBA’s purpose is to create more joyful lives through better health. Operating nearly 9,000 retail locations across America, Puerto Rico and the U.S. Virgin Islands, Walgreens is proud to be a neighborhood health destination serving nearly 10 million customers each day. Walgreens pharmacists play a critical role in the U.S. healthcare system by providing a wide range of pharmacy and healthcare services, including those that drive equitable access to care for the nation’s medically underserved populations. To best meet the needs of customers and patients, Walgreens offers a true omnichannel experience, with fully integrated physical and digital platforms supported by the latest technology to deliver high quality products and services in communities nationwide.
 
Basic Qualifications


 Bachelor's degree in Computer Science, Software Engineering, Electrical Engineering, Mathematics, or related field and at least 8 years of professional work experience in data engineering
 Deep knowledge of SQL
 At least 2 years of experience with REST API development
 Experience establishing and maintaining key relationships with internal (peers, business partners and leadership) and external (business community, clients and vendors) within a matrix organization to develop strategies that meet department goals within budget and timelines.
 Experience interacting at the executive level
 Experience presenting to all levels of an organization, including the C Suite level.
 At least 5 years of experience contributing to financial decisions in the workplace.
 At least 5 years of direct leadership, indirect leadership and/or cross functional team leadership.
 Willing to travel up to/at least 10% of the time for business purposes (within state and out of state).


 Preferred Qualifications


 Experience deploying Python applications
 Experience with Azure application deployment
 Experience with messaging systems such as Kafka or Azure Event Hubs"
Sr. Consultant - Data Engineer,Insygnum,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=add721e79e9d7463&fccid=ed94e1a293166c52&vjs=3,"Insygnum needs a Consultant - Data Engineer to help our clients for data analysis, data integration and data quality. Our Chicago-based team is small but growing fast and we need to complement our in-house experts who knows how to tame challenging data. This is a unique opportunity to not only work with cool technology, but also to create a new methodologies and techniques. You'll get in on the ground floor of a new company, help shape its future, and benefit directly from your work.
Why work here

  Joining insygnum now offers several unique opportunities 
  You will receive competitive salary, benefits, and stock options
You will be working on hard, interesting problems
You will help shape the culture of the company as we grow
You will have the opportunity to apply your skills in a meaningful way and have a real-world impact

Responsibilities

Identify data warehouse needs and develop strategy for implementing a warehousing solution including investigating data sources, rationalizing information sources, identifying technology components, building roadmaps and reference architecture stacks 
Work with Business Analysts and other information management professionals through all phases of project development, from envisioning to architecture definition and end solution realization
Provide direction and collaborate with Data Engineers to implement enterprise solutions that will support organizational business intelligence and analytics requirements 
Work with the business to identify opportunities where technology can be leveraged to solve existing problems and can assist with new market opportunities 
Meet with technology vendors, convey technical requirements and business use cases, develop scorecards, install vendor products in a lab environment, and summarize findings and results of testing 
Technologies to be used may include some combination of relational databases (PostgreSQL, Teradata, Aster, HANA), NoSQL, Hadoop, Object-based stores, and OLAP.

   Specific responsibilities include: 
   Help design an architecture for federated data stores and data fusion
Help design methods for storing data in a way that facilitates extremely fast data parsing and management
Implement ""glue code"" that connects middle tier components with backend components
Implement data management and analytics code utilizing data architecture (e.g. map reduce)
Collaborate with machine learning folks to determine how to analyze various data sets and set up methods for querying data stores
Collaborate with enterprise architects to understand the applications we integrate with and the data they produce
Review requirements for new approaches to big data storage and analytics 
Design methods for caching, paging, and integrating real-time data with historical data stores

Desired Skills and Experience
Requirements

Minimum ten years of experience in an IT environment with at least five years designing and working with large enterprise database warehouses, designing robust data models and partitioning strategies 
Minimum five years of data architecture experience, including data modeling with project teams, data governance strategy, metadata management, system architecture, design, and implementation 
Minimum five years experience using one or more data integration tools including Data Quality and ETL 
Development knowledge for integrating components and contributing to core code base - Java preferred
Solid understanding of database and data warehousing technologies
Experienced in advanced SQL as well as NoSQL queries, syntax, and technologies
Experienced in big data requirements, applications, and technologies such as Hadoop
Proficient in ETL methods and approaches including triggers, named views, temporary tables, etc.
Experienced in Linux environments

Bonus Points

Experience working with IT strategy teams, business teams and business analysts to define information systems, services and management 
Experience with RDBMS including SQL Server, Oracle 11g, MySQL; Big Data including SQL Data Warehouse Appliance, Oracle Exadata, Netezza, Greenplum, Vertica, Teradata, Aster Data, SAP HANA, Hadoop a plus; Analytics including SAS, SPSS, Spotfire, Tableau, Qlikview, R, Oracle Endeca; BI Tools including Oracle OBIEE, SAP Business Objects, SAS and other Analytics Vendors with BI components; ETL & MDM including Informatica, SAS Dataflux, IBM, Siperion, Rochade, Map/Reduce for ETL is a plus
Java is strongly preferred (e.g. for working with map reduce) but not ultimately a requirement if you excel in other areas 
Strong SQL skills are highly desirable
OLAP experience"
Sr Staff Software Engineer - Data Platform,ServiceNow,"Chicago, IL 60607 (West Town area)",Posted 1 day ago,Full-time,https://www.indeed.com/rc/clk?jk=5bd796b1428bfafc&fccid=7442885bc0fa7c14&vjs=3,"Company Description
 At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
 Job Description
 *Flexible in-office*
Team
As a Senior Staff Data Platform Software Engineer, you will have the opportunity to become a key member of the Data Scale team in the Platform Persistence group. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work. Depending on the nature of the data, the storage systems include both relational databases and non-relational database such as columnar database.
What you’ll do and need to know:

You’ll work toward managing our explosive data growth and ensuring our systems remain available and highly responsive.
Delivering complex project on time
Having aptitude for learning new technologies quickly.
Developing platform technologies at scale.
Experience with troubleshooting difficult production issues e.g., memory leaks, concurrency issues, locking issues, network problems, intermittent failures etc. across the stack.
Relational Database Experience: Developing on, troubleshooting, and optimizing performance.

Nice to have:

Passionate database technologies
Experience with Unix shell
Experience working with JDBC drivers.
Experience working in a DevOps environment.
Experience working in a customer focused environment.


Qualifications


10+ years of software development experience
Expert level with core Java development
Advanced-Expert level of backend platform development
Expert level understanding of best practices for object-oriented and modularized software. Emphasis on Java
Knowledge and/or experience with relational databases: PostgreSQL, Oracle, MySQL, MariaDB, MS SQLServer, etc.


Additional Information
 ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
 At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
 If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
 For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
 Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
 From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
 Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow."
Lead Data Engineer,PharmaCann,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=1d0f1d30ae001dc4&fccid=4453ef2a4f58a5cc&vjs=3,"Join the movement!
 Pharmacann Inc., one of the nation's leading cannabis companies, is changing the way people view cannabis. Be a part of the team shaping the future of this booming industry, where our people, our reputation and our standards matter. With a strong foundation and dynamic growth plan, opportunities to join our team abound in this fast-paced environment. Are you ready to join the movement?
 We're grounded and growing. Based in Chicago, PharmaCann Inc. operates across multiple states including New York, Illinois, Massachusetts, Maryland, Ohio and Pennsylvania with licensing secured in the Midwest and on the east coast. For more information about our company, please visit pharmacann.com.

 Job Description
 The Lead Data Engineer will design, architect, develop, and lead modern data platform implementation to meet key business objectives. You will engage in understanding key data opportunities to enable business growth and will design right-size and right-fit end-to-end data solutions as part of a broader data strategy and roadmap. As the lead, you will work closely with internal and external project and development teams to ensure successful implementation of data solutions.
 Responsibilities

Lead and mentor a team of senior and junior data engineers to develop enterprise grade cloud data solutions on Azure using a combination of native Azure, commercial off-the-shelf and open-source data technologies.
Lead implementation partners when needed and provide day-to-day oversight and leadership for their development team.
Take technical ownership of all solutions designed and developed as part of end-to-end data solutions.
Lead technical work streams in a Scrum/Agile software engineering practice focused on delivery.
Engage with analysts, analytics, and project teams early on to frame use cases and identify data challenges and opportunities.
Develop and establish best practice design patterns and development processes.
Develop and establish DevOps best practice and work closely with hosting and infrastructure teams to implement best practices.
Engage in hands-on development of data models, ingestion pipelines and analytics datasets for batch and streaming data.
Engage in data analysis to understand upstream data and applications.
Document technical implementation details and artifacts.
Serve as a subject matter expert for the technology stack and demonstrate initiative and ownership of deliverables during development, testing and post-production phases.

Qualifications

Bachelor's Degree or equivalent experience in Computer Science or Software Engineering.
10+ years of experience in Information Technology.
7+ years of experience in Data Engineering.
Experience building batch and stream pipelines on Azure (preferred) or other cloud platforms.
Experience with diverse ways of storing and processing data (file vs SQL vs NO-SQL, batch vs streaming, stateful vs stateless).
Experience in the following technology stack, not limited to: 
   
Azure (preferred) or other cloud data technologies
Apache Airflow or similar orchestration tools
Blob, Azure Data Lake or similar data stores
Talend, DBT or similar ETL tools
Azure Streaming, Spark, Azure Data Factory
Postgres, SQL Server or other DBs
Power BI, Domo or similar analytic tools

Experience modeling and building data warehouses for analytics consumption.
Strong interpersonal skills, customer-centric attitude, proven team player and team builder."
Data and Analytics Engineer - Senior Associate,PRICE WATERHOUSE COOPERS,"Chicago, IL",Posted 15 days ago,,https://www.indeed.com/rc/clk?jk=5f4e194e3ec100d9&fccid=5e964c4afc56b180&vjs=3,"A career in our Managed Services team will provide you an opportunity to collaborate with a wide array of teams to help our clients implement and operate new capabilities, achieve operational efficiencies, and harness the power of technology. Our Managed Data, Analytics & Insights team will provide you with the opportunity to help organizations harness the power of their enterprise data/analytics solutions by optimizing the technology while driving innovation to increase business outcomes and through data insights. We assist our clients in capitalizing on technology improvements, implementing new capabilities and achieving operational insights by managing, maintaining and evolving their analytics platforms and ecosystems. We help our clients maximize the value of their investment focusing on continuous improvement of their analytics solutions such as Microsoft, Amazon Web Services and Google Cloud.
  To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

 As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:


 Use feedback and reflection to develop self awareness, personal strengths and address development areas.
 Delegate to others to provide stretch opportunities, coaching them to deliver results.
 Demonstrate critical thinking and the ability to bring order to unstructured problems.
 Use a broad range of tools and techniques to extract insights from current industry or sector trends.
 Review your work and that of others for quality, accuracy and relevance.
 Know how and when to use tools available for a given situation and can explain the reasons for this choice.
 Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
 Use straightforward communication, in a structured way, when influencing and connecting with others.
 Able to read situations and modify behavior to build quality relationships.
 Uphold the firm's code of ethics and business conduct.


 Additional Responsibilities: 
Our Data and Analytics Managed services team is focused to build, enhance, and scale the modern, connected data ecosystem that accelerates the use of data, analytics, and advanced AI. We are in search of passionate, motivated, and creative Senior Associates in role of Data Technology Engineer, Data Governance SME to join our Managed services team. The senior associate will be responsible for designing and implementing innovative solutions to build and manage the advanced Data ecosystem.

 Basic Qualifications:   Minimum Degree Required:  Bachelor Degree  Minimum Years of Experience:  10 year(s)   Preferred Qualifications:   Preferred Fields of Study:  Computer and Information Science, Information Technology  Certification(s) Preferred: 
Certification in any industry leading tools or technology for Data and Analytics
 Preferred Knowledge/Skills: 
Demonstrates thorough abilities and/or a proven record of success as a team leader by:

 Demonstrating minimum 5 years’ experience of leading data architecture and design implementations and discussions;
 Demonstrating minimum 3 years hand on experience building advanced Data warehousing solutions on leading cloud platforms;
 Demonstrating minimum 3 years’ hands on Experience of delivering Managed Data and Analytics programs (Managed services and Managed assets);
 Designing, implementation and maintaining data technology solutions that meet business requirements;
 Developing scalable, repeatable, and secure data structures and pipelines to ingest, store, collect, standardize, and integrate data that for downstream consumption like Business Intelligence systems, Analytics modelling, Data scientists etc.;
 Building efficient, ETL/ELT processes using industry leading tools like Informatica, Talend, Spark etc.
 Building and maintaining Data Governance solutions (Data Quality, Metadata management, Lineage, Master Data Management and Data security) using industry leading tools;
 Demonstrating experience with Data analytics tools like Informatica, Collibra, Hadoop, Spark, Snowflake etc.;
 Understanding of data consumption patterns and BI tools like tableau, Qlik sense, PowerBI etc.;
 Demonstrating experience of ITIL processes like Incident management, Problem Management, Knowledge management, Release management, Data DevOps etc.;
 Demonstrating communication, problem solving, quantitative and analytical abilities;
 Working with a managed services organization with a passion for building new service offerings in the Data and Analytics space and demonstrate proven experience in following key areas/activities;
 Designing, implementing, and maintaining data technology solutions that meet business requirements;
 Implementing Data processing functions like Data Cleansing, profiling, wrangling standardization and make data available to be ingested the Data ecosystem using advanced concepts like Data lakes, Data fabric, Data Vault, Data Mesh etc.;
 Driving large transformation initiatives like Cloud migration etc.;
 Working closely with cross functional teams to develop and maintain scalable, robust, and efficient data architectures to support business Intelligence, analytics, and reporting needs;
 Evaluating and selecting best fit tools and technologies by conducting PoCs and Pilot solutions;
 Conducting performance tuning, troubleshooting and optimization of Data solutions to improve system performance and stability; and,
 Providing guidance and mentorship to junior associates and engineers in the team.

 Learn more about how we work: https://pwc.to/how-we-work
 
 PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.
 
 All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.
 
 For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.
 
 For positions in Albany (NY), California, Colorado, Nevada, New York City, Washington State, or Westchester County (NY), please visit the following link for pay range information: https://pwc.to/payrange-v1-mgdsrvcsseniorassociate"
"Data Center Colocation Electrical Project Engineer, Colocation Regional Engineering - AMER","Amazon Data Services, Inc.","Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=ac08e669d5078895&fccid=fe2d21eef233e94a&vjs=3,"Bachelor’s Degree in Electrical or Mechanical Engineering or equivalent experience.
 6+ cumulative years of experience with industrial or commercial engineering in Mission Critical facilities including but not limited to: data centers, power generation, oil / gas facilities. (Design Engineer)



 As an Amazon Data Center Project Engineer, you will provide full life-cycle support to AWS Data Centers from design inception through site improvement and maintenance. 
 
 You will be the ‘go to’ engineering resource for your region when technical advice is needed, and will use your subject matter expertise and engage with diverse teams to: 
 

Perform design and equipment submittal review for new Data Centers in your region.
 Troubleshoot, conduct Root Cause Analysis (RCA) and create Corrective Action (CA) documentation for site/equipment failures.
 Directly support operational issues with ad-hoc training, complex operating procedure reviews, including critical equipment, and event support.
 Own the design for existing data center upgrades and design-solutions, which add capacity, improve availability, and increase efficiency.
 Lead, Review, and approve designs for existing co-location (colo) data center upgrades which improve availability/efficiency.
 Interface with internal data center design engineering team, server hardware team, environmental health and safety team to promote standards that maintain consistency and reliability in services delivered.
 Work on concurrent projects, sometimes in multiple geographical regions.
 Initiate and lead engineering site audits within Amazon’s owned or colo data centers. Produce reports outlining risks with recommended mitigations and remediations.
 Act as resident engineer during new construction projects. Support construction, commissioning, and turnover.

 Amazon's vision is to be the world's most customer-centric company, and this role is key to that vision. As a Design Engineer, you will be leading projects to fit out our data centers to meet ever-evolving customer needs as we continue expanding our fleet to hyper-scale.
 
 AWS Colocation Engineers: 
 

Possess Strong Engineering Judgement and are able to provide recommendations despite uncertainty
 Are detail and data oriented
 Manage engineering projects and consultants.
 Build trust and relationships with different stakeholders (e.g., Operations, Commissioning, Construction and Design)
 Be inclined to get into the field to see things up close.

 Each day you will interact with different teams responsible for all aspects of the data centers. You will prioritize your activities to support data center capacity availability and safety focusing on the actions that are most impactful. You will have the opportunity to work on projects locally and globally.




Organized and have the ability to set priorities and meet deadlines and budget
 Possess leadership and problem-solving skills
 Experience using a variety of web based and other software tools for calculation and data processing.
 Direct experience with the design, construction, operation, or maintenance of mission critical facilities, especially data centers.
 Experience as resident engineer or hands-on (in the field) design consultant.
 Knowledge of building codes and regulations for your region.
 Experience reading, interpreting, and creating construction drawings, specifications, and submittal documents.
 Ability to carry design concepts through exploration, development, and into deployment/mass production
 Possess excellent communication and writing skills, attention to detail, maintain high quality standards
 Basic understanding of both mechanical and electrical equipment/design related to data centers (Including but not limited to: uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, air economizers, etc...)
 EPMS/SCADA/BMS Controls system experience (software and/or hardware)
 Registered Professional Engineer
 Advanced degree in engineering, business, or related field.
 Have fluent knowledge of continuous operating redundant electrical systems, cooling systems, air flow containment systems and building management systems. (Including but not limited to: uninterruptable power sources, AC/DC conversion, P&ID loops, diesel generators systems and complex arrangements, direct evaporative cooling systems, etc...)
 Ability to develop solutions and execute plans on complex projects
 Previous ownership of fast track design/build projects and or multiple significant upgrade projects

 Why AWS?
  About AWS
  Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud 
  platform. We pioneered cloud computing and never stopped innovating — that’s why customers 
  from the most successful startups to Global 500 companies trust our robust suite of products and 
  services to power their businesses.
 
 Inclusive Team Culture
  Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster 
  a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning 
  experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender 
  diversity) conferences, inspire us to never stop embracing our uniqueness.
 
 Work/Life Balance
  We value work-life harmony. Achieving success at work should never come at the expense of 
  sacrifices at home, which is why flexible work hours and arrangements are part of our culture. 
  When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the 
  cloud. 
 
 Mentorship & Career Growth
  We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer.
  That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing
  resources here to help you develop into a better-rounded professional.
 
 Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Cloud Data Engineer Lead - IL Lisle,Ryerson,"Lisle, IL 60532",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=ef8b1cfc61ad78b7&fccid=16b69d82eb3bb6d2&vjs=3,"The future will be made from metal. From global infrastructure projects to smart energy initiatives, metal is the essential material for building a more sustainable society. Joseph T. Ryerson & Son, Inc., a leader in the global metals supply chain for nearly 200 years, is at the center of it all, helping close the gap between metal producers’ supply and end-users’ demand.
   
 Here is your chance to help tell the next chapter in our story. We are currently seeking a Cloud Data Engineer Lead to contribute as an essential member within the IT team in Lisle, IL.
   
 Your strategic responsibilities will include participating with developing and supporting cloud data structures (Azure/AWS) with a focus on enabling the Power BI applications that drive analytics and reporting for the Company.
   
 The Ideal Candidate Possesses the Following Qualities:
   


Strong quantitative and logical thinking skills combined with the ability to think creatively, envision relationships between data, and communicate those findings to key decision makers.
Proven technical capabilities for developing, implementing and tuning cloud data structures used within modern BI systems and platforms.
Demonstrated ability to quickly learn and understand new software products and concepts, including ability to self-instruct using available texts and other resources.
Excellent organizational skills with emphasis on ability to organize tasks, manage multiple projects, create and maintain documentation, prioritize work and meet deadlines with minimal direct supervision.
Excellent communication and interpersonal skills; ability to interact across multiple departments and levels within a medium to large size enterprise.
Ability to work independently or with minimal instruction.

 Professional and Technical Responsibilities Include: 
   


Identifying, creating, preparing data required for modern BI solutions.
Designing, coding and testing data repositories needed to support software modules/applications.
Building BI solutions using existed cloud provided services.
Creating and documenting the tests to meet requirements.
Deploying BI solutions into cloud environments and integrating them with other components in the application.
Maintaining, tuning and adapting applications to keep them performing to specifications.
Work with data from all business disciplines (Materials, Customers, Vendors …) at all business levels (local, regional, corporate).
Work with people from all business disciplines (Supply Chain, Sales, Operations, IT, …) at all business levels (local, regional, corporate). This includes outside technical consultants when appropriate.
Gather and document requirements for projects and reports as well as generate business user training materials including direct communication with internal and external stakeholders.
Actively participate in the data collection, testing and validation for newly created and existing data sources as well as facilitate the data quality scorecards for same.
All other duties as they are assigned. 





Position Requirements:
 • Bachelor’s or Master’s degree in Computer Science, Analytics or Information Technology / Systems strongly preferred; degrees in quantitative majors such as Statistics, Applied Mathematics, Industrial Engineering, Supply Chain, Economics, Accounting, Finance or similar will be considered.
   

Five (5) or more years of relevant technical or highly analytic business experience, with two (2) or more years in leading role supporting Cloud Data development.
Experience in data engineering and cloud data processing services (AWS, Azure and/or Google Cloud Platform).
Knowledge of SQL, Python, and other similar languages is preferable.
Good understanding of ETL tools and related data movement concepts.
Advanced level abilities in ad hoc analysis tools such as Microsoft Excel, including knowledge of pivot tables, v-lookups, and query writing to collect, transform and evaluate data to provide actionable information.
Interest or experience in Big Data technologies (Hadoop, Spark, Data Bricks, Snowflake).
Open mindset, ability to quickly adapt new technologies and learn new practice.
Infrequent travel may be required.

 About Our Team: 
   
 Ryerson IT Analytics is part of the office of the Chief Data Officer and supports key decision-makers across the company. Our toolset includes best-of-breed software such as Salesforce.com, Microsoft PowerBI, Azure Analytics, IBM Cognos, Oracle, SAP, and Informatica MDM 360, in addition to in-house resources for custom application development. We are proud to employ a diverse team of analysts and developers as we help build and maintain the systems that drive Ryerson’s business.
  




 Experience Required: 5 - 7 Years



 Education Required: Bachelors Degree"
Mechanical Engineer (Mission Critical/Data Centers),WSP,"Chicago, IL",Posted 5 days ago,,https://www.indeed.com/rc/clk?jk=7fa5dc00693f8e7e&fccid=125e77713a321cdc&vjs=3,"Mechanical Engineer (Mission Critical/Data Centers)



Who We Are
 At WSP, we are driven by inspiring future-ready pioneers to innovate. We’re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!

 This Opportunity
 kW Mission Critical Engineering, a member of WSP USA is currently initiating a search for a Mechanical Engineer for our Chicago, IL or Milwaukee, WI office.  As a Mechanical Engineer with us, you will design complex cooling and HVAC systems including air distribution systems, chiller plants, and alternative energy solutions. The ideal candidate has familiarity with Building Information Modeling using REVIT, has strong communication skills, and an interest in liaising with internal and external design, client and construction team members.
 Your Impact

Collect, compile, and analyze data from the physical work site, surveys, blueprints, schematics, data, technical drawings, computer-generated reports, and other matrices for project development, design, and construction.
Perform professional mechanical engineering work and conduct research and inspections of proposed and existing site conditions, equipment, resources, building, infrastructure, usage, and mechanical systems to determine conformance with applicable rules, standards, and construction or operating permits.
Participate in incorporating advanced technology, modeling techniques, concept development, design requirements, load calculations, and operating strategies to account for the proper installation and functioning of equipment and systems according to specifications; implementing future-ready solutions with mechanical engineering design standards.
Work under direct supervision of senior engineers and to perform a variety of assignments requiring the application of standard engineering and design techniques to support a variety of kW MCE clients
Work within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners
Attend client meetings
Collaborate and coordinate with internal project discipline team members and external equipment vendors and manufacturers.
Perform cooling/heating load calculations
Design air distribution systems
Design hydronic systems
Schedule and select major equipment
Perform construction administrations tasks with oversight from experienced staff
Survey and evaluate existing conditions with oversight from experienced staff

Who You Are
 Required Qualifications

Bachelor’s degree in Mechanical Engineering or Architectural Engineering with mechanical building systems emphasis
1-3 years of relevant post education experience in engineering discipline and prior mechanical design experience.
Engineer in Training Certification.
Knowledge of AutoCAD, Revit and TraneTrace
Knowledge of building, mechanical and energy codes
Interest in innovative design, specifically in renewable energies and sustainable, high performing, commercial, industrial or mission critical/data center buildings
Knowledge of mechanical engineering principles, practices, process, design/build, and the application to project work-related issues.
Experience with building and infrastructure planning, design, and construction management; including rehabilitation and new design.
Effective self-leadership with attention to detail, results orientation, and managing multiple priorities in a dynamic work environment.
Ability to learn new techniques, perform multiple tasks simultaneously, follow instruction, work independently, and comply with company policies.
Moderate proficiency with technical writing, office automation, software, technology, math principles, predictive models, spreadsheets, and tools.
Experience with discipline-specific design software (i.e., AutoCAD, CAM).
Critical thinking and problem-solving skills required to apply technical knowledge to reach conclusions from testing results, data collation, load calculations, statistical analysis and arriving at the most effective, economical, and logical solution.
Proven track record of upholding workplace safety and ability to abide by WSP’s health, safety and drug/alcohol and harassment policies.
Ability to work schedules conducive to project-specific requirements that may extend beyond the typical workweek.
Occasional travel may be required depending on project-specific requirements.

Preferred Qualifications:

Master’s Degree in Engineering.
PE License, or ability to obtain PE is preferable
Previous building design or construction internship experience preferred.

#LI-JB3

 Additional Requirements

To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.

Additional Details

Travel Required: 10%
Job Status: Regular
Employee Type: Full
Primary Location: MILWAUKEE - N WATER ST
All locations: US-IL-Chicago, US-WI-Milwaukee


About WSP
 WSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com
 WSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee’s career.
 At WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?
 WSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race/Age/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability or Protected Veteran Status.
 The selected candidate must be authorized to work in the United States. 
NOTICE TO THIRD PARTY AGENCIES:
 WSP does not accept unsolicited resumes from recruiters, employment agencies, or other staffing services. Unsolicited resumes include any resume or hiring document sent to WSP in the absence of a signed Service Agreement where WSP has expressly requested recruitment/staffing services specific to the position at hand. Any unsolicited resumes, including those submitted to hiring managers or other business leaders, will become the property of WSP and WSP will have the right to hire that candidate without reservation – no fee or other compensation will be owed or paid to the recruiter, employment agency, or other staffing service."
Site Reliability Engineer III - Pricing Reference Data,JPMorgan Chase & Co,"Chicago, IL 60603 (Loop area)",Posted 13 days ago,Full-time,https://www.indeed.com/rc/clk?jk=2d4193619bdb8b5e&fccid=c46d0116f6e69eae&vjs=3,"JOB DESCRIPTION
 There’s nothing more exciting than being at the center of a rapidly growing field in technology and applying your skillsets to drive innovation and modernize the world's most complex and mission-critical systems.
As a Site Reliability Engineer III in the Price Reference Data team at JPMorgan Chase, you will solve complex and broad business problems with simple and straightforward solutions. Through code and cloud infrastructure, you will configure, maintain, monitor, and optimize applications and their associated infrastructure to independently decompose and iteratively improve on existing solutions. You are a significant contributor to your team by sharing your knowledge of end-to-end operations, availability, reliability, and scalability of your application or platform. 
Job responsibilities

Guides and assists others in the areas of building appropriate level designs and gaining consensus from peers where appropriate
Collaborates with other software engineers and teams to design and implement deployment approaches using automated continuous integration and continuous delivery pipelines
Collaborates with other software engineers and teams to design, develop, test, and implement availability, reliability, scalability, and solutions in their applications 
Implements infrastructure, configuration, and network as code for the applications and platforms in your remit
Collaborates with technical experts, key stakeholders, and team members to resolve complex problems 
Understands service level indicators and utilizes service level objectives to proactively resolve issues before they impact customers
Supports the adoption of site reliability engineering best practices within your team

Required qualifications, capabilities, and skills

Formal training or certification on site reliability engineering concepts and 3+ years applied experience
Proficient in site reliability culture and principles and familiarity with how to implement site reliability within an application or platform
Proficient in at least one programming language such as Python, Java/Spring Boot, and .Net 
Proficient knowledge of software applications and technical processes within a given technical discipline (e.g., Cloud, artificial intelligence, Android, etc.) 
Experience in observability such as white and black box monitoring, service level objective alerting, and telemetry collection using tools such as Grafana, Dynatrace, Prometheus, Datadog, Splunk, and others 
Experience with continuous integration and continuous delivery tools like Jenkins, GitLab, or Terraform 
Familiarity with container and container orchestration such as ECS, Kubernetes, and Docker
Familiarity with troubleshooting common networking technologies and issues
Ability to contribute to large and collaborative teams by presenting information in a logical and timely manner with compelling language and limited supervision
Ability to proactively recognize road blocks and demonstrates interest in learning technology that facilitates innovation 
Ability to identify new technologies and relevant solutions to ensure design constraints are met by the software team
Ability to initiate and implement ideas to solve business problems

Preferred qualifications, capabilities, and skills

Experience with AWS

ABOUT US

 JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
 



  We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.
  




  The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the “WELL Health-Safety Rating” for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. 
 


As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm’s current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm’s vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

Equal Opportunity Employer/Disability/Veterans 
 

ABOUT THE TEAM

 Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success."
Senior Data (Informatica MDM) Engineer,Wintrust Financial,"Rosemont, IL 60018",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=ef52fe15ba79727c&fccid=bd3a202af4b1346d&vjs=3,"Wintrust is a financial holding company with approximately $50 billion assets under management and traded on the NASDAQ:WTFC. Built on the ""HAVE IT ALL"" model, Wintrust offers sophisticated technology and resources of a large bank while focusing on providing service-based community banking to each and every customer. Wintrust operates fifteen community bank subsidiaries with over 170 banking locations in the greater Chicago and southern Wisconsin market areas. Additionally, Wintrust operates various non-bank business units including commercial and life insurance premium financing, short-term accounts receivable financing, out-sourced administrative services, mortgage origination and purchase, wealth management services and qualified intermediary services for tax-deferred exchanges.

 Why join us?

 An award-winning culture! We are rated a Top Workplace by the Chicago Tribune (past 8 years) and Employee Recommended award by the Globe & Mail (past 6 years)
 Competitive pay and discretionary or incentive bonus eligible
 Comprehensive benefit package including medical, dental, vision, life, a 401k plan with a generous company match and tuition reimbursement to name a few


 Why join this team? 

We hold ourselves accountable to high standards, share wins, operate ethically, and have fun
 Master Data Management (MDM) team members play a key part in the Wintrust Digital Journey supporting enterprise applications including CRM, Digital Banking, Account Opening Platform, LOS etc.


 Position Summary
 The Senior Data Engineer is a key position within the Data Management team, responsible for the development, test and implementation of best-in-class Data solutions for the organization. The ideal candidate will be engaged in all phases of the Data Integrations lifecycle, and will be called upon to mentor less experienced team members as necessary. Successful candidate will have a proven track record of being a Subject-Matter Expert for the data domain.

 Key Accountabilities

 Develop and maintain data solutions using best practices.
 Analyze the requirements and prepare technical specifications.
 Drive the Deployment of data flows.
 Support/enhance/create integrations to address business requirements, ensuring all related processes meets best-in-class standards offering high performance.
 Build continuous improvement process for complex data systems, tools and reports.
 Provides technical leadership across multiple domains.
 Serves as resource to internal, offshore team and third-party team members on escalated issues, analyzing and preparing specifications for less experienced team members
 Pursues self-development and effective relationships with others by sharing resources, information, and knowledge with coworkers and customers. Seeks opportunities to deliver continuous process improvement


 Qualifications

 Bachelor’s degree with 7+ years’ experience or Master’s degree with 5+ years’ experience in Computer Science, Engineering, Math, or other quantitative field.
 5+ years’ experience implementing Master Data Management (MDM) / Reference Data Management (RDM) Solution for enterprise needs (Informatica is preferred).
 Experience working with MDM Match and Merge Process, Trust and Survivorship Rules, User Exits, ActiveVOS Workflow, Composite Services, BES API’s, etc.
 Experience with source control repository system such as TFS or GIT is preferred.
 Experience working with Cloud and On-Prem data solutions.
 Experience working with Traditional and Distributed data processing systems.
 Should have worked with enterprise architects, data engineers, database administrators, business analysts to determine project requirements and capabilities, and strategized development and implementation timelines.
 Experience defining /implementing coding methodologies and best practices.
 Experience in establishing methods to maintain the integrity and security of the company data.
 Experience working with REST / SOAP services is preferred.
 Experience working with MuleSoft integrations is a plus.
 Experience with data integrations using SQL Server and SSIS is a plus.
 Experience with building CICD pipelines for data pipelines using Azure DevOps is a plus.
 Good understanding of Data Warehousing, Middleware, MDM and Data Governance concepts.
 Experience with working on Onsite and Offshore model.
 Experience working on Banking and Financial domain is a plus.
 Proven ability to work within a team environment and interacting with data professionals and business data SME’s throughout the organization.
 Proven track record of meeting commitments with the highest standards of ethics and integrity.


 #LI_REMOTE

 From our first day in business, Wintrust has been proud to serve a variety of unique communities and people from all walks of life. To be Chicago’s Bank® and Wisconsin's Bank®, we need to reflect that diversity both in all the communities we serve, the people we employ, the organizations we work with, and our banking and lending practices. Wintrust Financial Corporation, including community banking and financial services subsidiaries, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran or any other characteristic protected by law."
"Sr Lead, Cyber Security Engineer - Data Protection",Northern Trust Corp.,"Chicago, IL 60603 (The Loop area)",Posted 13 days ago,,https://www.indeed.com/rc/clk?jk=6845b088c6f3cdc7&fccid=659d7ed1b53f4cd4&vjs=3,"About Northern Trust:


 Northern Trust provides innovative financial services and guidance to corporations, institutions and affluent families and individuals globally. With 130 years of financial experience and nearly 20,000 partners, we serve the world’s most sophisticated clients using leading technology and exceptional service.


 As a Northern Trust employee (Partner), you will be part of a flexible and collaborative work culture, which has a strong history of financial strength and stability. Movement within the organization is encouraged, senior leaders are accessible, and you can take pride in working for a company that is committed to strengthening the communities we serve.


 Northern Trust is committed to working with and providing adjustments to individuals with health conditions and disabilities. If you would benefit from adjustments for any part of the employment process, please inform the recruiter to discuss your individual requirements.


 We recognize the value of inclusion and diversity in culture, in thought, and in experience, which is why Forbes ranked us the top employer for Diversity in 2018. 
Role/ Department:


 Seeking a dynamic engineer who is passionate for cloud and security technologies to be part of a team that develops a product impacting tens of thousands of customers. As an architect in our Data Protection team, you will be responsible for designing, implementing, integrating, testing and deploying features and components in a large-scale system. We expect you to drive improvements to code quality, performance, and team processes while leveraging modern web technologies and tool. Should be able to debug problems arising as a result of implementing data protection technologies and be able to understand the implications of his implementations.


 Responsibilities
 Develops and administers the solutions that meet system expectations relative to scalability, performance, fault tolerance, usability, and data integrity. Delivers solutions that meet end user expectations relative to performance, usability and security for the Data Protection Engineering and Architecture function.


 Uses specific knowledge of a discipline to achieve goals through own work. Has specific knowledge or expertise typically gained through formal education or equivalent experience. Uses expertise to provide guidance to others as a project manager or consultant. Requires in-depth conceptual and practical knowledge in own job discipline and basic knowledge of related job disciplines. Solves complex problems. Works independently; receives minimal guidance. Will lead projects or project steps within a broader project or may have accountability for on-going activities or objectives. Acts as a resource for colleagues with less experience


 Primary Duties

 Setting up Encryption using Technologies such as Voltage, Secupi, Protegrity, or Microsoft Purview


 Understanding Key Management framework and best practices around Bring Your Own Key and Hold Your Own Key.

 Secondary Duties

 Setting up DLP Policies in Microsoft Defender for Cloud Apps (CASB) , Microsoft Defender for Endpoint and Microsoft Purview


 Assisting the Implementation of Data Loss Prevention and guide on unit testing, and support documentation;


 Determining operational feasibility by evaluating, analyzing, problem definition, requirements, solution development, and proposing solutions.


 Collaborating with Enterprise Architecture organization as needed. 


 Reviewing documentation, processes or procedures, and recommends where automation or improvements can be implemented 


 Operating independently; has in-depth knowledge of business unit/function; Accomplishes engineering and organization mission by completing related results as needed. 


 As subject area expert, provides comprehensive, in-depth consulting and leadership to team and partners


Knowledge/Skills

 Excellent teammate skills, effectiveness both in independent and collaborative work.


 Ability to learn and use new technologies.


 Background in networking, data security and cloud-based applications.


 Experience with distributed computing platforms for high-scale systems.


 Experience with Azure services and eco-system.


 Experience with Microsoft and Linux-based environments.


 Experience with continuous integration and deployment tools.



 Experience Required
 A College or University degree and/or relevant proven work experience is required. Information Security Certification / Accreditation preferred such as CISSP, CISM, CISA, Cisco, SANS, etc.


 Working with Us:


 We’d love to learn more about how your interests and experience could be a fit with one of the world’s most admired and ethical companies. In return, we will support you with your personal and career goals in a number of ways:


 Financial – Life Assurance, Disability Plan, Pension/ Gratuity, Annual Pay Review


 Work Life Balance – Flexible Work Options, Incremental Annual Leave, Community Volunteer Days


 Health & Wellbeing – Private Medical Insurance, Active Sports & Social clubs (lunchtime and after-work groups), Employee Assistance Program


 Professional Development – Clear Career Path, Education Assistance, Recognition Programme, NT University (wide range of online, virtual & in-house training options) and employee-led Business Resource Councils dedicated to diversity and inclusion initiatives.


 And Finally 
 We hope you’re excited about the role and the opportunity to work with us.
 We value an inclusive workplace and understand flexibility means different things to different people.
 Apply today and talk to us about your flexible working requirements and together we can achieve greater."
Master Data (MDM) Engineer III,Retail Business Services,"Hybrid remote in Chicago, IL",Posted 6 days ago,,https://www.indeed.com/rc/clk?jk=f33e3b4fbd721295&fccid=c9cf363b57be4ab3&vjs=3,"Address: USA-IL-Chicago-300 South Riverside Plaza 
 
Store Code: Arch/Data Master Data (5119270)
 


Retail Business Services, ranked No. 25 on Fast Company’s 2022 100 Best Workplaces for Innovators, is the services company of leading grocery retail group Ahold Delhaize USA, which includes Food Lion, Giant Food, The GIANT Company, Hannaford and Stop & Shop.
 Retail Business Services is looking for a Master Data Engineer III? to help our ?Vendor Master Data Management Team?. The RBS IT team is proud to provide critical services, including software development, hardware purchase and support, network maintenance, data center optimization, around-the-clock IT systems monitoring and much more, to one of the largest portfolios of grocery companies in the nation.  We embrace innovation and creativity, and RBS is ranked No. 25 on Fast Company’s 2022 100 Best Places to Work for Innovators list, which honors organizations that demonstrate a steadfast commitment to encouraging innovation at all levels. We are proud to offer a safe and flexible work environment supported by a thriving culture of belonging and great benefits. We offer the flexibility to work from home and from the office so you can have the work/life balance that suits your lifestyle.

 In your role you will be ?an Individual Contributor? reporting into ?the Vendor MDM manager?. Just a few of your responsibilities are:


 Responsibilities:
  

Develop the technical design for solutions based on the defined scope, requirements, and functional design provided by the Product team and other stakeholders.
Build and configure technical components (interfaces, conversions, reports, workflows) so that solution design meets business needs and solution architecture standards.
Write and document programming code to meet the gathered requirements.
Deliver solutions through ERP or SaaS solutions (e.g. SAP, Manhattan Active WM, Relex)
Perform code reviews and quality assurance to ensure compliance to technical standards and business requirements.

 Qualifications:
  

Bachelor’s degree in Computer Science, Engineering or related field or 8 years of equivalent work experience/certifications
Proven work experience as a Software Engineer or Software Developer within MDM solutions
Experience designing interactive applications
Ability to develop software in Java, Python, C#, R, or other programming languages
Excellent knowledge of relational databases, SQL and ORM technologies (JPA2, Hibernate)



 We look forward to reviewing your application. If you meet the basic qualifications, a recruiter will reach out to you for a quick phone screen to learn more about your career aspirations.
 #li-mm1 #li-hybrid #zr #dicejobs
 Retail Business Services currently provides services to five omnichannel grocery brands, including Food Lion, Giant Food, The GIANT Company, Hannaford and Stop & Shop. Retail Business Services leverages the scale of the local brands to drive synergies and provide industry-leading expertise, insights and analytics to local brands to support their strategies. We are committed to diversity, equity and inclusion and we foster a community of belonging where everyone is valued. 
Retail Business Services is an equal opportunity employer. We comply with all applicable federal, state and local laws. Qualified applicants are considered without regard to sex, race, color, ancestry, national origin, citizenship status, religion, age, marital status (including civil unions), military service, veteran status, pregnancy (including childbirth and related medical conditions), genetic information, sexual orientation, gender identity, legally recognized disability, domestic violence victim status or any other characteristic protected by law. We provide reasonable accommodations to applicants and employees with disabilities. As important as what we do is how we do it. Our team embodies our values of Courage, Care, Teamwork, Integrity and Humor in everything that they do. We have a culture of care that values and celebrates the qualities and perspectives that make us all unique.
 If you have a disability and require assistance in the application process, please contact our Talent Acquisition Department at tad@retailbusinessservices.com. 
For more information, visit https://www.retailbusinessservices.com.
 Job Requisition: 326199_external_USA-IL-Chicago_7102023"
Data Engineer,Belvedere Trading,"Hybrid remote in Chicago, IL",Posted 15 days ago,Full-time,https://www.indeed.com/rc/clk?jk=4a5b22549281d07b&fccid=3af73fbc98e140e8&vjs=3,"Belvedere Trading is a leading proprietary trading firm proudly headquartered in downtown Chicago. Our traders work hard to provide liquidity to the market through their market-making activities and are the masters of a diverse set of commodities, interest rates, exchange-traded funds (ETF), and equity index options. From the beginning, we began iteratively investing in our proprietary technology and committing to building our systems from the ground up. Our trading models and software systems are continually re-engineered, optimized, and maintained to stay on top of the industry. This wouldn’t be possible without the dedicated efforts of our technology teams who utilize and perfect our innovative technology solutions.
 



   Our Intel focus is to deliver high-quality technology solutions to our core and affiliated groups. We strive to understand and support end-user needs, leverage data to gauge effectiveness, and advance our trading infrastructure by stabilizing all departments. The Business Intelligence team strives to ensure that
 

   properly curated data is in the hands of the people who need it. They deliver the data and tools Belvedere
 

   needs to perform complex analytics and make data driven decisions. We look for passionate team members that excel and their contribution is critical to our continued success.
 


 Belvedere Trading is looking for a proven Data Engineer that is passionate about data integrity and can help take our analytical capabilities to the next level. This role will be instrumental in ensuring the availability, breadth, and reliability of data that uses to continuously make better technical and trading decisions. This position will have the opportunity to actively take part in key decisions as we continue to advance our analytical capabilities.
 


 Our Data Engineers are responsible for data services including ETL pipeline implementation, data warehouse architecture, data quality automation, and integration.
 


 You will help solve some of the hardest problems in a team environment and incrementally adapt to changes in technologies, and business requirements. You will work on our platform to help ensure that our data quality is flawless. You will get the chance to work with a passionate team of engineers to solve challenging problems and ensure that we can deliver the best data to our traders that drive business insight.
 
What you'll do 

Design, build, maintain, and enhance analytical data models/structures in support of Belvedere’s analytical needs
 Establish and ensure reliable flow and integration of data from internally and externally sourced data
 Ensure reliable availability, integrity, and quality of data through automation
 Partner with multiple stakeholders to deliver end-to-end analytics solutions
 Collaborate with multiple cross-functional engineering teams to identify and address data gaps or inconsistencies
 Setup analytical infrastructure to facilitate visualization of datasets
 Determine reporting needs and integrate with business intelligence visualization tools
 Research, evaluate, and recommend technical solutions for data collection, processing, and reporting
 Create custom tooling, as necessary, to simplify the efforts of both the Business Intelligence team and end-users

 What you'll need

 Experience designing and developing big data warehouses and ETL pipelines
 Proven knowledge of SQL and Python
 Solid understanding and background building data structures and leveraging data stores optimized for analytical purposes
 Proficiency and relevant experience with ETL and stream processing toolsets
 Demonstrated ability to navigate and integrate data across multiple data platforms including RDBMS, NoSQL, and Time Series
 Excellent verbal and written communication, analytical, and problem-solving skills
 Experience in Financial Services or Proprietary trading preferred
 Bachelors degree in Computer Science, Information Systems, Engineering, or related field


 Women and underrepresented groups frequently apply to jobs only if they meet 100% of the qualifications.


 We encourage you to break that mold and apply. No candidate is perfect; all have a lot to offer. We welcome your application.



 Core Values


   The secret to our award-winning culture is our Core Values: 
  Team Belvedere, Me In Team, Own It, Iterative Innovation, and Passionate Discourse. We live and breathe these values every day.
 



 Our Stance


   Belvedere is an Equal Opportunity Employer and is committed to providing a non-discriminatory employment environment for its employees. Discrimination against employees and applicants due to race, color, religion, sex, national origin, disability, age, military, and veteran status is prohibited. Belvedere encourages initiatives to increase diversity and provide equal opportunity to all applicants and employees. Belvedere is committed to providing a positive environment in which team members are treated with respect, dignity, and courtesy. Our firm believes in a dynamic culture of inclusion and diversity, where people thrive on individual and organizational characteristics, values, experiences, and backgrounds.
 



   Please note that Belvedere Trading does not accept unsolicited resumes from search firms or employment agencies. Any unsolicited resumes will become the property of Team Belvedere. No phone calls, please.
 



   Any questions regarding the virtual recruiting process, please reach out to recruiting@belvederetrading.com.
 

 


 Work Schedule: Regular and reliable attendance during standard business hours
 

 Amount of Travel Required: None
 

 Sponsorship: Not available for this position"
Data Engineer,Fetch,"Chicago, IL 60654 (River North area)",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=d31e4b9ca132ea0f&fccid=2e5a195d27f5250c&vjs=3,"What we're building and why we're building it.
 There's a reason Fetch is ranked top 10 in Shopping in the App Store. Every day, millions of people earn Fetch Points buying brands they love. From the grocery aisle to the drive-through, Fetch makes saving money fun. We're more than just a build-first tech unicorn. We're a revolutionary shopping platform where brands and consumers come together for a loyalty-driving, points-exploding, money-saving party.
 Join a fast-growing, founder-led technology company that's still only in its early innings. Ranked one of America's Best Startup Employers by Forbes two years in a row, Fetch is building a people-first culture rooted in trust and accountability. How do we do it? By empowering employees to think big, challenge ideas, and find new ways to bring the fun to Fetch. So what are you waiting for? Apply to join our rocketship today!
 Fetch is an equal employment opportunity employer.

 The Role:
 The data engineering team is working to use all the latest technology to build a performant, reliable, and scalable platform for delivering data. The work of data engineers is to enable all stakeholders to be able to access and use endless amounts of data that come from an ever-growing variety of data sources. At fetch our motto is to make data processing appear seamless and effortless for both producers and consumers of data. With a goal of having world class data availability with terabytes of daily data, data engineering is critical to Fetch's success.
 The ideal candidate:

Python programming skills
Solid SQL skills
Familiarity with Unix systems, shell scripting, and Git
Experience with relational (SQL), non-relational (NoSQL), and/or object data stores (e.g., Snowflake, MongoDB, S3, HDFS, Postgres, Redis, DynamoDB)
Experience working with streaming data in Kafka and Flink
Interest in building and experimenting with different tools and tech, and sharing your learnings with the broader organization
The desire to work with other teams in the organization (e.g., Development, Business Intelligence, Data Science) to build tools and solutions that support and help manage data within the Fetch ecosystem
Bachelor's degree in Computer Science (or equivalent)
Bonus points for:

Excellent written and verbal communication skills
Familiarity with open source software and dependency management
ETL process, data pipeline, and/or microservice development experience
Cloud engineering and DevOps skills (e.g., AWS, CloudFormation, Docker)
Familiarity with messaging and asynchronous technologies (e.g., SQS, Kinesis, RabbitMQ, Kafka)
Big data development skills (e.g., Spark, Hadoop, MPP DW)
Experience with visualization tools (e.g., Tableau)


At Fetch, we'll give you the tools to feel healthy, happy and secure through:

Stock Options for everyone
401k Match: Dollar-for-dollar match up to 4%.
Benefits for humans and pets: We offer comprehensive medical, dental and vision plans for everyone including your pets.
Continuing Education: Fetch provides Ten Thousand per year in education reimbursement.
Employee Resource Groups: Take part in employee-led groups that are centered around fostering a diverse and inclusive workplace through events, dialogue and advocacy. The ERGs participate in our Inclusion Council with members of executive leadership.
Paid Time Off: On top of our flexible PTO, Fetch observes 9 paid holidays, including Juneteenth and Indigenous People's Day, as well as our year-end week-long break.
Robust Leave Policies: 18 weeks of paid parental leave for primary caregivers, 12 weeks for secondary caregivers, and a flexible return to work schedule.
Hybrid Work Environment: Collaborate with your team in one of our stunning offices in Madison, Birmingham, or Chicago. We'll ensure you are equally equipped with the hardware and software you need to get your job done in the comfort of your home."
Data Engineer,Prescient,"Chicago, IL 60601 (Loop area)",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=8b3ba7347a0244f9&fccid=184eeb1455c03c16&vjs=3,"TITLE: Data Engineer

 PRACTICE AREA: Cyber

 LOCATION: All Offices or Remote

 REPORTS TO: Managing Director & Practice Lead

 FLSA: Exempt

 WHY PRESCIENT?

 Prescient is a global risk management and intelligence services firm. Our Due Diligence, Investigations, Cyber, and Intelligence Practices help Fortune 500 companies, law firms, and financial institutions mitigate risk and uncover mission-critical information. Headquartered in Chicago, IL with offices in Arlington, VA; New York, NY; Los Angeles, CA and Dublin, Ireland, Prescient’s team of former military personnel, intelligence officers, law enforcement agents, and corporate investigators is proficient in multiple foreign languages and has decades of experience conducting due diligence, corporate investigations, and intelligence collection operations in over 110 countries. We provide stakeholders with actionable information to address challenges related to compliance, investments, physical & cyber security, and litigation, among others.

 POSITION SUMMARY

 The Data Engineer will play a critical role in designing, building, and maintaining our in-house dark web and open-source data repositories, search applications, and APIs. They will also work closely with a cross-functional team to improve and maintain the reliability, scalability, and performance of these tools and technologies. Expertise in data modeling, infrastructure design, and data integration will be essential in driving our search application development and enhancing our data.

 ESSENTIAL JOB FUNCTIONS

 Data Engineers will generally:


 Design and develop scalable search applications to enable efficient data retrieval and indexing from the deep and dark web.
Work with internal and external stakeholders to optimize data infrastructure and identify cost savings, where possible. 
Build and maintain data pipelines to ingest, transform, and process large volumes of open, deep, and dark web data from diverse sources.
Develop and maintain API endpoints for querying dark web data, ensuring efficient and reliable access to our systems.
Monitor and optimize search performance, address bottlenecks, and implement enhancements.
Implement data quality and validation measures to ensure accuracy and integrity of indexed data.
Identify and integrate optimal database solutions.



 DESIRED QUALIFICATIONS


 Proficiency in working with large-scale data processing frameworks, especially Elasticsearch
Solid understanding of data modeling and schema design principles for efficient search and retrieval


Familiarity with open source intelligence (OSINT) and/or dark web intelligence collection and/or processes


Experience with API development and management, including authentication, versioning, and performance optimization
Proven experience as a Data Engineer, preferably in the development and management of search engines and APIs
Demonstrated knowledge of cloud platforms, especially AWS and Azure 
Excellent communication and collaboration skills to work effectively in a cross-functional team environment
Familiarity with building CI/CD pipelines to ensure the delivery of high-quality software
Knowledge of data privacy and security considerations when working with sensitive data
Strong programming skills in Python



 EDUCATION & EXPERIENCE REQUIREMENTS

 To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable accommodations may be made to enable individuals with disabilities to perform essential functions.

 While not required, candidates will typically have a Bachelor's or Master's degree in Computer Science, Data Science, or a related field.

 PHYSICAL & SAFETY EXPECTATIONS

 When physical requirements are not essential job functions, reasonable accommodations may be made for individuals with disabilities.


 Prolonged periods of sitting at a desk and working on a computer.
Must be able to lift up to 5 pounds at times.
Ability to see, hear and speak continuously at a level to meet all essential functions of the job.
Physical work is of light demand. 
Work is of high attention and mental demands including the ability to prioritize and process with accuracy.



 HOW TO APPLY

 Resume
 Cover Letter

 You will receive an auto reply confirming that we’ve received your application. NO FOLLOW UP PHONE CALLS OR EMAILS, PLEASE. We pride ourselves on responding to every applicant, but that sort of diligent review takes time. If you receive a confirmation message from our system, we’ll get back to you soon.


 Prescient provides equal employment opportunities to all employees and applicants."
Data Engineer - Data & Analytics,McDonald's Corporation,"Chicago, IL 60607 (West Town area)",Posted 12 days ago,Full-time,https://www.indeed.com/rc/clk?jk=6d1535c0d70c2c15&fccid=f753bb1a40104d82&vjs=3,"Company Description
  McDonald’s evolving Accelerating the Arches growth strategy puts our customers and people first, and uses our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.
 Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development) Our growth pillars emphasize the meaningful role technology plays as the leading, global omni-channel restaurant brand. Technology enables the organization through digital technology, and improving the customer, crew and employee experience each and every day.
 Global Technology forging the way Leading the digitization of our business is the Technology organization made up of intrapreneurs who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of cutting-edge opportunities for the business. At McDonald’s you get to solve technology innovation challenges at an incredible scale, and work across global teams who are always eager for a challenge. This provides access to exciting career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.



 Job Description
  McDonald’s Global Technology – Data & Analytics team is looking to hire a Data Engineer who has a deep understanding of Data Product Lifecycle, Standards and Practices. You will be responsible for building scalable and efficient data solutions to support the company's data products and analytics initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Your expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role in delivering high-quality data products and enabling data-driven decision-making.
 Responsibilities:

 Builds and maintains relevant and reliable data products that support the business needs. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
 Participates in new software development engineering. Helps to define business rules that determines the quality of data, assists the product owner in writing test scripts that validates business rules, and performs detailed and rigorous testing to ensure data quality
 Develops a solid understanding of the technical details of data domains, and clearly understands what business problems are being solved
 Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).
 Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.
 Collaborating with data scientists and analysts to understand data requirements and ensure data accuracy, integrity, and availability.
 Building and optimizing data integration workflows to connect data from different systems and platforms.
 Monitoring and troubleshooting data pipelines, identifying and resolving performance issues and bottlenecks.
 Ensuring data security and compliance with data governance policies and regulations.
 Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.
 Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to improve data systems and processes.
 Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
 Ability and flexibility to coordinate and work with teams distributed across time zones, as needed. For instance, early morning/late evening hours to coordinate with teams in India




 Qualifications
  Requirements:

 Bachelor's or Master's degree in Computer Science or related engineering field and deep experience with AWS infrastructure
 5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.
 7+ years of proficiency in programming languages commonly used in data engineering, such as Python.
 3+ years of hands-on experience with big data processing frameworks, such as Apache Spark.
 5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.
 Working knowledge of relational and dimensional data design and modeling in a large multi-platform data environment
 Solid understanding of SQL and database concepts.
 Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
 Expert Knowledge of data, master data and metadata related standards, processes and technology
 Ability to drive continuous data management quality (i.e. timeliness, completeness, accuracy) through defined and governed principles
 Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
 Demonstrated experience in data management & data governance capabilities
 Familiarity with data warehousing principles and best practices.
 Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
 Excellent communication and collaboration skills to work effectively in cross-functional teams.

 Preferred Requirements:

 Experience with JIRA and Confluence as part of project workflow and documentation tools is a plus
 Experience with Agile project management methods and terminology a plus
 Experience with Prometheus, Grafana

 Additional Information
  McDonald’s is committed to providing qualified individuals with reasonable accommodations to perform the essential functions of their jobs. Additionally, if you (or another applicant of whom you are aware) require assistance accessing or reading this job posting or otherwise seek assistance in the application process, please contact recruiting.supportteam@us.mcd.com
 McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
 Nothing in this job posting or description should be construed as an offer or guarantee of employment."
Data Engineer,"SWJ TECHNOLOGY, LLC","Chicago, IL 60601 (Loop area)",PostedToday,Full-time,https://www.indeed.com/rc/clk?jk=e274d0ded25f18e3&fccid=c029a9eaa5362fd0&vjs=3,"Responsible for construction and development of ""large-scale cloud data processing systems"" The Data Engineer must have experience in data warehousing and the job requires coding experience with Python and/or Java, SQL, and familiarity with Spark languages. Must be able to understand and implement enterprise cloud data architecture designs, and will work closely with the Agile/scrum team and business partners to identify, evaluate, design, and implement large scale data solutions. The Data Engineer will work iteratively on a cloud platform to develop and implement scalable, high performance data solutions that offer measurable business value to customers. This role must be able to break down complex functional and technical requirements into independent coding tasks and strategies. This role will participate in Agile ceremonies and routines and is required to attend and contribute to daily standups, sprint planning, sprint demos/retrospectives. The Data Engineer will participate in design and code reviews, be responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing existing data flows.
 Qualifications and Education: Technology certifications preferred Bachelor's in computer engineering or equivalent field or equivalent foreign degree required
 Required Work Experience:

 3 years of experience required.
 Some of the minimum experience requirements may be met with bachelors or other advanced degree.
 Cloud Experience preferred
 Coding experience with SQL and Python required
 Coding experience with Java and Spark a plus
 Linux/Unix background and hands on knowledge.
 Past experience with big data technologies like HDFS, Spark, Impala, Hive
 Experience with Shell scripting and bash.
 Experience with version control platform github
 Experience unit testing code.
 Experience with development ecosystem such as Jenkins, Artifactory, CI/CD, and Terraform.
 Experience with RDBMS systems and/or large scale data.
 Works on problems of diverse scope and complexity ranging from moderate to substantial
 Assists senior professionals in determining methods and procedures for new tasks
 Leads basic or moderately complex projects/activities on semi-regular basis
 Must possess excellent written and verbal communication skills
 Ability to understand and analyze complex data sets
 Exercises independent judgment on basic or moderately complex issues regarding job and related tasks
 Makes recommendations to management on new processes, tools and techniques, or development of new products and services
 Makes decisions regarding daily priorities for a work group; provides guidance to and/or assists staff on non-routine or escalated issues
 Decisions have a moderate impact on operations within a department
 Works under minimal supervision, uses independent judgment requiring analysis of variable factors
 Requires little instruction on day-to-day work and general direction on more complex tasks and projects
 Collaborates with senior professionals in the development of methods, techniques and analytical approach
 Ability to advise management on approaches to optimize for data platform success.
 Able to effectively communicate highly technical information to numerous audiences, including management, the user community, and less-experienced staff.
 Consistently communicate on status of project deliverables
 Consistently provide work effort estimates to management to assist in setting priorities
 Deliver timely work in accordance with estimates
 Solve problems as they arise and communicate potential roadblocks to manage expectations
 Adhere strictly to all security policies

 Desired Work Experience:

 Proficient in multiple programming languages, frameworks, domains, and tools.
 Experience with gcp platform development tools Pub/sub, cloud storage, big table, big query, data flow, data proc, and composer desired.
 Knowledge in Hadoop and cloud platforms and surrounding ecosystems.
 Ability to document designs and concepts
 Able to collaborate with scrum team including scrum master, product owner, data analysts, Quality Assurance, business owners, and data architecture to produce the best possible end products
 Experience contributing to and leveraging jira and confluence.
 Ability to work with different file formats like Avro, Parquet, and JSON.
 Managing and scheduling batch jobs.
 Hands on experience in Analysis, Design, Coding and Testing phases of Software Development Life Cycle (SDLC).

 Education:

 High school diploma/GED with 2 years of experience, or Associate's degree, or Bachelor's degree required.

 Work Experience:

 3 years of experience preferred.


 FLSA STATUS/WORKING SCHEDULE:



 Location: Chicago, IL
 Schedule: Day Shift 
Core Hours: 8:00 am – 5:00 pm / Monday – Friday
 Weekly Overtime: If Needed 
Weekend Work: If Needed 
Travel: None
 Assignment Start: ASAP




 DISCLAIMER:
 This job description is a high-level overview of general expectations of this position. It is not intended to list every responsibility of the position, nor does it represent an employment contract of any kind.
 SWJ TECHNOLOGY and all of its subsidiaries (i.e., NGE EQUIPMENT and ProjectOne US) are Equal Opportunity Employers and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender, disability status, protected veteran status, or any other characteristic protected by law.
 
InC1C2uTin"
Data Engineer,Fooda,"Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=652fce2c21b3d561&fccid=9d5796b859dfc328&vjs=3,"Who We Are:
 We believe a workplace food program is something employees should love and look forward to every day. Powered by technology and a network of over 1,400 restaurants, Fooda feeds hungry people at work through our ongoing food programs located within companies and office buildings. Every day each Fooda location is served by a different restaurant that comes onsite and serves fresh lunch from their chef’s unique menu. Now with over 50 million meals sold, Fooda operates in major cities across the U.S. Eight out of ten employees believe Fooda is one of their company’s top perks.
 Why Choose Fooda?
 Do you dream of complex problems that stretch your imagination and force you to grow as a problem solver? We are a close-knit product development team of engineers, PMs and data scientists, tackling technical problems around scaling, rapid user acquisition, machine learning and optimization challenges in every vertical, every single day. 
Like most businesses, we have been impacted by the COVID-19 pandemic. We’re using this opportunity to expand into sectors like healthcare and manufacturing, and focus our team on the most impactful projects so we can serve our diners safely and help our restaurant partners weather this time.
 As we expand our technology platform and explore new market segments, we are breaking ground and building functional and useful products for independent restaurants across the country. This allows Fooda to help mom & pop shops expand their own businesses and deliver great food to people looking for more local and exciting food options.
 About the Team:
 Our Data Science & Analytics team is changing the way Fooda uses data. Do you want to get in on the ground floor of an analytics team at a high growth startup? The company has placed a huge strategic focus on building out our data science and analytics capabilities and you will be core to this growth. The team is responsible for all reporting & analytics for the company partnering closely with Product, Engineering, Sales, Marketing, Finance, and Operations to drive innovative analytic solutions.
 Will you join us?
 Position Opportunities and Responsibilities:
 As a Data Engineer, you will work on the Data Science and Analytics team to drive and evolve the analytics solutions and data systems at Fooda. You will contribute to analytics decision making, analysis, and data integration to enable Fooda to become a world-class data driven organization. 
What You Will Be Doing: 

Leverage Python and SQL to integrate and analyze data from internal and external systems that drive key business decisions throughout the organization
 Govern, analyze, and own data that drives stakeholders’ perception of the organization, which involves diving in, addressing questions, and perform root cause analysis of issues that arise within the data
 Develop ETL pipelines and data quality auditing systems using Airflow, Python, and SQL to create a cohesive, automated, and accurate data environment
 Assist in requirements gathering, design, and development of complex data systems that collect, analyze, and measure data throughout all business units
 Build automated data products and tools for internal and external stakeholders to drive engagement across Fooda
 Solve complex technical data problems to deliver insights and efficiencies to help the busines achieve growth goals across all functions
 Ingest, translate, and decode large volumes of data to enable a data driven culture across all levels of Fooda’s organization
 Collaborate with other members of the Data Team to ensure data integrity and quality of deliverables
 Consistently look for additional methods and ways to improve the data transformations and data consumption processes to ensure all internal systems are working efficiently

 What You Should Already Have: 

2+ years of experience working in data engineering, business intelligence, or engineering
 Bachelor’s Degree (Preferably in a quantitative field such as:Information Systems, Computer Science, Statistics, or Mathematics)
 Experience analyzing and integrating data using Python and SQL to extract and transform data according to business rules and requirements
 Extensive knowledge and experience working with large scale data warehouse, web APIs, and database platforms to integrate internal and external data sources
 Experience with programing/scripting languages and data science tools (Airflow, Python, Java, Spark)
 Experience diving into data quality and data profiling analysis to ensure data consistency and accuracy across enterprise reporting
 Experience with AWS tools and infrastructure to build and maintain a robust data warehouse
 Strong attention to detail and the ability to think critically and solve problems using analytical and quantitative methodologies
 Strong oral/written communication skills, specifically the ability to communicate and translate difficult analytical problems to stakeholders with minimal analytics background
 Ability to work effectively in a high paced environment with multiple priorities

 What We’ll Hook You Up With:

 Competitive market salary and stock options, based on experience
 Unlimited vacation 
Comprehensive health, dental and vision plans
 401k retirement plan with company match
 Paid maternity and parental leave benefits
 Flexible spending accounts
 A fulfilling, challenging adventure of a work experience
 Daily subsidized lunch program (ours!) and plenty of food and beverages in the office

 Must be authorized to work in the United States on a full-time basis. No phone calls or recruiters please.
 
fouS3E5YSO"
Data Engineer,Sky Consulting Inc,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=69c97f2cd1eacae8&fccid=992f3763834d395e&vjs=3,"Evaluate and experiment with novel data engineering tools and advises information technology leads and partners about new capabilities to determine optimal solutions for particular technical problems or designated use cases / Big data engineering skills: 
5+ years of hands-on experience in one or more modern Object-Oriented Programming languages (Java, Scala, Python) including the ability to code in more than one programming language. 
5+ years of hands-on experience applying principles, best practices, and trade-offs of schema design to different database systems, including relational (Oracle, MSSQL, Postgres, MySQL) and NoSQL (HBase, Cassandra, MongoDB) 
2+ years of hands-on experience implementing batch and real-time data integration frameworks and/or applications in private or public cloud environments (AWS, Azure, GCP, etc.) using various technologies (Hadoop, Spark, Impala, etc.), including assessing performance, debugging, and fine-tuning those systems 
2+ years of hands-on experience in developing enterprise level APIs leveraging python web frameworks, like Flask. 
Deep understanding of the latest data science and data engineering methods and processes to develop impactful and reusable patterns and abstractions from enterprise-level data assets 
3+ years of hands-on experience in all phases of data modeling from conceptualization to database optimization 
Demonstrated ability to perform the engineering necessary to acquire, ingest, cleanse, integrate, and structure massive volumes of data from multiple sources and systems into enterprise analytics platforms 
Proven ability to design and optimize queries to build scalable, modular, efficient data pipelines 
Ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets 
Proven experience delivering production-ready data engineering solutions, including requirements definition, architecture selection, prototype development, debugging, unit-testing, deployment, support, and maintenance 
Ability to operate with a variety of data engineering tools and technologies; vendor agnostic candidates preferred Domain and industry knowledge: 
Strong collaboration and communication skills to work within and across technology teams and business units 
Demonstrates the curiosity, interpersonal abilities, and organizational skills necessary to serve as a consulting partner, includes the ability to uncover, understand, and assess the needs of various business stakeholders 
Experience with problem discovery, solution design, and insight delivery that involves frequent interaction, education, engagement, and evangelism with senior executives"
Data Engineer,Starcom,"Chicago, IL (The Loop area)",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=7f44354059cca9a7&fccid=360b1f39dea9725f&vjs=3,"Company Description
  As the Human Experience Company, we are a global media agency that believes in the alchemy of people and technology to create experiences people love and actions brands need. It’s in our DNA. We’re powered by the strength of our innovative, driven and, intelligent people who are deeply passionate about achieving best-in-class results on behalf of our clients –some of the world’s leading marketers.
 We value you and the work you do. We work hard, but also enjoy scores of perks rooted in our legacy of having one of the strongest agency cultures. Our top-notch health insurance plans and paid time off allow you much-needed time to recharge and achieve the work-life balance you need to bring your absolute best self to work.



 Job Description
  Starcom is seeking a Data Engineer, a specialist in Microsoft SQL Server and Azure, to join its Analytics + Technology’s Engineering team. Candidate will contribute towards building custom data-driven applications for decision support, data exploration, and media activation. Candidate will provide support to media planners, buyers, and analysts, providing automation and incorporating their methodologies into applications for scaling across the organization.
 The Data Engineer role will contribute towards designing, developing, deploying, and supporting end-to-end solutions within our Hybrid (on-prem + Azure Cloud) infrastructure. This is a full stack engineering role. Custom solutions developed internally are used across the organization to help internal teams optimize media planning and buying.
 With responsibilities across multiple clients, this candidate will gain exposure to a variety of strategic business problems and the opportunity to contribute to our team’s set of innovative methods to solve them.
 Experience:

 BA/BS in Computer Science or a related degree


 3+ year building relational databases, ETL packages with in-depth understanding of theories, principles, and practices.


 2+ year experience working in Azure
 Azure certification on Data Engineering or Synapse Analytics preferred

 Core Skills

 Must have experience designing, implementing, and managing ETL packages using SQL Server Integration Services (SSIS)
 Excellent understanding of SQL database engine, query tuning, database objects and structures
 Production support of automated jobs/packages and related database servers.
 Migrate/Import data from various sources into a uniform SQL Server database schema
 Optimize database scripts, data storage, and packages to improve application performance.
 Strong understanding and experience of RESTful API's.
 Prior experience working in Azure Synapse Analytics
 Experience in managing data pipelines and workflows within Azure.




 Qualifications
  Functional Role:

 Excellent at working with cross-functional teams to develop use cases and propose engineering solutions.


 Ability to rapidly brainstorm and develop testable ideas alone or with teams.
 Highly effective communicator, both spoken and written


 Key role in testing and deployment


 Self-reliant, demonstrated desire to take ownership of projects
 Ability to prioritize and manage concurrent projects
 Demonstrate initiative and work independently with minimal supervision

 Valued Skills

 Expertise in Azure management, including VMs, Compute/App Engine, Storage, and Security
 Experience in Azure Data Lake, Azure Data Factory, Azure Data Flow, and Azure Functions a big plus
 Database application and process development using scripting using languages such as R, Python, PySpark
 Best practices on managing enterprise data assets

 Additional Information
  All your information will be kept confidential according to EEO guidelines."
Data Engineer,Fishawack Health,"Chicago, IL 60661 (Near West Side area)",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=88cc6609d65fc86c&fccid=2fb7e6aba188d2e4&vjs=3,"Job Title: Data Engineer 
Salary: $Competitive + excellent benefits (bonus, pension, healthcare, life cover etc.) 
Location: Chicago, Washington D.C. New York, or Pennsylvania (US), Hybrid

 About the role 
The Data Engineer is an experienced developer in data engineering and architecture. You will have a focus on data automation and standardization in the service of internal customers such as Data Science and Strategy. You will consistently balance the delivery of client work with the execution of internal data engineering efforts, which create sustainability, innovation and reliability across all clients’ data and analytics needs. This role is a key player in driving forward core components of our data and analytics platform in collaboration with cross-functional stakeholders. You must exhibit strong technical skills and serve as a subject matter expert on data solutions.
 About Fishawack Health
 Fishawack Health is the leading global commercialization partner for the modern life science era. Established in 2001 and headquartered in the UK, the organization is powered by a 1,300+ globe-spanning pack of strategic, creative, and scientific experts. We empower healthcare professionals and patients with the knowledge they need to live better lives.
 Our core operating units—Medical, Marketing, Market Access, and Consulting—bring together best-in-class capabilities from around the world. We empower our pharmaceutical, biotech, and medical technology clients to navigate the most complex of ecosystems, helping them on an effective path to develop, launch, and grow their brands, services, and portfolios.
 Our internationally recognized, award-winning teams collaborate across operations in the UK (Brighton, Fleet, London, Knutsford, Manchester, Oxford, and Sale), Ireland (Dublin), USA (Chicago, Evansville, Minneapolis, New York, Philadelphia, San Diego, Scottsdale, and St. Louis), Greece (Athens), and Singapore.

 What you’ll do 

Executes the design and implementation of various data architecture layers including ingestion, cleansing, unification, and consumption in order to meet the needs of our customers
 Collaborates with cross-functional stakeholders such as Data Scientists, Business Analysts, Project Managers, Media Operations and Quality Assurance to achieve expected results
 Builds, maintains, and distributes technical documentation across all data engineering work
 Proactively identifies and capitalizes on opportunities for efficiency, sustainability, innovation, and standardization through efforts such as data consolidation and automation
 Keeps up to date with the latest trends in data engineering and takes lead on leveraging new technologies and innovations relevant to the business
 Oversees and participates in day-to-day engineering tasks, break/fix routines and code reviews
 Understands and complies with compliance and security standards such as HIPAA, GDPR and CCPA
 Identifies risks with solutions while developing, proposing and implementing mitigation plans
 Works closely with Quality Assurance on data quality, relevant training, test cases and planning

 About you 

4 years of experience in data engineering with strong emphasis on complex SQL and DB design
 Experience with marketing analytics tools such as Google Analytics, Google Campaign Manager, and Facebook Ads
 Experience in a digital Marketing Agency preferred
 2 years of experience developing highly custom, automated ETL procedures and data pipelines 
2 years of experience building, designing, and architecting data solutions in support of advanced analytics, complex algorithms, and sophisticated data science modeling work 
Proficient with GCP (Google Cloud Platform), BigQuery, Postgres and data pipeline tools
 Proficient with Git version control systems and release/change management processes
 Proficient data warehousing, performance turning, data security, auditing and encryption
 Proficient translating high-level business requirements into data solutions
 Proficient with the full software development lifecycle from inception to deployment
 Excellent written and verbal communicator particularly with non-technical stakeholders

 Preferred Qualifications:

 BS/BA degree or higher in computer science, mathematics, or related field
 Experience working at a healthcare agency in a hybrid agile/waterfall environment
 Cloud engineering experience including infrastructure maintenance and IAM
 Experience with marketing analytics tools such as GA, GCM, and Facebook Ads
 Experience leveraging continuous integration methods
 Experience with HIPAA compliance and related security measures
 Experience programming with object-oriented methodologies
 Experience with web technologies such as HTML, CSS, and JavaScript


 What we can offer 
We offer a creative, supportive environment with a uniquely diverse career structure, where you will be able to develop and tailor your career towards your preferred route. Our Fuel50 talent experience platform will enable you to pick and map a career journey across the organisation, providing you with the option to progress within different areas of your team or beyond. Our Pack Academy provides a broad range of training delivered live and on-demand, which supplements on-the-job training and project team-led initiatives. We also offer a generous company pension, private medical insurance, various employee wellbeing initiatives, plus many other excellent employee benefits. 
Reasonable adjustments
 Fishawack Health is an equal opportunities employer and place where everyone is welcome. We believe success lies in our differences and only by embracing these differences can we build a healthier world together. We strongly encourage people from minority backgrounds, LGBTQIA+, parents, and individuals with disabilities to apply. If you need reasonable adjustments at any point in the application or interview process, please let us know. In your application, please feel free to note which pronouns you use (For example - she/her/hers, he/him/his, they/them/theirs, etc).
 We encourage all applicants to read our company Privacy Policy before applying to a role. 

g7tMdVxbeH"
Data Engineer - Consultant/Senior,"Lotis Blue Consulting, LLC","Hybrid remote in Chicago, IL 60606",PostedToday,,https://www.indeed.com/rc/clk?jk=8ebaec8e0c869ecd&fccid=98b462f8f2ffdd50&vjs=3,"DATA ENGINEER – CONSULTANT/SENIOR

 Lotis Blue Consulting is a growth advisory that helps clients grow and transform their organization to achieve their business goals. We apply expertise in behavioral and data science to set business and go-to-market strategy and then improve organization alignment to enable effective execution. We are looking for data and analytics-savvy professionals to join our Chicago-based team of consultants who have proven Data Engineering expertise and experience working with other data analysts and project resources. This role is client-facing and will be a fully-fledged member of the client service project team helping us to identify, understand and solve complex problems.
  

PRIMARY RESPONSIBILITIES


Work with the Lotis Blue team to develop hypotheses that explain business problems or opportunities, and then create the analytical work plan to test them
Create and manage highly structured data requests that acquire the right information in the right format to execute on the analytical work plan
Serve as lead point of contact with the client and be accountable for all matters related to data acquisition, cleaning, integration, management, transformation, interpretation, and analytics
Work with Power BI or Tableau to present and visualize new insights or reveal complex relationships between variables in a clear, accurate, and compelling manner that supports evolving ideation
Lead discussions internally around the relationship between different data elements to add to the Lotis Blue team’s knowledge, awareness, clarity, and depth in addressing the client situation and potential solutions
Develop and provide meaningful insights and relevant points-of-view on complex concepts directly to clients through simple, plainspoken materials
Contribute to leading-edge thinking that deepens the Firm’s capabilities in data science and engineering and differentiates Lotis Blue in the market


QUALIFICATIONS & EXPERIENCES


Bachelor’s degree in computer science, mathematics, engineering or related field
At least two years of experience working on an analytics or data science team
Experience communicating directly with clients and addressing business problems through analytics
Passion for learning and track record of keeping up to date on technologies, platforms, and tools
Some travel may be required


REQUIRED KNOWLEDGE, SKILLS & CAPABILITIES


Business acumen
Teamwork and collaboration
Critical thinking and ideation
Project management
Experience with and capability to execute on:
Production databases (e.g., SQL Server, MongoDB) and related administrative tools (e.g., SQL Management Studio, Navicat)
Python (preferable) or R
Business Intelligence tools (e.g., Power BI, Tableau)


PREFERRED KNOWLEDGE, SKILLS & CAPABILITIES


Working knowledge of Azure
Experience managing databases in the cloud (as well as AWS)
Working knowledge of data transformation tools (e.g., Alteryx)
Experience operationalizing data pipelines to support analytics in a production environment
Coursework or qualification in Machine Learning
Experience applying ML techniques in real world business scenarios


The candidate will be expected to pass a remote assessment on data structure and manipulation using SQL before we initiate the interview process.


PLEASE NOTE

 We are unable to consider any applicants without US citizenship or a green card.
   This is a hybrid position located in our downtown Chicago office."
Staff Software Engineer- Data Production,Supernova Technology,"Hybrid remote in Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=f8fb1e1a1555fd8b&fccid=471faeeea68f405d&vjs=3,"ABOUT US


   Founded in 2014, we offer the industry’s first and only cloud-based, fully-customizable, end-to-end software solution to automate securities-based lending from origination through the life of the loan. By combining thought leadership in suitability and risk management with industry-leading education and the latest technology, Supernova enables advisors to deliver holistic, goals-based advice and to help their clients achieve financial wellness. We partner with the industry’s largest banks, most prominent insurance companies and leading online brokerages to democratize access to securities-based lending and better the entire financial ecosystem.
 


 JOB DESCRIPTION


   At Supernova, we are dedicated to providing cutting-edge technology solutions that empower businesses and individuals to achieve their full potential. We are seeking an experienced and highly motivated Staff Software Engineer for our Data Production team and contribute to the continuous improvement of ETL job development and management. 
 
RESPONSIBILITIES: 

Collaborating with architects, other dev team leads, product owners, and other stakeholders to define and implement overall ETL job management and development strategy. The strategy should focus on ease of use, on overall low maintenance overhead, and align well on the requirement of high code quality.
 Leading, mentoring, and managing a team of software engineers responsible for the design, development, and maintenance of ETL jobs following the strategy above. Lead the team to design and implement effective job monitoring solution to help efficient issue diagnosing and prompt job status warning.
 Participating in architecture and design discussions, contributing to the overall technical vision and direction of the team. Making good technical design trade-offs based on the experience, juggling among costs, delivery timeline, immediate business impact and possibility of future extension.
 Reviewing code, providing constructive feedback, and ensuring adherence to coding standards and guidelines. 
Identifying and addressing technical debt, refactoring code, and driving improvements in the team's software development processes and practices. 

QUALIFICATIONS:

 Bachelor's degree in Computer Science, Engineering, or a related field. A Master's degree is a plus
 5+ years of software development experience, with a focus on ETL jobs and performance tuning. Experience in DB design is a plus
 2+ years of experience managing or leading a team of software engineers
 Strong problem-solving skills, attention to detail, and ability to work independently and collaboratively.Excellent communication and interpersonal skills
 Proficiency in Python and the user of Pandas. Experience in Java or other object oriented language is a plus. Experience with MyBatis and flyway is a plus
 Experience with version control systems (e.g., Git) and CI/CD pipelines
 Experience with TDD and mocking frameworks used with Python 


Knowledge of microservices architecture and containerization technologies (e.g., Docker, Kubernetes) preferred
 Hands-on experience with MySql or AWS Aurora RDS equivalent preferred
 Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and related services preferred


 OUR CORE VALUES


 At Supernova, we...


Form, execute, and communicate new ideas that add value to our employees and customers
Strive through obstacles and failures
Follow-through on promises or commitments to others, accept responsibility, and answer for actions & decisions
Listen to, understand, and support our employees and customers
Act with speed, positive attitude, and flexibility
Exceed expectations and surpass ourselves every day; we embrace a sense of pride and never stop growing"
"Sr. Data Engineer, Data & Decision Intelligence","fairlife, LLC","Chicago, IL 60607 (Near West Side area)",Posted 9 days ago,Full-time,https://www.indeed.com/rc/clk?jk=fb5404b832e00036&fccid=c80d0248edb95adc&vjs=3,"company information
 fairlife, LLC is a Chicago-based dairy company that creates great-tasting, nutrition-rich and value-added products to nourish consumers.
 With more than $1B in annual retail sales, fairlife’s growing portfolio of delicious, lactose-free, real dairy products includes: fairlife® ultra-filtered milk; Core Power® High Protein Shakes, a sports nutrition drink to support post-workout recovery; fairlife® nutrition plan™, a nutrition shake to support the journey to better health.
 A wholly owned subsidiary of The Coca-Cola company, fairlife, LLC has been recognized by both Fast Company and Nielsen for its industry leading innovation.
 The company is driven by its values of caring for people, the animals that supply us with milk, and the planet. By providing nourishing products, implementing stringent care standards for animals, and stewarding efficient operations and responsible packaging, fairlife, LLC puts a focus each day on making a positive impact for all.
 To learn more about fairlife and its complete line of products, please visit fairlife.com.
 job purpose: 
The Sr. Data Engineer will play a key role in delivering fairlife's ambition of building a best-in-class Data and Decision Intelligence (DDI) ecosystem. This role will be directly responsible for the digital transformation of our manufacturing operation. This role is able to express strategic requirements for our factories and deliver solutions to meet those requirements, ensuring the solutions fit into fairlife’s broader data framework, roadmap and architecture. This role is responsible for the extract, transform, and load process of our factory IIoT data.
 responsibilities: 

Integration of factory data into on-premise and cloud-based Azure IoT tools to support consumption of real time and historical data
 Design, implement, and operationalize data pipelines to support the data lifecycle for our factory IIoT data
 Design, develop and deliver the platforms and tools needed for optimal extraction, transformation, and loading of factory IIoT data
 Support the development and delivery of a Factory Data Model for our factories
 Develop and deliver master data solution for managing and onboarding industrial devices/assets into our data ecosystem
 Design and deliver solutions to support real-time factory data streaming, condition monitoring, and predictive maintenance
 Working closely with 3rd party data architects and internal data team to develop deep understanding of our data ecosystem
 Collaborating and coordinating with multiple departments, stakeholders, partners, and external vendors
 Provide training and support the technical development of fellow team members

 skills/qualifications required: 

Bachelor's degree in data science, management information systems or related
 AND 5+ years relevant work experience in data architecture capacity
 Experience with MES/factory level data is strongly preferred
 Strong working knowledge of established and emerging data management and reporting technologies and practices 
Proficiency with Azure, Azure IoT, Azure Edge, Azure Data Factory, SQL Server, T-SQL, Azure, Git, Dev Ops, Power BI, DAX
 Strong understanding of data warehousing and Kimball Methodology
 Experience leveraging other data development tools such as Visual Studio, DAX Studio and Tabular Editor 
Excellent communication and documentation skills
 Detailed oriented self-starter, with a growth mindset and a passion for data
 Ability to handle ambiguity and work in a fast paced, entrepreneurial environment

 position location: Chicago, IL
 reports to: Data Architect, Data & Decision Intelligence 
travel requirements: 20-30%
 fairlife, LLC is an equal opportunity employer. We do not discriminate on the basis of race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. All qualified applicants and employees will be given equal opportunity. Selection decisions are based on job-related factors.
 In addition to its nondiscrimination commitment, the Company will also provide reasonable accommodation of qualified individuals with known disabilities unless doing so would impose an undue hardship on the Company. If you have a disability and would like to request accommodation in order to apply for a position with us, please email careers@fairlife.com.
 
5nZ5gMXvt5"
Sr. Data Engineer,Wavicle Data Solutions,"Remote in Oak Brook, IL",Posted 1 day ago,Full-time,https://www.indeed.com/rc/clk?jk=f99ff2e69f8a875f&fccid=c6f867b4166b93af&vjs=3,"A BIT ABOUT WAVICLE



 Wavicle Data Solutions leverages Cloud, Data & Analytics technologies to deliver complex business & digital transformation solutions to our clients. As a Minority Business Enterprise (MBE) with a 40%+ women workforce, Wavicle fosters a diverse & equitable environment where innovative professionals come together as a team and enable our clients to realize their goals in their transformation journey. Our team members collaborate by infusing their creative problem solving skills, agile working & tech know-how to drive value for our clients.
 


 At Wavicle, a 
  Top Workplace award winner, you’ll find a challenging and rewarding work environment where our 500+ team members based in US, India Canada work from 42 cities in a remote/hybrid, digitally connected way. We offer a competitive benefits package that includes: healthcare, retirement, life insurance, short/long-term disability, unlimited paid time off, short-term incentive plans (annual bonus) and long-term incentive plans.
 


 WHY WAVICLE?



 Watch here to learn: https://vimeo.com/654661550
 


 THE OPPORTUNITY



 Wavicle Data Solutions, LLC seeks Sr. Data Engineer in Oak Brook, IL.
 
WHAT YOU WILL GET TO DO

 Create the conceptual, logical and physical data models.
 Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of sources like Hadoop, Spark, and AWS Lambda.
 Lead or mentor a small team of data engineers.
 Design, develop, test, deploy, maintain and improve data integration pipeline.
 Develop pipeline objects using Apache Spark, Pyspark, Python, or Scala.
 Design and develop data pipeline architectures using Hadoop, Spark and related AWS Services.
 Load and performance test data pipelines built using the above-mentioned technologies.
 Communicate effectively with client leadership and business stakeholders.
 Participate in proposal or SOW development.

 WHAT YOU BRING TO THE TEAM

 Master's degree in Computer Science, Computer Engineering, Computer Application, Management Information Systems, or a related field as well as 3+ years of experience in job offered or related roles.
 3+ years of experience in the following skills:
 Hadoop, Spark & AWS.
 Talend, Tableau & MicroStrategy.
 Apache, Spark & Pyspark.
 Python and Scala.



 Telecommuting Permitted within the US.
 


 This position is eligible for the employee referral program.
 


 Must also have authority to work permanently in the U.S. Applicants who are interested in this position may apply at jobpostingtoday.com, reference number 84907.
 

 EQUAL OPPORTUNITY EMPLOYER



 Wavicle is an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status."
Data Engineer,TMSW,"Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=99a19cdc247c449c&fccid=a396c9f65feb976e&vjs=3,"Overview: 
 
 A BIT ABOUT US


   The Marketing Store is a consumer engagement agency that believes in the power of experience to build brands. Experience is any valuable interaction between a brand and consumer, and it’s the currency of 21st century marketing; consumers are placing greater value on it, technology provides brands with greater opportunity to deliver, and it’s the key to unlocking huge growth.
 


 Our core skill is therefore transforming brands, products and services into experiences. To leave lasting impressions and influence future purchasing decisions.
 


 We do this through our expertise in the sharing of experience and the science of experience. Yet none of this can be achieved without our investment in people and culture. We’re committed to breaking down silos to create more efficient and better-connected working processes. That’s why we are a people-first agency, built to serve consumer-first brands.
 


 WHAT ARE OUR PEOPLE LIKE?


   Our agency is home to creative problem solvers. Those who overcome any obstacle to successfully put consumer-first ideas, products and technologies into market.
 


 People who wear their talent lightly. Willing to be part of a close community that pushes them to be better.
 


 Because our goal is to bring people and brands closer together. Closer insights, closer connections and closer collaboration breed better, more effective work. It’s this dedication to getting closer that drives us to go further.
 


 WHO WE WORK WITH


   We apply insightful, strategic, brand-building processes to the creation industry-leading, award-winning promotions, digital experiences, retail activations, CRM and loyalty programs, premiums and brand events.
 




  Our clients include McDonald’s, Nissan, Infiniti, T-Mobile and more!
 

 Responsibilities: 
 
 WHY WE THINK YOU WILL LOVE THIS ROLE


   This role will partner with Data & Decision Scientists to design, develop, and execute advanced software tool for the Data Science team and the agency. You will be responsible to efficiently implement and integrate data pipelines to power our analytic tool sets and deliverables. The position will span multiple brands and teams locally and globally to influence customer behavior across a multitude of marketing channels.
 




WHAT YOU WILL BRING TO THE AGENCY


   Keen on developing and building relationships, you are comfortable working with agency offices, partners, and various internal team members alike, and have excellent written and verbal communications skills with an ability to present complex solutions clearly.
 


 As a Data Engineer, you are a creative problem-solver by trade and have outstanding organizational skills, able to manage multiple responsibilities and deliverables simultaneously.
 




  Responsible for understanding industry trends and translate business requirements to analytical methods using data and software engineering best practices to drive positive shifts in customer behavior for our clients.
 


 RESPONSIBILITIES 


  This role will have a demonstrated track record in data modeling, ETL pipelines, and building high-performance and object-oriented, reusable code. It is critical that the candidate has experience designing modular data engineering capabilities to create advanced pipelines for clients.
 


 Digging deeper on the details:


 Works with members of the Data & Decision Science teams to design and lead the creation of an object-oriented, portable, scalable, robust, efficient, and testable library of data engineering capabilities. Key responsibilities include optimizing the following:
   
 Software architecture 
Software scalability and efficiency
 Selection of software stack
 Data model architecture
 Automation data pipelines
 Automation of testing
 Creation/integration of data abstraction layer

 Works with members of the Data & Decision Science team to transform requirements into automated solutions that deliver repeatable, testable, and scalable results
 Collaborates with Technology & Product teams to ensure seamless integration into broader initiatives
 Communicates unique insights uncovered through working with customer data
 Tracks and reports on initiatives, successes, and lessons learned, and packages outcomes for client-facing presentations


 Desired Skills & Experience: 
 
 SKILLS AND EXPERIENCE WE WOULD LIKE YOU TO HAVE


 1-3 years’ experience working with structured and un-structured data using tools such as SQL, Pandas, MapReduce, Spark, etc.
 1-3 years’ experience in delivering analytic results using tools such as Python, Spark, R, etc.
 Experience cleansing, manipulating, and transforming data
 Well versed in creating and conducting dynamic presentations
 Highly professional and presentable with a strong business acumen
 Highly collaborative with ability to build partnerships across different teams and people
 Innate curiosity and proven ability to connect insights and gain inspiration from disparate sources
 Highly organized and comfortable working in flexible, constantly evolving environments with tight turnaround times and shifting priorities



 And We’d Love If You Have:


 Familiarity with advanced analytics techniques (e.g., decision trees, regressions, neural networks, sentiment analysis, survival and time-series forecasting, collaborative filtering, etc.)
 1-3 years' experience designing and implementing high-performance software using tools such as C++, FORTRAN, MPI, OpenMP, CUDA, OpenCL, Python, etc 
Post-secondary education in a relevant field including Mathematics, Statistics, Computer Science Physics, Engineering, Economics, Business, or equivalent experience
 Experience in any of the following: business strategy and presentation, financial analysis, statistical analysis, and/or consumer market research would be an asset
 Examples to show of code/work initiatives in their career tenure
 Benefits: 
 
   The Marketing Store provides comprehensive benefits offerings to all full-time employees starting on day one. Our benefits include options for medical and dental insurance, 401(k) plan with Company matching provision, profit sharing, flexible spending accounts, tuition reimbursement, life insurance, health and wellness benefits (including discounts on products & services), employee assistance program, and disability insurance.
 




  Thank you for your interest in The Marketing Store. 
 

  Please note that we will only contact candidates who are selected for an interview. 
 

  The Marketing Store is an equal opportunity employer. 
 

  We do not accept unsolicited calls, resumes or candidate referrals from recruiters and agencies."
Test Data Management Engineer,Health Care Service Corporation,"Chicago, IL",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=15af730a7e9d42df&fccid=89564d5901dd5bfb&vjs=3,"This position is responsible for demonstrating a capable understanding of Test Data Management related to data security, data masking, synthetic data creation and test data strategy planning; working with teams to provide test data; creating synthetic data, perform data conditioning, macro creations for data generation, data masking, provisioning for data and mask data as needed; multi-tasking in an environment of changing priorities.


Required Job Qualifications:

Bachelor's degree required or combination of education and 2 years’ experience OR 4 years Information Technology experience


 
Preferred Job Qualifications:

Data Engineering Certification
Experience with Selenium Automation – novice
Python experience – capable
Experience with SQL database queries and programming – capable
Understanding of data masking concepts, with proven implementation experience. Familiarity with data quality, cleaning, and masking techniques -novice
Ability to diagnose diverse technical issues in a complex enterprise environment – capable
Organizational and time management skills, with the ability to manage workload and projects to navigate peaks, prioritize competing commitments, and complete assignments in accordance with established deadlines – capable
Attention to detail, follow-through, and customer focused orientation – capable
Analytical, decision making and problem-solving abilities, with demonstrated troubleshooting and debugging skills – capable
Ability to work independently, as well as collaboratively in a team environment – capable
Verbal and written communication, presentation, and interpersonal skills – capable
TDM functions including Data provisioning, sub setting, profiling, Data mining
Abilities with TDM masking tools
Macro generation for synthetic data creation
Scripting experience with Shell, Perl, .bat, VB Script, or any other scripting language experience

 BCBSTX complies with applicable Federal civil rights laws and does not discriminate on the basis of race, color, national origin, age, disability, or sex.
  XJ6"
Senior Data Engineer (remote),Ad Hoc Team,"Remote in Chicago, IL",Posted 28 days ago,"$101,570 - $136,994 a year",https://www.indeed.com/rc/clk?jk=91f232e7bf4e39e1&fccid=7707621c92754acd&vjs=3,"This is a fully remote position.
 Work on things that matter Ad Hoc is a digital services company that helps the federal government better serve people. Our teams use modern, agile methods to design and engineer government systems that connect Veterans with services, bring affordable health care to millions of people, and support important programs like Head Start. And as we work to make critical government services intuitive, accessible, and human-centered, we're also changing how the government thinks about and uses technology. If you thrive on change, want to help close the gap between consumer expectations and government services, and can see the possibilities in ambiguity, then we want you here with us.
 What matters most Ad Hoc operates according to our commitment to inclusivity, acceptance, accountability, and humility. We aren't heroes. We believe in missions larger than our individual selves and leave our egos at the door, learn from our mistakes, and iterate in order to better serve the people in our country. We prioritize building teams that represent the diversity of the people our government serves. We love the challenge of government-size projects. We want to bring skills to federal agencies, help them better meet the needs of their users, and close the gap between consumer expectations and government.
 Built for a remote life Ad Hoc is remote-first and remote-always. We've designed our culture, communications, and tools to support a nationwide distributed team since the beginning. Being remote by design allows Ad Hoc to be thoughtful and intentional about creating diverse teams and supporting them with a work environment that fits their lives. With a generous PTO policy and Slack channels for every interest (from bird watching to space nerds to parenting) our culture embraces the things happening in your life. Maybe you need to adjust your schedule to care for your family or take a bike ride. At Ad Hoc, that's embraced.
 What you'll do
 Our ideal Back End Software Engineer knows how to build large-scale production systems in modern agile environments. They write well-structured, tested, and secure code with little feedback or guidance. They've designed and implemented reliable and maintainable APIs and built services that integrate with external dependencies. They can articulate how the thing they've built fits into a larger ecosystem. They're not afraid of large, complex problems. They take an active role in planning and delivery efforts, drawing on their experience to suggest better approaches or alternatives. As an Ad Hoc Back End Engineer, you'll be:

Shipping software that impacts the lives of millions of people
Using modern programming languages and frameworks to build scalable services that gracefully integrate with legacy systems
Building and working with APIs to support both the digital services we deliver as well as third-party usage
Using unit and integration testing to ensure systems work as intended
Helping us continuously, iteratively improve

What we hope you'll bring
 

A minimum of four (4) years of professional software development experience
AWS experience
Understanding of ETL/ELT processes and tooling
Understanding of database technologies - setup/ maintenance / data loads / etc. (not data modeling)
Redshift experience preferred
Understand system security
API design and implementation
GIT and DevOps release process
Python or Scala, Python is preferred for ETL
Some experience with older file systems / file based processes such as MOVEit
Some experience with Mulesoft
Experience with agile software development practices emphasizing agility, flexibility, and iterative development


More than that, our ideal candidate wants to contribute to work that is bigger than themselves and wants to make a difference collaborating with their team. They care deeply about building better products, better relationships, and better trust in each interaction people have with their government. They believe in intuitive, easy-to-use government services. They collaborate well with designers, stakeholders, and other teams. They mentor and guide more junior engineers. They're human-centered.
 And if you don't check every box on the list? That doesn't mean you can't help us in our mission to deliver critical government services. Talk to us!
 Some basic requirements

All work must be conducted within the U.S., excluding U.S. territories. Some federal contracts require U.S. citizenship to be eligible for employment.
You must be legally authorized to work in the U.S now and in the future without sponsorship.
As a government contractor, you may be required to obtain a public trust security clearance.
Bachelor's Degree in a technical field is preferred
4 years of professional software development
Our technical screening involves completing a homework assignment that is then graded blind to remove bias. We do not do tricky, unreliable whiteboarding tests. You can read more about our homework here.

Learn more about engineering at Ad Hoc.
 Benefits

Company-subsidized Health, Dental, and Vision Insurance
Use What You Need Vacation Policy
401K with employer match
Paid parental leave after one year of service

Ad Hoc LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination.
 In support of the Colorado Equal Pay Transparency Act, and others like it across the country, Ad Hoc job descriptions feature the starting range we reasonably expect to pay to candidates who would join our team with little to no need for training on the responsibilities we've outlined above. Actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, and responsibility. The range of starting pay for this role is $101,570 - $136,994 and information on benefits offered is here. Our recruiters will be happy to answer any questions you may have, and we look forward to learning more about your salary requirements.
 job reference: 2011"
"Manager, Data Engineer & ETL Processing",Spark Foundry,"Chicago, IL (The Loop area)",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=32f972957c1aa277&fccid=65e65a4212c7f0fe&vjs=3,"Company Description
  About Spark Foundry:
 Spark Foundry is a global media agency that exists to bring HEAT – Higher Engagement, Affinity, and Transactions – to brands. By combining flawless media fundamentals with aggressive innovation, Spark inspires consumers to pay more attention, to care more about our clients’ brands, and to buy more products and services from them.
 Balancing the nimble spirit of a startup with the powerhouse soul of Publicis Media, Spark Foundry delivers the best of both worlds to a client roster that spans some of the world’s best and most beloved brands and companies. We combine boutique-caliber insights and service with the buying clout and first-look access of a global leader, bringing the heat to challenger brands that want to act like giants, and to giant brands that want to act like challengers.
 With a bottom-up culture that celebrates diversity and aims for all voices to be heard, Spark has become a magnet for the industry’s best talent, with one of the best retention rates in the industry. And by applying a whole-person approach to professional and personal development, Spark develops a workforce that is well prepared for today’s challenges, and also poised to create meaningful careers in the years to come.
 Because we know that heat arises the intersection of complementary forces, our professionals come from myriad disciplines and backgrounds: data, analytics, and insights, content and creative production, communications and strategy, finance and marketing, and sociology, psychology, and other liberal arts disciplines.



 Job Description
  Overview: 
The Manager, Data Engineering & ETL Development is a key driver to build data platform leveraging best in class ETL practice and is also a strategic thinker and a talented data visualization expert with emphasis on dashboard reporting. The primary responsibility will be developing business intelligence platform to support media and marketing data for our clients. This position will allow you to be a significant contributor as part of the team to support easy access of data and visualizations to fuel stronger insights and media optimizations.
 This position requires strong technical and tactical skill sets with an eye for numbers, intellectual curiosity, proficiency at problem solving, and a critical understanding of online media. The candidate must have a proven track record in managing ETL’s, APIs and business intelligence platforms. Candidate should be a team player. A “roll up the sleeves” approach is mandatory and a “get it done” attitude is a must. Specific responsibilities include coordination between the research, analytics & media teams ensuring high quality data projects are effectively delivered.
 Successful candidates will be multi-dimensional ‘rising-stars’ who are able to employ complex problem solving skills, and are able to communicate these succinctly to a broad client and media stakeholder audience.
 Role Objectives:

 Responsible for loading and validating data into the data warehouse from various source systems
 Analyze, develop, fix, test, review and deploy functionality, and bug fixes in ETL data pipelines
 Query tuning, diagnosis, and resolution of performance issues leveraging ELT and push-down if required
 Building Data mappings between Source to Target systems
 Provides support for technical issues and ensuring system availability
 Work with business customers to identify and develop additional data and reporting needs
 Understand how business intelligence platform/data technologies work and offer the ability to explain technical concepts in ordinary terms (be technically savvy - understand the opportunities and limitations)
 Establish and manage data integrations utilizing a taxonomy nomenclature to make recommendations for data visualization to showcase media performance through the use of Datorama or Tableau
 Perform regular quality assurance/quality control checks on assigned client campaigns to ensure the data is processing accurately
 Design and build backend data streams and processes to automate reporting capability with data visualization tools
 Contribute to client status and reporting calls, including presentation of reporting as required
 Develop subject matter expertise in ETL, API development, and Business Intelligence platforms
 Clearly define project deliverables, timelines, and dependencies for junior team members, internal stakeholders and clients
 Collaborate on an inclusive team, where members openly communicate and collectively problem-solve
 Strong ability to evaluate new technologies and present findings to team
 Contribute to knowledge sharing efforts and mentorships
 Complete other duties as assigned.




 Qualifications
 

 Bachelor’s degree or combination of education, and equivalent work experience is preferred in the field of computer science, management information systems or Information Technology
 3+ years’ related experience ETL development and business intelligence platform management
 Understanding of BI/ETL development in the IT industry with recent development, system administration, application tuning and debugging experience.
 3+ plus years’ development experience with database engines including Presto, Mongo db and Hadoop.
 3+ years’ experience in ETL development, Strong Database (Modeling, SQL), SQL Server, Hadoop, AWS Redshift, Qubole.
 Experience managing team of 2 or more associates/analysts preferred
 Strong database modeling and SQL skills. Ability to write complex SQL statement, Procedures and data automation programs
 Knowledge of ETL tools like Airflow, AWS Glue, Alteryx, SSIS, Qubole/Spark is a must
 Knowledge of Python or similar programming languages required
 Proficiency with Datorama, Tableau, or other data visualization tools is preferred
 Experience working with AWS or other cloud technologies
 Advanced user Microsoft Office Suite and reporting tools
 Demonstrated expertise in core MS Excel functions (vlookup, pivot tables, data visualization)
 Experience in designing jobs that can be easily promoted from one (Dev) environment to another (Test or Prod) seamlessly, without modification.
 Strong analytical and problem-solving skills
 Strong verbal/written communication and interpersonal skills is required
 Self-starter with ability to thrive in a fast-paced environment and able to function independently while providing status updates to a team of analysts
 Cooperative, flexible, conscientious, dependable, resourceful, self-motivated, and team-oriented
 Problem solving, time management, and critical thinking skills with a professional and positive attitude
 Ability to work independently and as part of an agile team, participating in daily stand-ups, sprint planning and sprint review


 Character: 
The following qualities help drive success as member of the Spark Data and Analytics team:

 Entrepreneurial, engaging, resourceful, curious, and self-directed spirit
 Willing and easily roll sleeves up or down; love the nitty-gritty and the strategy
 Collaborative approach to building cohesive, strong teams
 Loving and living the intersections between brands, people, media, communications
 Relentlessly passionate and resolute
 Planning and time management excellence.
 Embrace challenges
 Proactive, especially in pushing for new opportunities, approaches, and ideas.
 Keenly focused on action and solutions; thrives with deep critical thinking and analysis.
 Pioneering insight attitude and research in-the-know.
 Resourcefulness, flexibility and adaptability, strong ability to pivot when the need arises.
 Inspired to be part of the insight journey/revolution with a growing, dedicated team

 Additional Information
  All your information will be kept confidential according to EEO guidelines.
 23-2795"
Staff Data Engineer,Grindr,"Remote in Chicago, IL 60625",Posted 30+ days ago,"$190,000 - $250,000 a year",https://www.indeed.com/rc/clk?jk=be2b1d9070760b9e&fccid=7c4356358e0da7c8&vjs=3,"We are seeking candidates for this fully remote role who are based in the greater Chicago area. Grindr employees living and working in the greater Chicago area are encouraged, but not required, to join the Engineering Team in the West Loop Chicago satellite office a few times per month.
 What's so interesting about this role?
 The big data space is growing rapidly at Grindr and we're looking to add a staff-level Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. Beyond the data pipeline, you will also be instrumental in bringing the data-driven products and features to life and helping build the future of Grindr.
 In this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, deliver analysis to further improve engagement in existing features, and empower our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.
 What's the job?

Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.
Solve technical problems of the highest scope and complexity
Exert significant influence on the company's analytical long-range goals and data architecture
Define and extend our internal standards for style, maintenance, and best practices for a high-scale data platform
Provide mentorship for all on your team to help them grow in their technical responsibilities
Propose ideas to improve the scale, performance, and capabilities of the Data Platform
Moving implementation to ownership of real-time and batch processing and data governance and policies.
Maintain and enforce the business contracts on how data should be represented and stored.
Stay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users
Implementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.
Work closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.

What we'll love about you

7+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field
7+ years experience using Python
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Significant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases
Experience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Experience with dimensional data modeling and schema design in Data Warehouses
Familiar with ETL (managing high-quality reliable ETL pipelines)
Be familiar with legal compliance (with data management tools) data classification, and retention


What you'll love about us

Mission and Impact: Grindr is the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We currently have offices in LA, NYC, and Chicago, and are hiring someone for this role to be based ideally in Los Angeles, San Francisco, New York City, or Chicago
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events

About Grindr
 Grindr is the world's largest dating app for gay, bi, trans, and queer people. With around 13 million monthly active users, Grindr has become a fundamental part of the global LGBTQ community, and we take pride in empowering our users to connect, express themselves, and discover the queer world around them.
 Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we're blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.
 With a track record of strong financial performance and plans for continued headcount growth, we're looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us. 
Grindr is an equal-opportunity employer
 To learn more about how we handle the personal data of applicants, visit our Employee and Candidate Privacy Policy.


 #LI-Remote



 Grindr is committed to fair and equitable compensation practices. This base pay range is for the U.S. and is not applicable to locations outside of the U.S. The actual base pay is dependent upon many factors, such as training, transferable skills, work experience, business needs, location, and market demands. The base pay range is subject to change and may be modified in the future. This role will also be eligible for equity, benefits, and a company bonus program.

 Base Pay Range

    $190,000—$250,000 USD"
Senior Data Engineer,IHI Terrasun Solutions Inc.,"Remote in Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=b82da85d4e50bde8&fccid=dd616958bd9ddc12&vjs=3,"At IHI Terrasun, we are at the forefront of changing the world with green energy solutions. To build on our incredible success, we need a driven, curious, and collaborative people to join our growing team.
 We know our most important assets are our people, and your role will be critical to our future success.

 Position Summary
 This position is responsible for the development, implementation, and maintenance of data systems for both data in motion and data at rest to monitor and control battery storage systems. In this role, you'll work with setting up systems to capture hardware metrics and track their performance for outage tracking and compliance for one of the largest collections of industrial automation data worldwide.


 What you'll be doing

Create services to receive, translate, and send data in motion to data stores via APIs and query languages.
Developing and deploying data pipelines using docker/containerization, Jenkins and Kubernetes.
Participate in the entire software development lifecycle of a product from ideation, wireframing/prototyping, development, testing, deployment, commissioning, and long-term support.
Own automated testing and deployment for products that you create.



 The ideal candidate would have the following experience:

Developing in Python including libraries like pandas, the SciPy stack, request, and data tools in the context of data processing workflows, scripts, and services.
Working in every stage of the data lifecycle from converting business specifications/requirements to technical solutions through deployment, and maintenance.
Integrating software and services, including developing adaptors between different data protocols (e.g., MQTT to Prometheus exposition format)
Creating scalable and performant systems.


Analyzing messaging protocols using tools like tcpdump, WireShark, and custom data producers and consumers.
Reading, writing, and converting data formats like json, yaml, csv, pandas dataframes, and relational databases.
Working with Prometheus, PromQL, and Grafana.
Developing and deploying Docker workflows.
Working in a Linux environment including basic shell scripting and system monitoring.


Participating in Agile development including scrum ceremonies, ticket management, GIT version control, unit testing, code reviews, and documentation.
Experience in compiled languages like Go, Rust, or C++ are a plus but not required.



 Qualifications

5+ years experience in data engineering
BS, MS or PhD in CS, Engineering, Math, Physical Sciences or equivalent real-world experience.
Ability to work independently, with a development team, and within large multi-team projects.
Excited to learn and grow with new technologies and adaptability to handle evolving requirements.
Has a shared sense of responsibility and ownership both in your code and the larger system that it operates in.
Ability to communicate issues openly and honestly even when difficult.
Previous Energy Storage System experience is preferred, power industry or military systems experience is a plus



 Work Environment

IHI has its main office in Chicago, IL, however this position can be remotely located. Those in the Chicago-land area have the flexible option of working from the office or remotely from home.
Limited travel may be required for company All-Hands or other meetings. Travel expectations for this position are up to 5% within the US.



 The above job description identifies the essential job functions and skills needed by the person or persons assigned to this position. These job functions and skills are not intended to be a complete and exhaustive list of all responsibilities, duties and skills required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions. The information contained herein is subject to change at the company's discretion.

 About IHI Terrasun Solutions:
 IHI Terrasun Solutions is a subsidiary of IHI Corporation, a 165-year-old, $15 Billion organization with deep energy industry experience. IHI Terrasun Solutions is a solar + storage systems integration and lifecycle services provider with highly integrated hardware and software capabilities.
 The robust software and top tier energy storage solutions are developed by the expert team at IHI Terrasun Solutions. Employees have extensive industry knowledge and experience, and enthusiastically seek to build on IHI's advanced product offerings. 
To design systems, IHI Terrasun Solutions uses proprietary software that operates on the same algorithm later used to deploy the system in real-time. This end-to-end algorithm structure coupled with the support offered by a well-established parent organization enables IHI Terrasun Solutions to provide an advanced warranty to customers, reducing project risk and increasing clarity on system scheduling and deployment. 
With solar + storage expertise, robust service offerings, and technology-agnostic solutions, IHI Terrasun Solutions develops efficient and streamlined systems to achieve your energy storage goals.
 IHI Terrasun has over 480MWh of projects currently installed, contracted, and in construction with over 1GWh of projects in advanced phase of contracting.


 Benefits:
 Not only do our employees get the chance to work in a rapidly growing energy business with global impact, they also have access to some of the best benefits in the industry, including:

100% employer paid health, dental, and vision insurance for our premium Anthem Blue Cross PPO plan
401(k) plan contribution matching
Employer sponsored Life, AD&D, Short-Term and Long-Term Disability Insurance
Tuition and continuing education stipend
Fantastic employee culture"
"Lead Data Engineer – Snowflake, Informatica, AWS – Rosemont, IL 44602","PRIMUS Global Services, Inc","Hybrid remote in Rosemont, IL",Posted 1 day ago,,https://www.indeed.com/rc/clk?jk=975ee437904e2996&fccid=fab19a82e69a8358&vjs=3,"We have an immediate long-term opportunity with one of our key clients for a position of Lead Data Engineer, to work in Rosemont, IL.  Required Qualifications and Skills:

  Experience working on Snowflake. Experience developing technical solutions for Cloud data warehouses and data lakes. Exposure to Python is a plus. Experience working on Informatica Cloud (IICS) and on AWS data environments (S3, EMR, Lambda, SQS, etc.)
 

 For immediate consideration, please contact:  Aman PRIMUS Global Services Direct: 972-853-8927 Desk: 972-753-6500 Ext: 417 Email: jobs@primusglobal.com"
Senior Data Engineer,Chicago Public Media,"Chicago, IL",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=9dfbd52ebf247e36&fccid=8fc3aaf2b4404bce&vjs=3,"About Chicago Public Media
 Home to WBEZ and the Chicago Sun-Times, Chicago Public Media is the largest local non-profit news organization in the country. WBEZ and the Chicago Sun-Times serve more than 2 million people weekly across broadcast, print, and digital platforms. As a mission-driven organization, we aspire to become the essential and most trusted news source that Chicago turns to each day for understanding the people, events, and ideas that shape our community.
 WBEZ is home to local and national news programming as well as a growing portfolio of popular podcasts. WBEZ serves the community with fact-based, objective news and information, and its award-winning journalists ask tough questions, dig deep for answers and expose truths that spark change and foster understanding. WBEZ is supported by more than 86,000 members, hundreds of corporate sponsors and major donors. In 2022, WBEZ received more than 20 awards for its journalism, including two prestigious National Edward R. Murrow Awards.
 Chicago Sun-Times is Chicago's oldest continuously published daily newspaper serving Chicago and is known for its hard-hitting investigative reporting, in-depth political coverage, timely behind-the-scenes sports analysis, and insightful entertainment and cultural coverage. Chicago Sun-Times is the winner of eight Pulitzer Prizes and countless other awards. In recent years, the Sun-Times has focused on a digital transformation to deliver its news and content to a growing digital audience. Most recently, the Sun-Times dropped the paywall on suntimes.com to expand access to its journalism, and shifted to a community-funded digital membership program supported by voluntary member donations.
 Chicago Public Media believes independent journalism is essential to a well-functioning democracy and access to fact-based, objective news and information is a right of every citizen. We serve the public interest by creating diverse, compelling content that informs, inspires, and enriches. We connect diverse audiences and help them make a difference in the community, the region and the world. And, we employ 300+ staff who want to belong to an organization that inspires, supports, and challenges them to do their best work.
 For more information, please see the Chicago Public Media Annual Report.

 The Opportunity
 Chicago Public Media seeks an experienced engineer to own the end-to-end data operations that help us better understand and serve our community. Chicago Public Media is expanding its use of data to drive top-level organizational strategy, and this role plays a foundational role in expanding our organization's data capacities across audience, content and revenue teams. As of 2022, Chicago Public Media is the home of the Chicago Sun-Times, WBEZ, and Vocalo. In this role, you will be responsible for maintaining, developing and improving the data systems and models that inform our work across news, revenue, and audience development goals across all brands. You will create and maintain data pipelines, integrate new data sources, maintain and extend data warehouses, and collaborate with Product and Analytics leads to ensure that users across the organization have ready access to data, through methods that could include reports, dashboards, and internal research tools.
 General Responsibilities

Own core audience data operations for CPM, including content/product performance and revenue
Design and maintain data integrations and data quality framework
Work closely with all business units and engineering teams to develop strategy and design for long-term data platform architecture and specify appropriate tools and technologies to support strategic goals.
Develop and maintain scalable data pipelines, building out new integrations to support continuing increases in data volume and complexity.
Collaborate with Product, Revenue, and Audience Insights teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Write unit/integration tests, provide documentation, and ensure business continuity for all critical systems.

Qualifications

5+ years of data engineering experience
Experience running and supporting production of enterprise data platforms
Experience in building infrastructure required for optimal extraction, transformation and loading of data from various resources
Experience creating internal tools that combine content and audience data preferred
Knowledge of JavaScript, Python, Bash and SQL
Ability to build data pipelines with tools and cloud-based data services like Google's BigQuery, AWS, Dataproc and Pub/Sub
Strong statistics skills
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service


 Working at Chicago Public Media
 At Chicago Public Media, we care deeply about our employees as we know attracting, developing, and growing talent is key to our success and enhancing our impact. Our culture is one where collaboration, ideas, and innovation are encouraged. We value colleagues who will enhance our culture by bringing new ideas, diverse experiences, and talents to our dynamic workplace.
 Chicago Public Media's dedication to promoting diversity and inclusion is reflective across our brands, WBEZ 91.5 FM, Chicago Sun-Times, and Vocalo 91.1 FM, in our staff and in our work. We are fully focused on equality of opportunity and believe deeply in diversity of race, gender, sexual orientation, religion, ethnicity, national origin, experience, and all other fascinating characteristics that make us different.
 At Chicago Public Media we believe dedication to a great workplace includes supporting our employees and their families. As a result, we provide a broad and generous benefits package for you at hire and in the years to come.
 Our benefits include:

6 weeks fully paid family leave
High quality Medical, Dental, and Vision plans at an affordable cost
A 403(b)retirement plan with a company match
Generous paid time off, including starting with 3 weeks' vacation and 4 personal days.

The essential functions described above are not all-inclusive and may change periodically to meet the needs of Chicago Public Media (CPM). The information contained in this job description is not intended to create any contractual or other legal commitment. Chicago Public Media may change the content or format of this job at any time in its sole and exclusive discretion without notice.  Chicago Public Media is an Equal Opportunity Employer, and we actively seek and welcome people from all backgrounds, orientations, and life experiences to join our team."
Sr Big Data Engineer Designer,"Information Resources, Inc","Chicago, IL 60601 (Loop area)",Posted 28 days ago,"$110,000 a year",https://www.indeed.com/rc/clk?jk=13fe2ac26c9a0a9c&fccid=90e4e44116124fe2&vjs=3,"Let’s be unstoppable together!
 Circana (formerly IRI and NPD) is the leading advisor on the complexity of consumer behavior. Through unparalleled technology, advanced analytics, cross-industry data and deep expertise, we provide clarity that helps almost 7,000 of the world’s leading brands and retailers take action and unlock business growth. At Circana, we are fueled by our passion for continuous learning and growth, we seek and share feedback freely, and we celebrate victories both big and small in an environment that is flexible and accommodating to our work and personal lives. Join our inclusive, committed team to be a challenger, own outcomes, and stay curious together. Learn more at www.circana.com.
 At CIRCANA, we deliver growth to clients based on big data—our predictive analytics and forward-thinking insights help CPG, OTC, health care, retailers, and media companies remain relentlessly relevant, capture marketing share, connect with consumers, and deliver market-leading growth. The convergence of our proprietary, on-demand cloud-based technology and our client-focused colleagues leads to a seismic shift in drivers of success in all industries.
 For CIRCANA colleagues, we focus on the moments that matter. From meaningful work and impact to continuous improvement we challenge ourselves to grow both professionally and personally. You’ll feel a true sense of connection and purpose in your work and will craft the direction of your career in a highly personalized way. No matter the department you join, you’ll find yourself constantly growing and developing the skills of the future to deliver client growth. We believe in the undeniable strength that diverse people, culture, thought, and skill brings to our business, our clients, our people, and our communities. We are committed to nurturing a dynamic culture that embraces and celebrates growth, feedback, recognition, flexibility, belonging, and wellbeing for all.
 As a Sr Big Data Engineer Designer, you will be responsible for leading the development of client-specific implementations that will run in the client’s cloud environment leveraging the industry’s leading BI/Analytics solutions, Circana Liquid Data (LD). This is an end-to-end business intelligence solution that involves highly complex data transformations flowing into the LD Whitebox-powered data layer, and the LD Unify reporting application.
 You will interface with the client to understand requirements and translate the requirements into technical design. You will then manage and co-develop complex, fully automated data ingestion processes that meet the client's needs. You will also be responsible to debugging and resolving all the data issues that arises during the course of the project.
 Job Responsibilities

 Design the data loading pipeline which satisfies the business requirements and also extremely performant and fault tolerant
 Work with Product management team and client data ingestion teams to thoroughly understand all the datasets and ensure that it meets the business requirements
 Attend daily scrum calls with clients and provide feedback on the progress of all the data ingestion work
 Lead the offshore and onshore teams and explain the business requirements and design and ensure all data ingestion tasks are delivered on time
 Help the team in tuning the performance of the data ingestion jobs to ensure all jobs complete within the stipulated SLA time
 Co-develop all the complex data ingestion jobs and understand all the internal framework utilities and also build reusable code

Requirements

Bachelor of Science Degree in Computer Science, Data Analytics, or equivalent
 10+ years of Business intelligence industry experience
 5+ years of Big Data (Hadoop ecosystem) experience
 2+ years of experience leading client-facing projects
 Extensive experience in Linux or Unix OS Big Data scripting languages (Python, Spark, bash)
 Extensive experience aligning data from disparate sources with varying granularity
 2+ years of Azure cloud experience. Databricks experience is a plus
1+ years Amazon S3 experience
 Experience working with third-party job schedulers (Control-M, Airflow a plus)
 Eagerness to learn and adapt to evolving Hadoop tooling advancements
 Strong track record in kick-starting, executing, and advancing client-focused projects
 Experience leading offshore development teams
 Strong communication and leadership skills required

About Us As one of the original innovators in Big Data, CIRCANA integrates the world’s largest set of otherwise disconnected purchase, media, social, causal and loyalty data to help CPG, retail, over-the-counter health care and media companies grow their businesses. We combine this data with predictive analytics to uncover new consumer insights and integrate them on the most technologically advanced, cloud-based visualization platform. Learn more about us
 Our Benefits We offer a comprehensive benefit package (health, paid time off, 401(k), etc.) with additional unconventional offerings such as volunteer time off, flexible work arrangements, virtual doctor access, etc., along with the unrivaled benefit of working with our people - the best in the business.
 The below range reflects the range of possible compensation for this role at the time of this posting. We may ultimately pay more or less than the posted range. This range may be modified in the future. An employee’s position within the salary range will be based on several factors including, but not limited to, relevant education, qualifications, certifications, experience, skills, seniority, geographic location, performance, shift, travel requirements, sales or revenue-based metrics, any collective bargaining agreements, and business or organizational needs. The salary range for this role is $110,000.00 to $Y190,000.00.
 This job is also eligible for bonus pay.
 We offer a comprehensive package of benefits including paid time off, medical/dental/vision insurance and 401(k) to eligible employees.
 You can apply for this role through our Careers website link and/or Intranet site for internal candidates.

 Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
 The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Senior Data Engineer (Azure),iManage,"Hybrid remote in Chicago, IL 60606",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=7ab28d6a6bd6ca62&fccid=51a0dc5d18fb429c&vjs=3,"We offer a flexible working policy that supports the health and well-being of our iManage employees. As an organization, we value collaborating and learning from our peers in person, while providing the necessary flexibility for our employees to have a meaningful work-life balance. Please reach out to learn more.
 Being a Senior Data Engineer at iManage Means…
 You are excited about data and believe in the democratization of data to support data driven decision-making. You will partner with our Information Technology team to implement, support, and extend our Enterprise Data Lake hosted on Azure and built using Azure Synapse. You will gather requirements from iManage business units and craft solutions which provide access to critical business data. You will develop data models and data pipelines for our Enterprise Data Lake, and provide integration with BI platforms and tools such as Totango and Power BI. You are passionate about lakehouse architecture and have experience using Delta Lake and bronze, silver, and gold data lake design.
 Here is what one of our leaders, Cloud Services Director (Jacqueline Toepfer), has to say about the role: “As a Senior Data Engineer on our team, you will get the opportunity to showcase your expertise and make a real difference across the organization. You will be part of a truly collaborative team that is passionate about delivering quality solutions. You will be the in-house expert in the data models of multiple, disparate enterprise SaaS systems and utilize your wealth of knowledge to provide recommendations and solutions for consolidation, transformation, and integration of the disparate data sources.”
 iM Responsible For…

 Modeling, managing, and reporting of data stored in Azure Data Lake.
 Gathering data requirements from various business units and translating these requirements into data models. 
Using Python, PySpark, and system specific APIs to extract, transform, store and analyze data from a variety of systems.
 Data modeling, defining data pipelines, and integrations necessary to present data in BI platforms such as Totango, or BI tools like Power BI.
 Identifying and modeling all current disparate data sources and the data flows between these data sources. 
Analyzing current repositories and proposing changes to data repositories and data flows to better support company objectives for the measurement of user experience and customer success.
 Understanding the business needs of data integration and governance from disparate systems to drive the enhancement of the enterprise data lake. 
Applying best practices to ensure the security and privacy of the data repositories.
 Ensuring data repositories meet company standards for storage of PII.
 Developing proficiency with the iManage product APIs for all iManage Cloud services.

 iM Qualified Because I Have...

 A Bachelor’s degree or higher in Computer Science or equivalent field.
 3-5 years of experience working with data in a business setting.
 Proficiency in data extraction, manipulation, and subsequent reporting with Spark and Python.
 Experience designing data pipelines with a cloud-native mindset using Azure or AWS.
 Knowledge and experience with architecting a data lake with Azure Synapse or adjacent technologies like Databricks.
 Experience ingesting data from SaaS solutions and other services via API or other related technologies.
 A passion to be a thought leader and work collaboratively within a team.
 Commitment to understanding data requirements and delivering scalable, robust solutions that meet those requirements.
 A creative mindset with a desire to explore new technologies and create innovative solutions.

 Bonus Points If I Have…

 Familiarity with Delta Lake.
 A background with relational databases and data warehouse design using star schemas.
 Experience with cloud-based data models for business solutions like Salesforce, Zendesk, and NetSuite.

 Don't meet every qualification listed above? Studies show that women and people of color are less likely to apply to jobs unless they meet all qualifications. At iManage, we are committed to building a diverse and inclusive environment and encourage everyone to show up as their full authentic selves. We welcome those that come with a growth mindset and a hunger for learning; so, if you are excited about this role but your past experience doesn't align perfectly with every qualification, we encourage you to apply anyways!
 iM Getting To…

 Join a supportive, experienced team with an inclusive, encouraging, and vibrant culture.
 Have flexible work hours that allow me to balance my ‘me time’ with my work commitments.
 Collaborate in a modern open plan workspace, with a gaming area, free snacks, drinks and regular social events.
 Focus on impactful work, solving complex, real challenges utilizing the latest technologies and protocols.
 Own my career path with our internal development framework. Ask us more about this!
 Learn new skills and earn certifications with access to unlimited courses in LinkedIn Learning.
 Join an innovative, industry leading SaaS company that is continuing to grow & scale!

 iManage Is Supporting Me By...

 Creating an inclusive environment where I can help shape the culture not just by fitting in, but by adding to it.
 Providing a market competitive salary that is applied through a consistent process, equitable for all our employees, and regularly reviewed based on industry data.
 Rewarding me with an annual performance-based bonus.
 Offering comprehensive Health/Vision/Dental/Life Insurance, and a 401k Retirement Savings Plan with a company match up to 4%. 
Giving access to HealthJoy, a healthcare concierge service, to help me maximize my health benefits.
 Granting enhanced leave for expecting parents; 20 weeks 100% paid for primary leave, and 10 weeks 100% paid for secondary leave. 
Providing me with a flexible time off policy to take the time off that I need. Be it for vacation, volunteering, celebrating holidays, spending time with family, or simply taking time to recharge and reset.
 Caring for my mental health and well-being with multiple company wellness days and free access to the Healthy Minds app for mindfulness, meditation and more.

 About iManage…
 iManage is dedicated to Making Knowledge WorkTM. Over one million professionals across 65+ countries rely on our intelligent, cloud-enabled, secure knowledge work platform to uncover and activate the knowledge that exists inside their business content and communications. 
We are continuously innovating to solve the most complex professional challenges and enable better business outcomes; Our work is not always easy but it is ambitious and rewarding. 
So we’re looking for people who love a challenge. People who are happiest when they’re solving problems and collaborating with the industry’s best and brightest. That’s the iManage way. It’s how we do things that might appear impossible. How we develop our employees’ strengths and unlock their potential. How we find meaning in everything we do. 
Whoever you are, whatever you do, however you work. Make it mean something at iManage.
 iManage provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. 
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
 Learn more at: www.imanage.com 
Please see our privacy statement for more information on how we handle your personal data: https://imanage.com/privacy-policy/ 
#LI-LM1
 #LI-Hybrid
 
pm5GRruoGc"
Lead Data Quality Engineer (No C2C),Kairos Technologies Inc,"Remote in Chicago, IL",EmployerActive 8 days ago,$50 - $70 an hour,https://www.indeed.com/company/Kairos-Technologies/jobs/Data-Engineer-e605d813878b6939?fccid=609eeb6b6a1a2e5b&vjs=3,"Greetings from Kairos Technologies Inc,
Role: Sr Data Quality EngineerLocation: Chicago, IL (Remote 100%)Duration: 12+ monthsVisa: USC, GC, H4 EAD
Responsibilities:

Develop database solutions to store and retrieve company information
Migrate data from legacy systems to new solutions as necessary
Design conceptual and logical data models and flowcharts and be able to instantiate these to physical models
Improve system performance by conducting tests, troubleshooting and integrating new elements
Optimize new and current database systems
Define security and backup procedures
Coordinate with the Data Science department to identify future needs and requirements
Provide operational support for Management Information Systems (MIS)
Develop code for insertion/retrieval of data

Qualifications:

Proven work experience as a Data Architect, Data Modeler or similar role
In-depth understanding of database structure principles
Experience gathering and analyzing system requirements
Knowledge of data mining and segmentation techniques
Expertise in SQL
Knowledge of data modeling tools
Knowledge of ETL tools
Knowledge of Microsoft Office Suite products including Visio
Experience with SOA, web services, enterprise data management, information security, applications development, and cloud-based architectures
Proven analytical skills
Problem-solving attitude
Good communication and customer relationship skills
Health Insurance knowledge a plus
MDM knowledge a plus
Common Data Service knowledge
BSc in Computer Science or relevant field

Thanks& Regards,
K Hemanth Kumar | Sr IT Technical Recruiter | Kairos Technologies Inc
Job Type: Contract
Pay: $50.00 - $70.00 per hour
Schedule:

8 hour shift

Experience:

SQL: 7 years (Preferred)
Data warehouse: 5 years (Preferred)
ETL: 7 years (Preferred)

Work Location: Remote"
"Data Engineer (Mansfield OH, Greenville WI or Lombard IL)","School Specialty, LLC","Hybrid remote in Lombard, IL 60148",Posted 15 days ago,"$87,000 - $124,000 a year",https://www.indeed.com/rc/clk?jk=5adcc8cbdd766487&fccid=dbdf71469b0cc9f1&vjs=3,"People Passion Purpose
 Everything School Specialty offers is designed for one purpose – to help students succeed. We believe every student can flourish in an environment where they feel safe and inspired to explore and grow.
 
 We’re determined to positively impact the future, one child at a time. We need to talk if you share our passion:
 

Transforming more than classrooms.® 


Benefits 

 School Specialty offers Medical, Dental, & Vision plans (Effective Day 1), Wellness programs, Health Savings Accounts, Flexible Spending Accounts, 401 (k), Unlimited PTO for Salaried Exempt employees, which can also be used for dedicated 
 volunteer hours, Education Reimbursement, Paid Holidays, Fall & Winter Flexible Hours, Employee Discounts and much more! 
 

Data Engineer

(Hybrid role- in Greenville WI, Lombard IL, or Mansfield OH)

 Candidate will be responsible for designing, building, and maintaining scalable and efficient data systems supporting our organization's data-driven decision-making. You will work closely with our data scientists and business analysts to develop ETL processes and pipelines that transform raw data into valuable insights. The Data Engineer will serve as a backup to the DBA role in the event of their absence or unavailability.
 
 The base salary range for this role is 
 $87-124K Annually


Summary of Primary Responsibilities

 Design, build, and maintain scalable and efficient data systems and pipelines
 Develop and maintain ETL processes that transform raw data into valuable insights, including data cleansing, data mapping, and data transformation
 Work closely with data scientists and business analysts to understand their data requirements and develop solutions to meet their needs
 Design and implement data storage solutions that are secure, reliable, and accessible
 Develop data quality checks and monitoring to ensure data accuracy and completeness
 Develop and implement data processing and validation procedures
 Develop and maintain documentation on data pipelines, data dictionaries, and data lineage
 Perform data profiling, data mapping, and data modeling to support data analysis and reporting
 Collaborate with cross-functional teams to integrate data from different sources
 Continuously optimize and improve data systems and pipelines for performance, scalability, and reliability
 Creating and executing backups, performing database tuning and optimization, monitoring database activity and usage, and providing support to end-users
 Stay up-to-date with emerging trends and technologies in data engineering

 Minimum Experience Requirements

 5+ Years Proven experience as a Data Engineer or similar role
 Strong understanding of data modeling, database design, and data architecture principles
 Experience building ETL processes and pipelines, including data cleansing, data mapping, and data transformation
 Proficiency in SQL and experience working with Oracle and MS-SQL database technologies
 Experience in database administration and be able to troubleshoot issues related to database connectivity, security, and performance
 Ability to work independently and collaboratively in a fast-paced environment
 Excellent problem-solving and communication skills
 Willingness to learn and adapt to new environments and technologies
 Self-starter and confident

 Preferred Knowledge and Skills

 Experience with big data technologies such as Hadoop, Spark, or NoSQL databases
 Experience with distributed data processing frameworks like Apache Hadoop, Apache Spark, or Apache Flink
 Knowledge of data warehousing concepts and tools such as Redshift, Snowflake, or BigQuery
 Familiarity with data visualization and reporting tools such as Tableau or Power BI
 Experience working with data streaming and real-time data processing frameworks like Apache Kafka or Apache Storm

 **Qualified applicant must live with a reasonable commute/ driving distance of a School Specialty Facility (Greenville WI, Mansfield OH or Lombard IL). Applicant must reside within 100 miles of one of these locations.


Disclaimers 
 The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. All personnel may be required to perform duties outside of their normal responsibilities from time to time, as needed.
 
 School Specialty, LLC. is a Drug Free Workplace. All applicants are subject to a drug screen and background check as a condition of employment.
 We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. 
If you need a reasonable accommodation for any part of the employment process, please contact us by email at Opportunities@SchoolSpecialty.com and let us know the nature of your request and your contact information.
 #LI-Hybrid"
Mainframe Data Security Engineer,Ensono,"Remote in Downers Grove, IL 60515",Posted 2 days ago,,https://www.indeed.com/rc/clk?jk=28f81c10accefc49&fccid=ae5e1126346d034a&vjs=3,"At Ensono, our Purpose is to be a relentless ally, disrupting the status quo and unleashing our clients to Do Great Things! We enable our clients to achieve key business outcomes that reshape how our world runs. As an expert technology adviser and managed service provider with cross-platform certifications, Ensono empowers our clients to keep up with continuous change and embrace innovation.
 We can Do Great Things because we have great Associates. The Ensono Core Values unify our diverse talents and are woven into how we do business. These five traits are the key to achieving our purpose.
 This position is responsible for all aspects of information and network security within the Agency, including the administration of applicable security technologies, proactive monitoring of all information technology assets for potential security issues, Identity and Access Management activities, as well as the application of security best practices to mitigate risks within the organization. This position performs at a moderate level of complexity with proficiency under general supervision.
 Clearance of Federal background check will be required.
 PRIMARY DUTIES AND RESPONSIBILITIES 
Security Technology and Controls Support (75%)

Responsible for administering, monitoring, maintaining on-premises and cloud-based security systems.
Assist with coordinating the implementation of security system(s) and upgrades to systems as needed.
Assist security configurations related to Identity and Access Management and other security systems.
Manage and support the Identity and Access Management and other security technologies within the team's jurisdiction.
Participate in the implementation of low to moderate complexity security initiatives.
Monitor compliance and adherence to agency security policies and assist with violation investigations.
Perform ongoing oversight of the vulnerability and security-patch management process.
Manage end user requests and act as liaison between end users and development; establish role definitions within Identity and Access Management systems.
Access review of user account privileges and activity for designated systems.
Monitoring and processing of configuration changes and service requests to facilitate timely resolution.
Implement and maintain the controls and procedures required to protect the Agency's information system assets in a cost-effective and uniform manner.
Responsible for performing root cause analysis (RCA) of events and incidents.
Perform risk analysis to identify any security issues that could lead to lost or stolen data.
Deploy and administer vendor and internally developed software and procedures to address security requirements.

Project Management (10%)

Provide accurate estimates and timely updates to project management.
Monitor and report on system availability, performance, and capacity metrics.

Testing and Documentation (10%)

Perform analysis, documentation, and testing of enhancements associated with new or existing application functionality.
Perform unit testing of system modifications to ensure that the specifications are met, and that there is no unexpected or adverse impact on system performance and functionality.
Responsible for application documentation for both technical and functional purposes.
Provide support and collect evidence for internal and external audits.
Assist with maintaining and testing the department's Disaster Recovery and Business Continuity Plan.

OTHER DUTIES AND RESPONSIBILITIES (5%)

Review processes and suggest process improvements or opportunities for automation.
Mentors less experienced staff in information security processes and procedures.
Required to stay current in industry specific knowledge.

Requirements:
 Associate Degree or equivalent and two to five years of experience in information security, specializing in information security, or any combination of knowledge, skills, and abilities.

Proven ability to identify, engage, and coordinate escalation teams to resolve issues in accordance with security objectives.
Demonstrated ability to challenge the status quo, identify issues, and provide viable suggestions to improve.
Demonstrated ability to accept personal accountability and ownership for areas of responsibility. Pursue solutions and make decisions.
Ability to analyze complex information.
Possess a high level of integrity and ethics.
Demonstrated exceptional communication skills.
Proficient knowledge of Microsoft Suite.
Effective skills with time management, organization, and prioritization.
Proficient with the implementation of security principles, risk assessment policies and standards, information security best practices, products and technologies, defense-in-depth strategies, and network technologies.
Knowledge and experience in several of the following areas: access control, application development, database, encryption, network, security controls, security frameworks such as NIST, server hardening, and server patching technologies.
Comprehensive knowledge and experience with authentication standards and technologies such as multi factor authentication, JSON Web Token (JWT), etc.
Extensive hands-on knowledge of identity and access management best practices, procedures, user access certification and software solutions such as CyberArk, ForgeRock, Okta, Ping Identity, etc.
Extensive knowledge and experience with identity and access management technology, such as Active Directory, Azure, AWS, single sign-on (SSO), two-factor authentication, privileged access management, etc.
Experience with one or more programming languages such as C++, Java, Python, JavaScript, or C#. Experience with Windows, Linux /Unix, scripting (Bash, PowerShell, or Perl), LDAP, SQL, and web services.
Preferred Qualifications: Current security-related industry certifications; knowledge of cloud computing and cloud native technologies; application development experience, including the ability to create programs and scripts from scratch; automation of business processes.

Preferred:

Hands-on administration of RACF logon IDs, dataset, and resource rules desired.
Experience using Vanguard security products desired.
Must possess excellent analytical problem-solving skills with an attention to detail.
Must be able to prioritize multiple assignments, and complete priorities in a rapidly growing, fast-paced environment.
Exercise judgment and discretion in applying, and interpreting regulations, guidelines, and procedures.
Ability to work accurately, efficiently, and concentrate for long periods of time.
Strong verbal/written communication skills and the ability to communicate technical information to a non-technical audience.
Ability to work effectively in a team environment and promote effective working relationships with all levels of AES/PHEAA management.
Ability to promote a consistent, professional and customer focused work ethic.
Discreetly manage sensitive and confidential information.

Why Ensono?
 Ensono is a place to make better happen – for our clients and for your career. You can do great things through innovation or collaboration, by learning or volunteering, or to promote diversity and inclusion. You can do great things for your own health or for a healthier planet. Whatever it means to you to do great things we want Ensono to be the place you can do it.
 We are a client-facing business, but we do encourage clients to allow us to work remotely most of the time so if you are not required to be on client site, you can choose to work from home or in our Ensono offices.

Unlimited Paid Days Off
Two health plan options through Blue Cross Blue Shield
401k with company match
Eligibility for dental, vision, short and long-term disability, life and AD&D coverage, and flexible spending accounts
Depending on location, ability to take advantage of fitness centers
Wellness program
Flexible work schedule

Ensono is an Equal Opportunity/Affirmative Action employer. We are committed to providing equal employment to our Associates and building a diverse and inclusive workforce. All qualified applicants will be considered without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or other legally protected basis, in accordance with applicable law.
 Pay transparency nondiscrimination statement/posting OFCCP's pay transparency policy can be found on OFCCP's website.
 If you need accommodation at any point during the application or interview process, please let your recruiter know or email USTalentAcquisition@ensono.com."
Field Engineer (Data Systems),Teragonia,"Chicago, IL 60607 (Near West Side area)",EmployerActive 5 days ago,"$148,000 - $186,000 a year",https://www.indeed.com/rc/clk?jk=67b6ffc0d801cc74&fccid=dd616958bd9ddc12&vjs=3,"Base Salary: $140k - $186k
 Company Summary:
 Teragonia, a robustly capitalized startup with a well-established clientele, is dedicated to transforming the financial sponsor universe through cutting-edge data science and AI solutions. Our mission is to reimagine how financial sponsors execute their investment thesis, from sourcing to exit, and maximize value to all stakeholders (financial sponsors comprise private equity firms, venture capitalists, family funds, and sovereign wealth funds). We seek to accomplish this mission through an industry-aligned operating model that optimally blends business domain knowledge, technology, and quantitative techniques.
 Our core offerings include: (i) business intelligence applications, (ii) enterprise solutions that provide data science and operations research-driven insights to business users, and (iii) data science consulting. Our enterprise applications suite provides clarity and focus to C-Suites of middle-market companies owned by financial sponsors, significantly boosting their operating efficiency and return on investment. 

Teragonia offers a comprehensive career development platform through cross-learning within our multidisciplinary structure. We nurture a diverse, inclusive, collaborative, respectful, and collegial environment. Our competitive compensation package aligns with the technology industry leaders, encompassing 401k contribution matching, medical insurance, and additional benefits.
 Division summary:
 Teragonia’s Software Engineering division focuses on developing and maintaining various cutting-edge enterprise applications providing real-time business intelligence from clients’ structured and unstructured data. We develop (i) enterprise-wide business intelligence applications and (ii) domain-specific data science and generative AI applications to improve pricing, customer segmentation, sales force effectiveness, customer life-time-value, attrition management, workforce scheduling, cost optimization etc. Our full-stack Software Engineering team works closely with our Data Science and Operations Research division, for ideation and product design. 
Job Summary:
 We are currently expanding our team and seeking a talented engineer, preferably with prior knowledge and experience in IT systems & operations, to play a crucial role in product development and implementing our innovative solutions with clients. In this role you will actively participate in ideation within a multidisciplinary team of highly qualified and experienced technologists, data scientists, operations researchers and business analytics experts. You will be working directly with our clients' databases, ERP systems, and accounting systems, researching and developing strategies for seamless integration and optimal performance. Working closely with IT departments across a diverse range of companies, your expertise will be pivotal in researching and developing new strategies for connecting to various systems, ensuring seamless integration and optimal performance.
 We are committed to the growth and development of our team through focused education, cross-functional experiences, and mentorship. We are particularly interested in candidates who are committed to a long-term career with us and are excited to be part of our thriving, collaborative, and forward-thinking team.
 Responsibilities:

Develop & provide expertise in the company’s data engineering solutions, including database integration, ERP/accounting system integration, and data ELT tools & workflows. 
Utilize software programming languages, such as Python or Javascript, to ingest & manipulate data.
Collaborate with IT organizations across a diverse range of companies to seamlessly integrate our solutions with clients' databases, ERP, and accounting systems. 
Act as a primary point of contact, providing technical support, troubleshooting, and addressing any issues that may arise during implementation of our products with clients.
Research and develop innovative connection methods and strategies to integrate our solutions with various enterprise systems, contributing to Teragonia's ongoing growth and success.
Deliver training and documentation to ensure clients have a clear understanding of how to use our solutions effectively.
Continuously improve customer satisfaction by gathering and analyzing feedback to identify areas for improvement and implementing necessary changes.
Mentor junior team members.
Perform other responsibilities as needed from time to time due to the nature of Teragonia being a startup. 

Engineering Division Flexible Work Policy:
 At Teragonia, we believe that you should be empowered to choose the work environment that best suits your needs, fostering harmony in work, personal, and family life. A flexible workspace allows you to focus, work, and flow without interruption. Simultaneously, we recognize that in-person interactions often lead to the most effective brainstorming, planning, and team-building experiences.  Therefore, we only expect your presence in the office for work and team-building activities that are most productive in person, based on business or team needs. We do not impose specific days for in-office attendance.
 Diversity, Equity & Inclusion Statement
 Teragonia strives for diversity and inclusion in the workforce and does not tolerate harassment or discrimination of any kind. We make employment decisions based on the needs of our business and the qualifications of the individual and do not discriminate based upon race, religion, color, national origin, gender (including pregnancy or other medical conditions/needs), family or parental status, marital, civil union or domestic partnership status, sexual orientation, gender identity, gender expression, personal appearance, age, veteran status, disability, genetic information, or any legally protected characteristic not otherwise covered here. We encourage all to apply.
 Requirements
 Need-To-Haves:

Be located in the United States
Currently live within commuting distance of Chicago or be willing to relocate to within commuting distance of Chicago.
Bachelor's degree in Information Systems, Computer Science, or a related field.
2+ years of experience as a data engineer, software implementation engineer, field engineer, database administrator, or in a similar position; or, experience in a consulting or sales organization involving such skills. 
Strong problem-solving and communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.
Proficiency in at least one programming language and experience with scripting languages, specifically bash and PowerShell.
Familiarity with multiple methods of connecting to databases, as well as REST APIs to connect to other enterprise systems.
Help handle highly exceptional incidents (loss of availability, security, etc.) during off-hours.
Be available for occasional meetings in early mornings or late evenings to collaborate with staff in remote time zones. 
Familiarity with SQL.

Nice-To-Haves:

Demonstrated experience in customer-facing roles, particularly in IT Consulting or B2B Software Implementation.
Familiarity with middle-market ERP and accounting systems such as Oracle NetSuite, Sage Intacct, Quickbooks, or Xero.
Hands-on experience working with a diverse set of database technologies commonly found in enterprise environments, including but not limited to SQL Server, Oracle, PostgreSQL, and MySQL.
Basic understanding of networking concepts and protocols.
Ability to work independently and as part of a team, managing multiple projects and priorities simultaneously.

Benefits

Competitive Total Compensation - We constantly benchmark our pay scales against the market to maintain competitiveness.
Restricted Stock Awards - We offer restricted stock awards to select positions to ensure our teams’ long term commitment and hard work are rewarded by sharing our collective success.
Visa Sponsorship - We offer visa sponsorship for eligible employees.
401k Plan with Employer Contributions - We help secure your future with matching of 401k contributions up to 3.5% of your annual base salary, rising to 6% on the calendar year after your first work anniversary.
Professional Development Opportunities - We will sponsor company-selected training sessions, conferences, and certifications to foster your growth.
Meal Reimbursement - Reimbursement for lunch at the office, and dinner too if you are working past 7 pm, up to a limit. 
Gym Membership - Reimbursement for fitness & wellness programs, such as gym memberships, up to a limit. 
Commuter Benefits - We offer the opportunity to leverage the available tax concessions for commuting expenses.
Relocation Assistance - Available to those who move to the Chicago or New York City metropolitan area as required by their job role.
Paid Time Off (PTO) - You will be eligible for 15 to 20 days PTO, depending on level, accrued according to company policies.
Annual Quiet Week - From Dec 24 to Jan 2, we anticipate a quiet week. During this period, all employees may work remotely, and we put in our best effort to keep workload as light as possible in light of balancing business needs. 
Firm Holidays - 12 firm-designated holidays annually, in addition to the eligible PTO.
Comprehensive Healthcare, Vision, and Dental Insurance - We prioritize your health and wellness with insurance coverage through leading national providers.
Gynecology, fertility, and family-building benefits through leading providers.
Flexible Spending Account (FSA) / Health Savings Account (HSA) Plan - We provide the opportunity to manage your healthcare expenses efficiently through FSA/HSA plans.
Mental Health Support - Enroll in our healthcare plan and gain access to mental health support through Talkspace.
HealthAdvocate - Expert assistance to help you navigate the complexities of the healthcare system.
Disability Insurance - We sponsor short term disability insurance through a leading national provider.
Sick Days - We adhere to applicable state regulations, ensuring you have time to recover when you are not feeling well."
Azure Data Engineer,Tiger Analytics,"Chicago, IL 60642",EmployerActive 26 days ago,Full-time,https://www.indeed.com/rc/clk?jk=d77feb5141088c73&fccid=cba01270e96bb012&vjs=3,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.
 The Azure Data Engineer will be responsible for designing, and implementing advanced analytics capabilities.
 Requirements

Bachelor’s degree in Computer Science or similar field
Strong in Python scripting
Experience extracting/querying/joining large data sets at scale
Experience building data platforms using Azure stack and Spark SQL
Experience building data ingestion pipelines using Azure Data Factory to ingest structured and unstructured data
Strong knowledge on Azure Storage schematics such as Gen1 and Gen2
Experience in harmonizing raw data into a consumer-friendly format using Azure Databricks
Knowledge of Azure networking, security, key vaults, etc.
Experience utilizing Snowflake to build data marts with the data residing in Azure storage is a plus
Good to have exposure to Big data applications
Strong communication and organizational skills

Benefits
 This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility."
Master Data (MDM) Engineer III,Retail Business Services,"Hybrid remote in Chicago, IL",Posted 6 days ago,,https://www.indeed.com/rc/clk?jk=f33e3b4fbd721295&fccid=c9cf363b57be4ab3&vjs=3,"Address: USA-IL-Chicago-300 South Riverside Plaza 
 
Store Code: Arch/Data Master Data (5119270)
 


Retail Business Services, ranked No. 25 on Fast Company’s 2022 100 Best Workplaces for Innovators, is the services company of leading grocery retail group Ahold Delhaize USA, which includes Food Lion, Giant Food, The GIANT Company, Hannaford and Stop & Shop.
 Retail Business Services is looking for a Master Data Engineer III? to help our ?Vendor Master Data Management Team?. The RBS IT team is proud to provide critical services, including software development, hardware purchase and support, network maintenance, data center optimization, around-the-clock IT systems monitoring and much more, to one of the largest portfolios of grocery companies in the nation.  We embrace innovation and creativity, and RBS is ranked No. 25 on Fast Company’s 2022 100 Best Places to Work for Innovators list, which honors organizations that demonstrate a steadfast commitment to encouraging innovation at all levels. We are proud to offer a safe and flexible work environment supported by a thriving culture of belonging and great benefits. We offer the flexibility to work from home and from the office so you can have the work/life balance that suits your lifestyle.

 In your role you will be ?an Individual Contributor? reporting into ?the Vendor MDM manager?. Just a few of your responsibilities are:


 Responsibilities:
  

Develop the technical design for solutions based on the defined scope, requirements, and functional design provided by the Product team and other stakeholders.
Build and configure technical components (interfaces, conversions, reports, workflows) so that solution design meets business needs and solution architecture standards.
Write and document programming code to meet the gathered requirements.
Deliver solutions through ERP or SaaS solutions (e.g. SAP, Manhattan Active WM, Relex)
Perform code reviews and quality assurance to ensure compliance to technical standards and business requirements.

 Qualifications:
  

Bachelor’s degree in Computer Science, Engineering or related field or 8 years of equivalent work experience/certifications
Proven work experience as a Software Engineer or Software Developer within MDM solutions
Experience designing interactive applications
Ability to develop software in Java, Python, C#, R, or other programming languages
Excellent knowledge of relational databases, SQL and ORM technologies (JPA2, Hibernate)



 We look forward to reviewing your application. If you meet the basic qualifications, a recruiter will reach out to you for a quick phone screen to learn more about your career aspirations.
 #li-mm1 #li-hybrid #zr #dicejobs
 Retail Business Services currently provides services to five omnichannel grocery brands, including Food Lion, Giant Food, The GIANT Company, Hannaford and Stop & Shop. Retail Business Services leverages the scale of the local brands to drive synergies and provide industry-leading expertise, insights and analytics to local brands to support their strategies. We are committed to diversity, equity and inclusion and we foster a community of belonging where everyone is valued. 
Retail Business Services is an equal opportunity employer. We comply with all applicable federal, state and local laws. Qualified applicants are considered without regard to sex, race, color, ancestry, national origin, citizenship status, religion, age, marital status (including civil unions), military service, veteran status, pregnancy (including childbirth and related medical conditions), genetic information, sexual orientation, gender identity, legally recognized disability, domestic violence victim status or any other characteristic protected by law. We provide reasonable accommodations to applicants and employees with disabilities. As important as what we do is how we do it. Our team embodies our values of Courage, Care, Teamwork, Integrity and Humor in everything that they do. We have a culture of care that values and celebrates the qualities and perspectives that make us all unique.
 If you have a disability and require assistance in the application process, please contact our Talent Acquisition Department at tad@retailbusinessservices.com. 
For more information, visit https://www.retailbusinessservices.com.
 Job Requisition: 326199_external_USA-IL-Chicago_7102023"
