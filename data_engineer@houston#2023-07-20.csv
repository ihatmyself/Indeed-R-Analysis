job_title,company,job_location,post_date,salary,job_url,job_description
Data Quality Engineer - All-Payor Claims Database - Hybrid,UTHealth Houston,"Hybrid remote in Houston, TX",EmployerActive 2 days ago,"$80,748 - $121,140 a year",https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0B0WYpsfFdlHnzkaod_43XUfc-xLBay7Qn_M2_P6Smr4FgZna4v5OdiEQqbcAGbWm2NqwI9EJrQiIzvyIGqgfawj9RWsEoVSCL7tJNaSZcWUf-rPw9sK7tgbUL4Lx609zZFJzIjvqchEFXvZ7PUMGlHSZImfONDnFkK-HG7cOjjB8c8gmOwBL6-2bVaqWgrov8V47MeRBbv3mTbhLFn-_YnW5aYQiFfsFSlA5qyX_n9dwOSYFnT9tmStNFH2wYuiLoZl3g4qbJID87o9gRdC7XQnG39Hl92-CcBUHmR62yeqse2JWkX3A_huqRNsQFDOF5eDPv2dtla_MjfHjseOYElJILlwcqe6j8hXmraxlF9Ih0vr9KSRNrcpbxtt8mknck4uav9Brb-UaKSDYtpmi6P5jOK92_3VilI3g0q5YZM-kytDEauO_UIMokOpTHFz4XQ5YmNPanzLEysrd1wRyyw7S3msOOD6ZUog_imWLvWgmunfA4VPyRPb1keZNPEJ6o0eJSiXdUE3z-uMXtKLx9liQ21jMTacCV5DHYeSgbSqN2wN8iX8C5m68lNT9duD-Q=&xkcb=SoAD-_M3MLz6rT3-5x0LbzkdCdPP&p=0&fvj=1&vjs=3,"What we do here changes the world. UTHealth Houston is Texas’ resource for healthcare education, innovation, scientific discovery, and excellence in patient care. That’s where you come in.We are seeking a Full-Time Data Quality Engineer to join the UTHealth Center for Healthcare Data as part of the School of Public Health in Houston, TX 77030. This is a hybrid position that requires the employee to reside in Texas. In this position, you will join a fantastic team that strives to make a meaningful difference in the quality of data available to researchers doing innovative healthcare research. The Data Quality Engineer is a skillful team player with a clear track record of transforming big data into actionable insights, which leads to improvements in data quality and associated standards and processes. This individual is a deliberate and systematic scientist who can clearly articulate the goals of the data quality program, practice with rigor and precision, and maintain a balanced/independent point of view to achieve targeted data quality standards.Once you join us you won't want to leave. It’s because we reward our team for the excellent service they provide. Our total rewards package includes the benefits you’d expect from a top healthcare organization (benefits, insurance, etc.), plus:

100% paid medical premiums for our full-time employees
Generous time off (holidays, preventative leave day, both vacation and sick time – all of which equates to around 37-38 days per year)
The longer you stay, the more vacation you’ll accrue!
Longevity Pay (Monthly payments after two years of service)
Build your future with our awesome retirement/pension plan!

We take care of our employees! As a world-renowned institution, our employees’ wellbeing is important to us. We offer work/life services such as...

Free financial and legal counseling
Free mental health counseling services
Gym membership discounts and access to wellness programs
Other employee discounts including entertainment, car rentals, cell phones, etc.
Resources for child and elder care
Plus many more!

Position Summary:The Data Quality Engineer is a skillful team player with a clear track record of transforming big data into actionable insights which lead to improvements in data quality and associated standards and processes. This individual is a deliberate and systematic scientist who can clearly articulate the goals of the data quality program, practice with rigor and precision, and maintain a balanced/independent point of view to achieve targeted data quality standards. Applies the principles of data quality across a range of data sets and their intersection, including but not limited to administrative claims, electronic health records, social determinants of health data sets, and others. It is essential for this person to be a very effective communicator who can evangelize data quality standards throughout the organization.Position Key Accountabilities:

Uses a variety of tools and techniques to develop a suite of data quality metrics which provide benchmarks for assessing data quality both at points in time and across periods of time leveraging key elements of the Patient Demographic Data Quality (PDDQ) Framework developed by the Office of the National Coordinator for Health IT (ONC).
Plans, implements and is responsible for maintaining a metadata management program using the Common Data Layout (CDL) based on CDL specifications published by the APCD Council/NAHDO including standardized definitions of data attributes and associated documentation designed for broad consumption.
Builds quality measurement and scoring models and monitoring frameworks which allow for the proactive and automated assessment of quality across diverse data sets including administrative, clinical, and social determinants of health data when applicable. Conducts periodic assessments and drives processes for continuous improvement.
Applies a variety of methods based on standards and metrics to review and improve data acquisition and data management processes such as statistical analysis, machine learning, data mining, predictive analytics, time series analysis, multivariate regression analysis, statistical process control and optimization solutions.
Collaborates with the Data Linkage Scientist and other team members to improve Master Person Index (MPI), Master Provider Registry (MPR), and other link index match rates.
Performs as a results-oriented problem solver to quickly synthesize complex scenarios, conduct root cause investigations, apply appropriate methods, and plan/implement practical and timely solutions.
Serves as a champion for data quality throughout the organization using a collaborative approach to fully realize the talents of colleagues such as data stewards, IT staff, business analysts, business stakeholders and industry experts.
Interfaces and collaborates with all other functions within the organization and with data submitters on quality-related issues.
Performs other duties as assigned.

Certification/Skills:

Mastery of data discovery and data profiling techniques and tools.
Familiarity with health care claims data and associated X12 knowledge
Ability to influence and collaborate broadly within the organization as a data quality champion
Proficiency with statistical packages, databases and programming languages for data preparation, storage, transformation, analysis or visualization. Examples include R, SAS, STATA, SQL, Python, PySpark, Tableau, Excel and other big data frameworks.
Ability to work with a wide variety of large dataset formats/sources such as relational databases, Parquet, ORC, XML, JSON, CSV, streams and geolocation
Effective communication skills including written, oral, listening and interpersonal.

Minimum Education:

Master's degree in mathematics, engineering, informatics, or a related field.

Minimum Experience:

Three (3) years of enterprise experience as a data scientist, informaticist, senior analyst or related role.
Five (5) years of relevant data analysis experience.

Physical Requirements: Exerts up to 50 pounds of force occasionally and/or up to 20 pounds frequently and/or up to 10 pounds constantly to move objects. Security Sensitive: This job class may contain positions that are security sensitive and thereby subject to the provisions of Texas Education Code § 51.215 Residency Requirement: Employees must permanently reside and work in the State of Texas.
Job Type: Full-time
Pay: $80,748.00 - $121,140.00 per year
Education:

Bachelor's (Required)

Experience:

 Linux-based Pythonic environment: 3 years (Required)
continuous integration/deployment, source code management, or quality assurance: 2 years (Required)"
Data Engineer with Python,TekValue IT Solutions,"Houston, TX 77002 (Midtown area)",EmployerActive 2 days ago,$60 - $65 an hour,https://www.indeed.com/company/TekValue-IT-Solutions/jobs/Data-Engineer-37f0bc3f679fac13?fccid=dd0695607f4cb8d3&vjs=3,"Requirements:
8-10 Required Experince on Data Engineer and Revalent Skills
Experience with NoSQL (MongoDB)
Experience with API'S
Good Knowledge on Data Migration like Oracle to Mongo db
Experience with Python Programming
Job Type: Contract
Salary: $60.00 - $65.00 per hour
Experience level:

10 years
9 years

Schedule:

8 hour shift

Ability to commute/relocate:

Houston, TX 77002: Reliably commute or planning to relocate before starting work (Required)

Experience:

Python: 9 years (Required)
Data Engineer: 8 years (Required)
Pyspark: 6 years (Required)
Oracle Database: 6 years (Required)

Work Location: In person"
Data Engineer,Suvida Healthcare,"Houston, TX 77027 (River Oaks area)",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=8bc8eecdd9551297&fccid=6a2b0db8eb92fae8&vjs=3,"Suvida Healthcare is a neighborhood-centric, multidisciplinary primary care program built to address the physical, behavioral, social, and cultural needs of the underserved Medicare-eligible Hispanic population. Multigenerational in design, Suvidas differentiated approach will enable us to deliver on the quadruple aim, improving health outcomes as well as consumer and employee experience while lowering total cost of care. Suvida will thoughtfully cultivate an empathetic and service-centric environment, positioning us not only as a best-in class health care provider, but also as the provider of choice for our patients, their families, and the community at large.

 Our Purpose
 We are an empowered primary care team creating health equity through an exceptional clinical and consumer experience that improves the quality of life for the people, families, and the neighborhoods we serve.
 Our Vision
 To improve the quality of life for underserved people and those that care for them in neighborhoods across America.

 Job Summary

 Job Summary:
 We are seeking a skilled Data Engineer to design, develop and maintain data pipelines and systems that facilitate the efficient and reliable processing of large amounts of data. The Data Engineer will be responsible for ensuring the optimal performance of our data infrastructure and implementing appropriate data governance and security measures.


 Responsibilities:
 Design, develop, and maintain data pipelines and systems that enable the efficient and reliable processing of large amounts of data


 Ensure the optimal performance and scalability of data infrastructure through effective monitoring, tuning, and troubleshooting
 Work with Data Scientists and Analysts to understand their data requirements and design appropriate solutions that meet their needs
 Develop and maintain data governance and security policies and procedures to ensure the integrity and confidentiality of sensitive data
 Collaborate with cross-functional teams to identify and implement data-related improvements to business processes.
 Implement and maintain data integration solutions that enable the integration of data from various sources into a unified view.


 Develop and maintain documentation of data architecture and processes.
 Hands on experience working with cloud technologies and solutions, with preferred depth in Azure services.
 Ability to successfully execute proof of concept projects and implement new technologies.
 Passion and understanding of new technology and trends including database and analytics technologies, data science, AI and machine learning. Desire and willingness to continuously improve those skills and knowledge.
 Creative and innovative mindset with the ability to drive to outcomes.


 Strong analytical ability - understanding complex technology solutions and how they interrelate with other technologies and business drivers across the enterprise.
 Ability to work with ambiguity and organize requirements to identify options.
 Ability to build productive relationships and collaborate with partners and stakeholders.

 Qualifications:

 Bachelor's degree in Computer Science, Information Technology, or related field
 Proven experience as a Data Engineer, with expertise in designing and implementing data pipelines and systems.
 Strong programming skills in Python, Java, Scala, or other languages commonly used in data engineering.
 Experience with big data technologies such as Hadoop, Spark, or Azure data lake


 Familiarity with data warehousing concepts and technologies such as Redshift, Snowflake, Oracle or Azure Synapse
 Knowledge of SQL and database management systems (DBMS)
 Strong problem-solving and analytical skills, with the ability to work independently and in a team environment.
 Excellent communication and collaboration skills
 If you meet these requirements and are passionate about working with data, we encourage you to apply for this exciting opportunity as a Data Engineer.

 Physical Demands
 While performing the duties of this job, the employee is required to sit for prolonged periods of time, stand, walk, talk, hear, and reach with hands and arms. Hand eye coordination is necessary to operate computers and other office equipment; must be able to operate a motor vehicle. When representing Suvida Healthcare at external events, the Data Engineer is also required to stand for prolonged periods of time, kneel, crouch, bend and lift, and be able to move up to 30 pounds. The work environment characteristics described here are representative of those employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions."
Data Engineer - People Insights,HP,"Spring, TX 77389",Posted 6 days ago,Full-time,https://www.indeed.com/rc/clk?jk=df1b598212f976bf&fccid=1b866506aec22461&vjs=3,"The People Insights team at HP is looking for an experienced Data Enablement Engineer to support the build, design, and development of analytics products and platforms. Specifically this role will focus on platform enablement through data modelling, data orchestration, data pipeline, front end feature enablement, API & connection configuration, calculation development and documentation, and tools and technology implementations.

 Responsibilities:

 Design, develop, and create reporting, analytics, and data orchestration capabilities using applications such as Microsoft Product Stack (Azure,PowerBI), Databricks, Altyryx, Amazon Redshift etc.
 Advises and makes recommendations around building or buying solutions for the following topics: Data model storage and maintenance, data processing layers, data aggregation and data management, and advanced analytics enablement.
 Responsible for making recommendations on ongoing tools and technology selection for People Insights solutions development.
 Responsible for establishing connectivity and enablement between back-end databases and front- end solutions for example ODBC, WebConnector (RaaS), or API development.
 Develop, manage, and maintain centralized dimensional data model for core workforce data at HP.
 Responsible for connecting and operationalizing disparate people data models from across the organization.
 Responsible for testing and solutioning embedded analytics from sources not integrated into core dimensional modelling.
 Presenting written recommendations, requirements, and insights through the addition of technology platforms and net new data sources.
 Build, maintain, and document centralized calculation library (Calculation Language: DAX).
 Creates and maintains documentation for data orchestration.


 Experience & Qualifications:

 7-10 years of experience working in large complex global organization with responsibilities including data warehousing and business intelligence data, techniques, and technology.
 7-10 years working with Business Intelligence (data visualization and reporting) tools and technology, specifically in the space of data orchestration (dataflows, datasets, data marts, business objects, security provisioning) and dimensional modelling.
 Experience implementing solutions using full Microsoft Power Platform considered an asset.
 High level of proficiency working with complex effective dated transactions, change data capture, and slowly changing dimensions.
 High level of proficiency working with DAX or equivalent language to prepare complex and custom calculations and measures.
 Exposure to the application of Python, R, SQL for the purposes of statistical analytics, data querying and or process enhancement.
 Experience supporting full cycle technology implementations in a large complex organization.
 Exposure to the field of People Insights/Analytics considered an asset.
 Required post secondary education in the field of computer, information science, or statistics.



 About HP





  You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you.
 

   So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.
 



   HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.
 



   Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are.
 

   From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!"
Data Engineer - Architecture,Vantage Point Consulting,"Remote in Houston, TX",Posted 20 days ago,Contract,https://www.indeed.com/rc/clk?jk=750947a4861e2e75&fccid=5b5ea8923be4052d&vjs=3,"Location: Chicago or Houston or Remote
  
Duration: 6+ months contract
  

Job Description:


United is modernizing the functionality and the user experience to enable the logistical shipment and receiving of parts required for scheduled aircraft maintenance events.
This will enable United to have the right parts, at the right place and at the right time to provide maintenance to aircraft.
AOG and BMC operate from over 15 stand-alone applications and rely on emails to channel requests and information, which impacts situational awareness and status resulting in delayed decision-making and oversights, that with time are costly to the operation.
This project will modernize the experience and provide United with the tools needed to facilitate decisions and provide transparency in tracking where parts are at in the procurement and shipping process.
Need someone that has the ability to work in both a technical and functional capacity on the team
From a technical standpoint creating a data structure to support the data functions but could control the data aspect. Want them more technical in nature they are able to create an appropriate data structure with multiple inputs and outputs and helping with the data services and pieces 
Need someone self-sufficient and has experience interacting with the business team to understand the structure of the project


Top Skills


Data Mining, Architecting and Modeling
Highly proficient in SQL and nice to have is comfortable with foundry or frontier 
Data Analysis and Design Solutions
PostgresSQL – Need Experience with AWS 
Creating the architecture step above a data analysis creating new data structure and architecture 
Design Solutioning 
Ability to develop user stories 
Familiarity with Supply chain Data - Pyramids or branch of supply chain"
Data Engineer,Integration Developer Network LLC,"Houston, TX 77002 (Fourth Ward area)",Posted 30+ days ago,$65 - $70 an hour,https://www.indeed.com/company/Integration-Developer-Network/jobs/Data-Engineer-f1864bf4bc02aba6?fccid=6af1cd9d656e6476&vjs=3,"Required Skills:
Experience with Oracle
Experience with Semi store Database/ Mysql Database
Experience with Python Programming
Job Type: Contract
Pay: $65.00 - $70.00 per hour
Experience level:

8 years

Schedule:

8 hour shift

Ability to commute/relocate:

Houston, TX 77002: Reliably commute or planning to relocate before starting work (Required)

Experience:

Mysql Database: 6 years (Required)
Oracle: 8 years (Required)
Python: 8 years (Required)

Work Location: In person"
Data Engineer,Southwestern Energy (SWN),"Spring, TX 77389",EmployerActive 9 days ago,Full-time,https://www.indeed.com/company/Southwestern-Energy-(SWN)/jobs/Data-Engineer-fdadc985c29bcc70?fccid=38fcc1e69ff6b897&vjs=3,"Southwestern Energy is searching for a Data Engineer to join our Corporate IT team.
You will analyze user needs and develop solutions to support data science workflows, data and application integrations, analytics platforms, or specialized utility programs with the aim of optimizing operational efficiency while adhering to appropriate data quality and data governance principles. You will work individually and coordinate database development as part of a team and lead small to medium projects and assists on large projects. Functions as primary support for all solutions in one or more discipline(s) and secondary support for multiple solutions in related disciplines. You will report to the BIS Manager and the position is located at our headquarters in Spring, TX.
To be successful in this role you will:

Write, analyze, review, and rewrite programs, using workflow charts and diagrams, and applying knowledge of computer capabilities, subject matter, and symbolic logic.
Perform revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements.
Analyze user needs and software requirements to determine feasibility of design within time and cost constraints.
Confer with systems analysts, engineers, programmers and others to design systems and to obtain information on project limitations and capabilities, performance requirements and interfaces.
Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program.
Develop and perform software system testing and validation procedures.
Store, retrieve, and manipulate data for analysis of system capabilities and requirements.
Analyze information to determine, recommend, and plan installation of a new system or modification of an existing system.
Coordinate software system installation and monitor equipment functioning to ensure specifications are met.
Consult with engineering staff to evaluate interface between hardware and software, develop specifications and performance requirements, or resolve customer problems.
Confer with data processing or project managers to obtain information on limitations or capabilities for data processing projects.
Participate in on-call and after-hours support, including weekends and holidays.
Lead medium projects as defined by scope

Qualifications - External
Your Background includes:

Bachelor of Science degree in computer science, engineering, or management of information systems is preferred.
Minimum of 5 years of software development experience
Experience creating dashboards and analysis using tools such as Microsoft PowerBI, TIBCO Spotfire, Tableau, etc. is required.
Experience querying and developing Oracle and Microsoft SQL Server databases is required.
Experience integrating data using ETL technologies such as Informatica, Dell Boomi, Microsoft SSIS/DTS, etc. is required.
Experience integrating applications using APIs and scripting languages. Python/R is a plus.
Knowledge of WellView, SiteView, Enertia, and other upstream oil and gas systems is a plus.
Ability to communicate ideas in both technical and user-friendly language
Strong customer focus mindset

Job Type: Full-time
Benefits:

401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance

Schedule:

Monday to Friday

Ability to commute/relocate:

Spring, TX 77389: Reliably commute or planning to relocate before starting work (Required)

Work Location: In person"
Data Engineer,TheRIIM LLC,"Houston, TX",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=82824d0546a1efbf&fccid=8b525a8d0577c714&vjs=3,"Company Description
  Client is in Banking & financial domain.



 Job Description
  Job Description Summary

 Summary: As data engineer, you will join the Data, Analytics and Reporting team. Our goal is to help the business we support unlock the full potential of their data. In this role, you will design, implement and support data and analytics solution using a broad range of technologies including Hadoop, Spark, AWS and various NoSQL databases.  Description: We are looking for individuals who are passionate about data and take pride in delivering high quality software. As data engineer, you will join the Data, Analytics and Reporting team. Our goal is to help the business we support unlock the full potential of their data. In this role, you will design, implement and support data and analytics solution using a broad range of technologies including Hadoop, Spark, AWS and various NoSQL databases. You’ll bring your in-depth knowledge of big data technologies best practice and a desire to work in a DevOps environment.





 Qualifications
  Your technical capabilities will include: 

To excel in this role, you will be:
 highly proficient in Hadoop and related technologies including HDFS, Spark, Impala and Hive
 highly proficient in Java, Scala and/or Python
 proficient in AWS including S3, Redshift, EKS, IAM and EC2
 experienced with Linux
 experienced with data modelling
 experienced with CI/CD
 familiar with AWS including S3, IAM and EC2
 proactive and have great communication skills

 Additional Information
  Selection process includes Code exercise.."
Subsurface Data Engineer,Shell,"Houston, TX",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=e4110a76eb545f9c&fccid=167aa4ca2fe7d8e6&vjs=3,"The Role

Subsurface Data Management is helping Shell execute a strategy of moving from Epicure to OSDU. At the same time Shell has unleashed multiple digitalization efforts that require large volumes of SSW data.
 You’ll will be responsible for finding new ways to help Subsurface Data Management execute upon the strategic movement of SSW data to a new platform (Point C), providing opportunities to unlock value from data now (Point B), and post Point C (once OSDU is deployed).
 Your success in this role will flow not only from your technical abilities, but your capacity to manage leaders across natural teams and convince them of the business value to your approaches.
 Where you fit in

 The Integration team is part of the Integration and Seismic Data management team under the GM Subsurface Data Management & WF in the Upstream Subsurface Digital and Data VP-ship.
 The Integration Team works with the business and IT to improve the data landscape with ambitious and realistic plans and have a track record integrating on-premise and cloud systems in a way that delivers business value in the Point B and C timelines.
 You will help the business find fast and lower-cost ways to deliver the data required to optimize digital solutions, accelerate global scaling and value replication, and enable innovative ways of working.

 What is the role
 As a member of this team, you will have the following key responsibilities:

 Assist program and project teams (e.g. X-Digi/Data, (O)SDU and Subsurface Data Management) virtualize and integrate their data in order to deliver upon the tactical and strategic goals from those programs and projects.

 Utilize your knowledge of source systems and project needs to become a liaison between the business and Shell IT.
 Utilize your knowledge of cloud tooling to negotiate with Shell Architects on the positioning of new technology in SSW data flows. This is convincing IT Stakeholders of the validity of our technical solutions.

 Convey to management, programs and projects the business value of our approach to integration. This is convincing the business of the value of our solutions.

 Work scope requires business domain knowledge and technical TIDM knowledge with demonstrable passion for identifying, developing, and deploying new ideas and ways of working. Within this role there will be significant interaction with leaders of programs, projects, IT and Subsurface Data Management, your ability to convey your technical knowledge and how it enables business value will be key to your success.

 What we need from you

 You will bring an open and external mindset with a sense of urgency to drive strategic SSW data integration improvements. You will collaborate and work across organizational boundaries and help develop a collaborative natural team with the business stakeholders.

 Requirements: 

Must have legal authorization to work in the US on a full-time basis


 You have:


 6+ years in a Technical Data Management Role Or proven experience leading projects within Technical Data Management programs. Or proven experience in a relevant data engineering or data science program of project.
 An appetite to discover new technology solutions to improve our technical data workflows that transform our ways of working.
 Experience with AWS services, or Azure equivalents.
 Programming skills utilized in the data science domain (e.g. Python).
 Self-starting and self-managed. You will need to move from requirements to a decomposed set of work (user stories) and deliver that work in 2-week increments (sprints).
 Be able to convey to Product Owners, Program Managers, Chief Data Officers, and Architects the “why” and “how” of your approach to delivering work.
 Be able to convey the business value of proposed solutions to Product Owners, Program Managers, CDOs and Architects when proposing solutions to work, or responding to challenges.
 Knowledge, or experience with, data virtualization tools, especially Denodo would be beneficial.


 Company description 
Shell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world’s growing need for more and cleaner energy solutions in ways that are economically, environmentally, and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals.

 As a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity, and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork, and professionalism, as well as pride in what we do and how we conduct business.

 Building on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.

 An innovative place to work
 There’s never been a more exciting time to work at Shell. Everyone here is helping solve one of the biggest challenges facing the world today: bringing the benefits of energy to everyone on the planet, whilst managing the risks of climate change.

 Join us and you’ll add your talent and imagination to a business with the power to shape the future – whether by investing in renewables, exploring new ways to store energy, or developing technology that helps the world to use energy more efficiently.

 An inclusive place to work
 To power progress together, we need to attract and develop the brightest minds and make sure every voice is heard. Here are just some of the ways we’re nurturing an inclusive environment – one where you can express your ideas, extend your skills, and reach your potential.


 We’re creating a space where people with disabilities can excel through transparent recruitment process, workplace adjustments and ongoing support in their roles. Feel free to let us know about your circumstances when you apply, and we’ll take it from there.
 We’re closing the gender gap – whether that’s through action on equal pay or by enabling more women to reach senior roles in engineering and technology.
 We’re striving to be a pioneer of an inclusive and diverse workplace, promoting equality for employees regardless of sexual orientation or gender identity.
 We consider ourselves a flexible employer and want to support you finding the right balance. We encourage you to discuss this with us in your application.


 A rewarding place to work
 Combine our creative, collaborative environment and global operations with an impressive range of benefits and joining Shell becomes an inspired career choice.

 We’re huge advocates for career development. We’ll encourage you to try new roles and experience new settings. By pushing people to reach their potential, we frequently help them find skills they never knew they had, or make career moves they never thought possible.




Disclaimer 


    Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date. Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Shell/Shell Group companies around the world. The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand. Shell participates in E-Verify. All qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, protected veteran status, citizenship, genetic information or other protected status under federal, state or local laws. Shell is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability. As a US Federal Contractor, hiring selections are subject to periodic audit review and documentation of your selections should be maintained for a period of three calendar years. It is the policy of Shell in the U.S. (“Shell”) to provide equal opportunity to all individuals, employees and all qualified applicants for employment consistent with employment requirements and qualifications. Shell prohibits discrimination based on race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, veteran status, citizenship, genetic information, or other protected status under federal, state or local laws. All employees are expected to support this policy and contribute to an environment of equal opportunity. If you need an accommodation for a disability during the resourcing process, please speak with an HR representative."
Data Engineer with PL/SQL Developer,Integration Developer Network LLC,"Houston, TX 77004 (Midtown area)",EmployerActive 28 days ago,$65 - $75 an hour,https://www.indeed.com/company/Integration-Developer-Network/jobs/SQL-Developer-43cf3a11e94a0059?fccid=6af1cd9d656e6476&vjs=3,"Recent pl/sql development work experience with Oracle 19
Must have working experience with tools like Airflow, Git
Must have python coding experience and REST API development experience
Plus would be experience with microservices, docker, Kubernetes
Plus would be experience with accounting and financial data
Job Type: Contract
Pay: $65.00 - $75.00 per hour
Ability to commute/relocate:

Houston, TX 77001: Reliably commute or planning to relocate before starting work (Required)

Experience:

Python: 3 years (Required)
PL/SQL: 8 years (Required)

Work Location: In person"
Data Engineer & Analyst,Benelynk,"Remote in Houston, TX 77002",Posted 30+ days ago,"$80,000 a year",https://www.indeed.com/rc/clk?jk=18555195c7601478&fccid=9656435542936ad4&vjs=3,"COMPANY OVERVIEW
 

   Does the idea of applying your talents at a company that assists people in understanding how to obtain additional health care benefits and compensates well for doing so, inspire you? We call it 
  “Doing good while doing well” and invite you to apply to join us and begin moving forward along a beneficial career path – one built on providing solutions by helping others navigate through the complex world of health care benefits.
 

   Here at BeneLynk, our mission is to improve lives and positively impact social determinants of health barriers by providing our healthcare partners with the information they need, and people with the advocacy they deserve. We are laser-focused on our longstanding area of expertise in the healthcare world. We fully understand barriers and surface solutions, then provide the advocacy that changes lives and improves outcomes. Everything we do, from the systems we build, to our government relations, to our outreach operations, is in service of this one central vision.
 


 WHO WE ARE
 

   We are big-hearted people, passionate about serving our health plan clients, their members, and each other. We are a team in every sense of the word, striving toward a common mission – that is the goal of everyone at BeneLynk. Every day, we are relentless in helping people who need essential resources to make their lives easier and healthier. The members we serve call us ""miracles,"" ""kind,"" ""professional,"" ""human,"" and ""compassionate,"" and all with ""service that gets the job done."" We pride ourselves on creating a healthy environment for our employees to thrive in their ability to assist others.
 


 Data Engineer & Analyst (Remote)
 

   POSITION SUMMARY
 


 A talented and driven Data Engineer & Analyst is required to help facilitate growth for dynamic healthcare services company. BeneLynk is a fast growing, data driven company that delivers services benefiting veterans, Medicare enrollees, and Medicaid enrollees. BeneLynk delivers value to its clients through its deployment of analytics and data integration technologies.
 

   Within BeneLynk, the BI and Analytics team supports that growth by providing reporting and analytics across the organization. The company is building out its software platform and is looking to leverage technologies in cloud services, storage, data visualization, machine learning, and artificial intelligence.
 

   This is a technical role that involves defining changes to the warehouse data model and building scalable and efficient processes to extract or modify warehouse data. The ideal candidate will be comfortable in a fast-paced, high-performance environment with hands on data processing and data modeling experience in a ""big data"" environment. This role would also at times act as a liaison between the data team and the project/functional analytics leads.
 

   KEY RESPONSIBILITIES
 

 Collaborate with business stakeholders to review and identify data requirements.
 Development and management of Azure Data Factory Pipelines, Data Sources, Data Flows, and custom Integration Runtimes
 Leverage Microsoft PowerBI for the visualization and deployment of model and ad-hoc data.
 Maintain Azure Data Warehousing (DW) infrastructure, data-organization, ETL and support
 Leverage Azure Analysis Services to build conceptual and logical data models
 Analyze and validate data accuracy of report results
 View and understand other project or functional areas to consolidate analytical needs and facilitate team growth, helping to train and integrate new data team members



 REQUIRED SKILLS, QUALIFICATIONS, AND EXPERIENCES:
 

   The following skills and experiences are required:
 

 Advanced SQL skills including knowledge of joins, window functions, groupings, subqueries, and stored procedures.
 Must have specific experience in a cloud environment, preferably Microsoft Azure. Must be comfortable spinning up new applications and services and understand the basic architecture of cloud-based solutions
 Experience with data platforms and in data transformation and extraction: some combination of ETL/ELT, relational & snowflake schema design, query design, performance analysis and optimization
 Experience developing and managing reporting solutions, dashboards, etc.
 Experience collaborating with various business stakeholders to gather requirements, review any process changes, and translate those into work items.



 PREFERRED SKILLS, QUALIFICATIONS, AND EXPERIENCES:
 

   The following skills and experiences are preferred but not required:
 

 Experience deploying modern data solutions leveraging components like Azure functions, Azure Storage Accounts, Azure Data Factory, Data Flows, Azure Data Lake, Azure SQL, Azure Synapse, Streaming Analytics and Data Lake, Azure SQL, Azure Synapse,
 

 Technical degree in computer science, computer engineering, or a related technical field
 Knowledge of and the ability to perform basic statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniques
 Experience working with R or Python
 Prior experience with PowerBi
 Big Data experience with products such as Hadoop or MongoDB, and/or cloud platforms from Microsoft, Google, or Amazon
 Project management experience
 Experience working in both Agile and Waterfall environments



 PHYSICAL DEMANDS
 


 The physical demands described here are representative of those that must be met by an employee to successful perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
 


 Physical Activities – Remote



 Weight Lifted/ Force Exerted – The employee’s job does not require weight to be lifted or force exerted.



 WORK ENVIRONMENT
 


 This role is a remote position.
 


 POSITION TYPE/ EXPECTED HOURS OF WORK
 


 Hours are flexible, but the Data Engineer will be expected to coordinate with teams working out of several different time zones, primarily EST
 


 SALARY
 


 Salary will be based on experience
 

   The minimum salary for this position is $80k annually
 


 EMPLOYEE PERKS
 

 Work hard, play hard! Having an engaged workforce and positive work environment is one of our top priorities here at BeneLynk. We do so through numerous initiatives that can be found below. We like to call our virtual work community, “The Bene-Verse”. We also have an internal Culture Ambassador committee dedicated to ensuring all employees have a pleasant and exciting work experience.
 

   Monthly Company Town Hall Events:
 


 We love the opportunity to come together as a company. Join us monthly as we discuss exciting company updates, internal promotions, internal awards, upcoming events, and more!




 Monthly Internal Mental Health Newsletters:
 


 Our Culture Ambassadors spearhead an internal newsletter centered on mental health topics. Our employees’ overall wellbeing is our top priority, so we like to provide support whenever it is needed through this uplifting internal newsletter.




 Monthly Streaming Services Perk:
 


 Yes- we pay YOU to enjoy the television shows that you enjoy! We pay up to a $12 per month for any streaming service subscriptions that you currently have.




 Tickets at Work Perk:
 


 Enjoy discounted movie tickets, hotel stays, and more through our company’s ‘Tickets at Work’ perk!




 Monthly Lunch & Learn Events:
 


 Meet key members of our Senior Management team through engaging Lunch & Learn sessions on a monthly basis. Lunch is on us for those employees that sign up!




 Monthly Bene-Verse Events:
 


 We put on awesome monthly events for our employees including virtual trivia, team building exercises, guided painting sessions, and more!




 EEO STATEMENT
 

   At BeneLynk, we don’t just accept differences; we celebrate, support, and thrive on them for the benefit of our employees, our products, and the communities that we serve. All employees share in the responsibility for fulfilling this company’s unwavering commitment to equal employment opportunity. BeneLynk is an equal opportunity employer, and as such, employment here is solely based on a person's merit and qualifications directly related to their professional expertise. BeneLynk does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, military status, marital/familial status, pregnancy, or related condition, including breastfeeding, or any other classes protected by law.
 

   It is BeneLynk’s policy to comply with all applicable federal, state, and local laws pertaining to nondiscrimination and equal opportunity. The company's EEO policy, as well as its affirmative action obligations, includes the full support of the company, including its Chief Executive Officer because it's just the right thing to do and we hope that you think so too.
 

   If you require reasonable accommodation in completing an application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to our HR team.
 


 E-VERIFY
 

   BeneLynk participates in E-Verify. We will provide the U.S. Social Security Administration (SSA) and, if necessary, the U.S. Department of Homeland Security (DHS) with information from each new employer’s Form I-9 to confirm work authorization.
 

 ***Offer of employment is contingent upon the results of a required background and drug screening.***"
Data Warehouse & Artificial Intelligence Engineer,Foxconn Corporation,"Houston, TX 77064",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=7d000e2c62c26306&fccid=2c4b4bbb6840a346&vjs=3,"Job Description:

 Design, Implement and Maintain data warehouse.

 Duties and Responsibilities:


 Develop, test, and deploy extraction, transformation and loading (ETL) routines to load the data warehouse using SSIS, stored procedures, etc.


 Develop analytics including reports, dashboards, and data visualizations


 Troubleshoot BI-related problems and tune for performance


 Implement and oversee a company-wide data governance program to support master data management and resolve data definition discrepancies among stakeholders


 Plan the technical approach for implementing analytics strategy across multiple channels


 Plan and implement activities to maintain data confidence


 Provide technical direction and technical support for all member of the team


 Architect and implement analytics solutions to meet data collection and reporting needs.


 Work with team to recommend analytic software


 Provide general troubleshooting assistance for analytic reports and break fixes


 Wrangle data (a.k.a. data engineering) from a wide variety of complex data sets large volumes of data into normalized and enriched data sets.


 Assemble and evaluate data such that new insights, solutions, and visualizations can be derived.


 Perform data discoveries to understand data formats, source systems, file sizes, etc. and engage with internal and external business partners in this discovery process.


 Deliver data acquisition, transformations, normalization, mapping, and loading of data into a variety of data models.


 Collaborate extensively with Technology to design data ingestion, data models, and automated operational metrics for consistently high quality data


 Supports the research, analysis and presentation of information by: producing reports, compiling and summarizing information, producing supporting documentation and exhibits, and verifying information received from external sources.


 Assists other associates with preparation of reports and use of information systems, software and related sources of information. Trains other users on report preparation and database access.


 Perform other duties as assigned.


 Required Knowledge, skills and abilities:


 Ability to manage change successfully in a fast-paced environment


 A passion for learning and the ability to do so on the fly


 Must be strategic, dynamic, and detail-oriented. The ideal candidate is an analytical thinker, a self-starter and a quick learner.


 Ability to design and architect method of extracting data from its original source to another location (i.e. a data lake) to make that data consumable for a variety of downstream purposes such as applications, visualizations, analytics and other related data science activities.


 Basic understanding of data science


 Ability to transforming and map one ""raw” data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics.


 Exceptional ability to clearly and effectively communicate with IT peers and users at all levels of technical and business acumen.


 Strong time management skills and multi-tasking capabilities


 Ability to understand business rules governing financial and budgeting process


 Exceptional oral and written communication skills


 Self-motivated, ability to set priorities and meet deadlines


 Education and Experience:


 Bachelor's degree in Computer Science, Business, Economics, Information Science, or Analytics


 Minimum of 3 years of experience with data analytics across multiple channels


 Experienced with the technologies required to implement Analytics across multiple channels, (for example, Data Layer, Custom JavaScript, JAVA, AJAX, HTML, Objective-C, Swift)


 Knowledge of Tableau is a plus


 Familiarity with Microsoft Power BI


 Extensive experience with ETL and/or other Big Data processes.


 Contract manufacturing experience is a plus.


 Foxconn Assembly, LLC is an Equal Opportunity Employer (EOE). All qualified candidates will receive consideration without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, or marital status in accordance with applicable federal, state and local laws.
 Foxconn Assembly, LLC participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.
 
 
NbXn0DyWY6"
Data Center Applications Engineer,Toshiba International Corporation,"Hybrid remote in Houston, TX 77041",EmployerActive 10 days ago,Full-time,https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0ChbgYjWcif22hw4nRPBa9ZpaWXN2YxPMimdtIolzSdeG3K5hthPdZ9-Dk26gWUOFtp6Jyjm1HeGjMcXx62CdnZlOCNme8dcKuBrATIu5QXphTSu9U-xcgIUWY91JQfCVSs2LLbQoT8RkAdJZZq1wm41z93vT7DfJAqmUVv5ZoIKCPgK2VC3n6azOTgOsBAFv5NjRi0-JtcZBMkDeI7BPKHP_I_ig_9InBZASyCk-w_xYrKCORfFDInBTDR7tvMtD4x2ZDSBtLmqMQjxNBFX3l7pC-9qaX-mZRQmBtjGEXdHEAfprfAkrtleKHyYWtRPW-spN-9QH6Xo92KNZFmUEMkEH-O5sOXIRkPR-l8DALPirmCzz9UZwIzu86_VtlBxJvW9qWz2Hqly4G2aElMN7hFZ0mn1NmDq3BamWXl7HtHLToWa57UVGL1bZUIBna4jbXrrNkhJNL0G3_xeZXmTZToDMQg-krvMG7a0rhSuDWA-LKjLDSfyIzOEcJzw30WYxzevzYDBl-ailbnOKYvYwUGbhzA8oqjk_gNru5KmLqShW4h7EGeW8dMvK-qQTv3j1WfhN66Nudps4haIbokgEaF&xkcb=SoB3-_M3MLz6rT3-5x0HbzkdCdPP&p=12&fvj=1&vjs=3,"Toshiba International Corporation is a world leader in the design and manufacture of motors, motor controls and power electronics products. Many of these products are designed, built and tested in our 1,000,000 square foot state-of-the-art manufacturing facility in Houston, TX. We have developed a totally integrated manufacturing process from research and development, design, engineering, production and manufacturing to after-market service and sales & marketing. Toshiba differentiates itself from its competitors through its commitment to quality and reliability. We build products to perform in the most difficult conditions. From raw material to the finished product, we assure exacting quality, engineering excellence and stringent testing to meet domestic and international performance standards.
Job Summary:
The Data Center Application Engineer uses technical knowledge along with interpersonal skills to understand Data Center customer`s issues and propose solutions. Data Center Engineer may participate in all facets of the business cycle including; inputs on new product designs, review of Data Center one lines and applications, quoting, forecasting, preparing technical literature, presenting product features and benefits, solving technical issues.
Responsibilities:

Assist Product Managers and the UPS sales department with Data Center product support including technical presentations, proper application of our products, review of customer engineering specifications, preparation of quotations, and obtaining answers to questions at all stages of negotiation, production, and after shipment activities.
Possesses extensive knowledge of the Data Center product lines, industry standards (i.e. UL, CE, NEMA, IEEE, etc.)
Possesses extensive knowledge of the application of Toshiba`s and competitors product offerings in complex Data Center systems.
Provides technical guidance and mentorship to more junior engineering team members.
Develops and reviews product literature such as manuals, brochures, application notes, success stories, Technical Document papers, etc.
Possesses an extensive knowledge of Toshiba Data Center complimentary products.
Creates test specifications / test plans for Data Center products.
Capable of testing assigned Data Center products and competitor`s products in the laboratory environment for their performance characteristics. Interface with internal and external
Design Engineers for the design and development of existing and new Data Center products, author and technically review new product specifications, as well as resolving technical problems on supplied products.
Interface with internal and external manufacturing regarding customer orders.
Communicate with sales force and customers and serve as a key contributor in Data Center sales activities.
Train sales force and customers independently and in-group settings.
Complete additional projects as assigned by management.
Comply with all Toshiba policies, procedures and link company objectives to assigned activities.
Provides leadership to ensure group adherence to policies, procedures and company objectives.
Responsible for preparing competitive analysis.
Employee needs to be aware and maintain profitability through orders and quotes.
This position may be responsible for sign off/review of quotes, according to Toshiba s policy.
Travel: 25% to 50%

Educational Requirements:

An engineering degree in electrical engineering (BSEE or MSEE).

Experience Requirements:

At least 4 years' experience in data center infrastructure over 1MW, including UPS, design, and operations.

Job Type: Full-time
Schedule:

8 hour shift

Work Location: Hybrid remote in Houston, TX 77041"
Software Data Engineer,HP,"Spring, TX 77389",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=d2b744775bd134ff&fccid=1b866506aec22461&vjs=3,"Applies advanced subject matter knowledge to solve complex business issues and is regarded as a subject matter expert. Frequently contributes to the development of new ideas and methods. Works on complex problems where analysis of situations or data requires an in-depth evaluation of multiple factors. Leads and/or provides expertise to functional project teams and may participate in cross-functional initiatives. Acts as an expert providing direction and guidance to process improvements and establishing policies. Frequently represents the organization to external customers/clients. Exercises significant independent judgment within broadly defined policies and practices to determine best method for accomplishing work and achieving objectives. May provide mentoring and guidance to lower level employees.

 Responsibilities

 Leads one or more project teams of other data engineers for all stages of design and development for complex, secure and performant data solutions and models, including design, analysis, coding, testing, and integration of structured/unstructured data.
 Builds and manages relationships throughout the organization
 Reviews and evaluates designs and project activities for compliance with architecture, security and quality guidelines and standards; provides tangible feedback to improve product quality and mitigate failure risk.
 Provides domain-specific expertise and overall data systems leadership and perspective to cross-organization projects, programs, and activities.
 Drives innovation and integration of new technologies into projects and activities in the big data space.
 Collaborates and communicates with project team regarding project progress and issue resolution.
 Represents the data engineering team for all phases of larger and more-complex development projects.
 Provides guidance and mentoring to less experienced staff members.


 Knowledge & Skills

 Extensive experience with data engineering tools, languages, frameworks to mine, cleanse and explore data.
 Excellent analytical and problem-solving skills.
 Fluent in NoSQL & relational based systems.
 Strong experience in overall architecture of big data systems, cloud services/systems.
 Designing data systems/solutions to manage complex data in complex, distributed and massively parallel systems.
 Evaluating forms and processes for database architecture testing and methodology, including writing and execution of test plans, debugging, and testing scripts and tools.
 Excellent written and verbal communication skills; mastery in English and local language.


 Ability to effectively communicate product architectures, design proposals and negotiate options at senior management levels.
 Extensive experience with working with the multiple BI platforms (Thoughtspot, PowerBI, Tableau, etc.)
 Minimum 5+ years of experience in data integration and data integrity concepts
 Experience in data integrations with SAP using tools like Odata services/ SLT/API


 Ability to and aptitude with extracting data out of SAP
 Expertise in defining an overall solution and technical architecture, design solutions involving application development, data integration between SAP systems and non-SAP systems, between On-premises SAP and on-cloud applications
 Knowledge on various SAP data structures/models and integration framework
 Knowledge on SAP CPI
 Knowledge in sustainability areas is a plus


 Scope & Impact

 Collaborates with peers, junior engineers, data scientists and project team.
 Typically interacts with high- level Individual Contributors, Managers, Directors and Program Core Teams.
 Leads multiple projects requiring data engineering solutions development.
 Drives design innovation.


 Education & Experience

 Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent.
 Typically 6-10 years’ experience.


 About HP





  You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you.
 

   So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.
 



   HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.
 



   Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are.
 

   From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!"
Data Engineer,CAPCO,"Houston, TX",Posted 20 days ago,,https://www.indeed.com/rc/clk?jk=31f52de76214beb6&fccid=c2a63affe8751868&vjs=3,"About the team:
 Capco’s Data Team helps our clients transform every aspect of their business. We are highly skilled at formulating data strategy, defining business and technology initiatives across the data management lifecycle, and aligning multi-year strategic roadmaps with client’s business goals. As digital technologies advance and regulations tighten, today’s consumers – and, therefore, today’s businesses – are becoming more aware of the importance of good quality data. We work to establish holistic ways to effectively manage data through the modern data supply chain and facilitate consumption through analytics, modelling, AI, machine learning, dashboarding, and reporting.
 About the Job:
 As a member of our Data Team, you will work across Capco’s different domains and solution offerings to help break down large problems, develop approaches and solutions. As a Data Engineer, you will create analytics reporting and provide data-driven strategic insights, trends, and perspective to help drive transformation for our clients.
 What You’ll Get to Do:

Work on hard problems with smart people.
Be highly motivated, result-oriented, and take pride in being a problem solver.
Work with new technology, focus on using the right tool for the job, rather than any sticky preference for a tool or technology.
Linux system administration, development and production environments.
Learn and share knowledge across our engineering teams, so we can continue to iterate and improve.
Write reusable, testable, and efficient code as needed.
Design and implement of low-latency, high-availability, and performant database systems.
Work on implementation of data pipelines/data warehouses/data marts/ODSs/Lakehouses.
Collaborate and work on integration of data storage solutions.
Cloud, container and microservices infrastructures.
Software security.
Focus on performance tuning, improvement, balancing, usability and automation.

What You’ll Bring with You:

Data Analysis – Intermediate to expert level with algorithms and complexity analysis.
Data Engineering -using Microsoft Azure cloud and on prem Spark/Hadoop Development.
Data Engineering Foundation – Certification nice to have, theory and practice.
Real-time event processing.
Proficient in Azure technologies such as: Azure Data Factory (ADF), Azure Data Bricks (ADB), Azure Active Directory, Azure Storage, Azure data Lake Services (ADLS), Azure key vault, Azure SQL DB, Azure HDInsight and OR AWS.
VBA, Python, PowerBi, Excel.
Functional programming.
Data Engineering using Microsoft Azure cloud and on prem Spark/Hadoop Development
Experience in Energy Trading and/or experience in the competitive Gas and Power markets a plus.

Why Capco?
 A career at Capco is a chance to help reshape the competitive landscape in financial services. We launch new banks, transform existing ones, and help our clients navigate complex change. As consultants, we work on the front-end business design all the way through to technology implementation.
 We are the largest Financial Services focused consultancy in the world, serving everyone from global banks to emerging FinTechs, from strategy through digital transformation, design, business consulting, data and analytics, cyber, cloud, technology architecture, and engineering.
 Capco is a young and growing firm. We maintain an entrepreneurial spirit and growth mindset and have minimal bureaucracy. We have no internal silos that get in the way of your career opportunities or ability to focus on our clients and make a difference to the business. We offer the opportunity for everyone to learn rapidly, take on tough challenges, and get promoted quickly. We take pride in our creative, collaborative, diverse, and inclusive culture, where everyone can #BYAW.
 We offer highly competitive benefits, including medical, dental and vision insurance, a 401(k) plan, tuition reimbursement, and a work culture focused on innovation and creation of lasting value for our clients and employees.
 Ready to take the Next Step
 If this sounds like you, we would love to hear from you. This is an opportunity to make a difference and contribute to a highly successful company with a significant growth trajectory."
Data Integrity Engineer - Aveva PI,Meta,"Remote in Houston, TX 77001",,,https://www.indeed.com/rc/clk?jk=f75d235d2f2e9fb4&fccid=d314ad972cb806dc&vjs=3,N/A
Senior Data Engineer,"Vorys, Sater, Seymour and Pease LLP.","Houston, TX 77010 (Downtown area)",,Full-time,https://www.indeed.com/rc/clk?jk=11708fcadce2d364&fccid=1278a7bab1639d00&vjs=3,"Precision eControl is an Ancillary Business of Vorys, Sater, Seymour and Pease LLP.
 
Precision eControl is all about helping brands better manage their eCommerce presence on Amazon and other online marketplaces. As a Senior Data Engineer, you will be part of a team that creates innovative, cutting edge, one of a kind solutions that are revolutionizing how brands manage online marketplace sales.
 Position Summary
 The Senior Data Engineer for the Azure infrastructure will be responsible for the day to day operations of a large data warehouse, and will work closely with the business, product team, and the technical staff to ensure alignment to goals and objectives. Utilizing experience with Big Data, this position will drive consensus on designs of stable, reliable and effective dynamic ETL pipelines leveraging Azure Synapse Analytics Pipelines. At this time, candidates who would work in the following states will not be considered for this role: VT, RI, NY, NJ, NH, MI, ME, MA, DE, CO, CT, CA, and AZ.
 Essential Job Functions

 Drive consensus on designs of stable, reliable and effective dynamic ETL pipelines leveraging Azure Synapse Analytics Pipelines.
 Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
 Design, implement, and document data load processes from disparate data sources into Azure Synapse Pipelines.
 Work with Continuous Integration/Delivery using Azure DevOps and Github.
 Provide data management, monitoring, troubleshooting and support to client success
 Create various triggers to automate the pipeline in Azure Synapse Analytics Pipelines.
 Tune SQL queries in Azure SQL DB, Azure Synapse and solve complex data challenges and deliver insights that help our customers achieve their goals.
 Self-organize as part of a small-size scrum team and apply data engineering skills.
 Follows industry best practices and meets company’s security and performance and requirements

 Knowledge, Skills and Abilities

 Minimum three (3) years’ experience with MS SQL/T-SQL
 Minimum three (3) years’ experience with Azure SQL
 Minimum three (3) years’ experience with Apache Spark (PySpark)
 Minimum of three (3) years’ experience with Azure Data Factory or Azure Synapse building dynamic ETL pipelines
 Minimum three (3) years' experience building dynamic Spark notebooks in Azure Synapse Spark or Azure Databricks
 Minimum three (3) years’ experience with Python
 Minimum two (2) years’ experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
 Experience working with parquet, json , delta, avro and csv files
 In-depth understanding of data management (e.g. permissions, recovery, security and monitoring)
 Experience with Data Warehouse Architecture
 Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
 Excellent analytical and organization skills required
 Ability to understand user requirements
 Client service mindset
 Excellent verbal and written communication skills
 Excellent problem solving skills
 Familiarity with Agile frameworks a plus

 Education and Experience

 Bachelor's degree in related discipline or combination of equivalent education and experience
 7-10 years of experience in similar field

 Precision eControl LLC does not discriminate in hiring or terms and conditions of employment because of an individual’s sex, race, age, religion, national origin, ancestry, color, sexual orientation, gender identity, genetic information, marital status, military/veteran status, disability or any other characteristic protected by local, state or federal law. Precision eControl only hires individuals authorized for employment in the United States."
Big Data Engineer - PySpark,Logic20/20 Inc.,"Houston, TX",,"$130,000 - $155,000 a year",https://www.indeed.com/rc/clk?jk=7f7b1f6f3668d307&fccid=2e9e942085461a66&vjs=3,N/A
Data Security Engineer - Corporate - US,Sysco,"Houston, TX",,Full-time,https://www.indeed.com/rc/clk?jk=c3d43f2ceada2c1e&fccid=053befe8409ab9e4&vjs=3,N/A
Senior Data Engineer,Business Intelli Solutions Inc,"Houston, TX",,"From $130,000 a year",https://www.indeed.com/company/Business-Intelli-Solutions-inc/jobs/Data-Engineer-a70fee14e91e98c7?fccid=7c90bc2e3e871d56&vjs=3,N/A
Sr. Data Engineer,mBridge Solutions,"Houston, TX",,Contract,https://www.indeed.com/rc/clk?jk=37dcdbed1192af5c&fccid=2605c7c80b4a846c&vjs=3,"mbridge is seeking an experienced Data engineer for a leading Oil and Gas client in Houston, TX.
  





Job Title: Senior Data Engineer 



Contract: 12 months plus 



Location: Houston, TX 





  N 
  ote: Only Houston, TX candidates 




Responsibilities: 


Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. 


Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. 


Create data tools for analytics and data scientist team members that assist them in 


Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. 


Work with data and analytics experts to strive for greater functionality in our data systems. 


Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. 


Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other technologies. 


  building and optimizing our product into an innovative industry leader.
  






Requirements 

Required Qualifications: 



Minimum 10+ years of experience 


Analytics/data product solution architecture on Azure (Azure Data Factory, Databricks) 


Data extract, load and transformation techniques and tools including orchestration of needed azure resources 


Azure analytics services 


Programming, scripting (Python, SQL, Scala) 


Analytics data frameworks (Spark etc.) 


Data architecture concepts understanding (relational and dimensional data models) 


Information security 


Software engineering tools and methodologies (e.g. Agile, ADO, Ansible, GIT)"
Data Performance Engineer,National Oilwell Varco,"Hybrid remote in Houston, TX 77086",,"$82,632 - $101,557 a year",https://www.indeed.com/company/NOV/jobs/Performance-Engineer-f7c3a7d81c58e847?fccid=0059806ce5dabd16&vjs=3,"19332 - View NOV careers webpage for more opportunities at www.nov.com/careers/.
Responsibilities:

Analyze drilling and equipment data to measure operational performance of NOV Drilling Automation systems to support the Performance Center and its customers.
Use data visualization tools to monitor, develop performance reports and assist team members to maintain top performance at the operational level.
Proactively provide insights and detailed analysis to our customers and establish Key Performance Indicator (KPI) goals to maintain drilling efficiencies and automation performance.
Review and validate data received from the customer’s drilling automation systems.
Analyze and interpret drilling data to determine operating performance metrics and identify areas for improvement with equipment tuning, maintenance and Automation usage.
Attend customer operation planning sessions to discuss and determine KPI targets for well sections.
Create detailed Performance Reports utilizing data visualization tools and provide analysis on current drilling and equipment operation metrics.
Drive action recommendations based on analytics and communicate to management.
Perform data profiling to identify and understand anomalies.
Implement new data analysis methodologies.
Identify and communicate opportunities for Performance Center improvement based on data analysis and customer feedback.
Assist the Performance Center teams in providing insight for troubleshooting, utilization of automated systems and recommendations for data technology improvements.

Qualifications:

Bachelor’s degree in engineering.
5 or more years’ experience in O&G or drilling operations preferred.
Location: 5100 N Sam Houston Pkwy West, Houston TX. 77086.
Hybrid work schedule (3 days in the office and 2 days remote work) once training is completed.
Ability to travel internationally.
Proficiency with MS Visio, Excel, PowerPoint, Project, Teams, SharePoint a plus.
Proficiency with JIRA and Confluence software a plus.
Proficiency with Amphion and/or Cyberbase Controls preferred.
Proficiency with NOVOS, MMC, and/or other Automation products preferred.
Proficiency with Business Intelligence tools (Power BI, Tableau, Grafana) preferred.
Thorough knowledge of Drilling Fundamentals and Equipment required.
Experience with Drilling Controls (Amphion, Cyberbase) or similar a plus.
Proficiency in Automation Systems (NOVOS, MMC, etc.) or similar a plus.
Comfortable with figures and collecting, studying, and interpreting data.
Ability to compile, configure, and present data in a concise manner.
Skilled in creating and manipulating Excel spreadsheets. Knowledge of SQL or basic programming a big plus
Experience transforming data into reports, dashboards, and KPIs

NOV Rig Technologies makes and supports the world’s most advanced drilling solutions. To learn more about Rig Technologies products and services, please visit us at https://www.nov.com/about/our-company-structure/rig.
Job Type: Full-time
Pay: $82,631.78 - $101,556.55 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Employee discount
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Referral program
Retirement plan
Vision insurance

Compensation package:

Bonus pay

Experience level:

10 years
5 years
6 years
7 years
8 years
9 years

Schedule:

8 hour shift

Ability to commute/relocate:

Houston, TX 77086: Reliably commute or planning to relocate before starting work (Required)

Experience:

offshore drilling or monitoring rig equipment: 5 years (Required)
analyzing drilling and equipment data work: 5 years (Required)
data visualization tools to monitor performance reports work: 5 years (Required)

Work Location: Hybrid remote in Houston, TX 77086"
Excel Expert Software Engineer/Data Scientist,Ed Mehlman and Associates,"Houston, TX",,,https://www.indeed.com/rc/clk?jk=49bd94b747a337d7&fccid=3af7f76841d08814&vjs=3,"We are seeking an Excel expert software engineer with excellent general technology expertise and problem-solving skills to build and run new software modules in our cutting-edge proprietary software suite. Candidates can have any education background but a degree in computer science, data science, and/or finance is a plus. Extreme location and hours flexibility, and commission component of compensation plan can result in extremely lucrative position for high achievers. Excellent performers will have extreme growth and management opportunities as well.
Position Details
Responsibilities

Understand current technical problems related to analyzing and reporting on large datasets, and design and implement elegant software solutions
Prepare and run specific software modules with emphasis on refining and improving the software modules and workflows
Position work schedule has inherent flexibility and working from home is recommended

Compensation: Total compensation well above-market for high achievers including commission based on percentage of productivity with no cap or limit; excellent performers will have significant future growth roadmap as well
Qualifications

General coding experience required; Excel expertise required; automation, SQL Server, and/or Python expertise valued
Expertise with large dataset and database analytics required
Verbal and written communications skills required
Ability to quickly learn a variety of new software programs important"
Sr Business Intelligence Data Engineer,American National Family of Companies,"League City, TX",,,https://www.indeed.com/rc/clk?jk=a8afe39d04e6ea1b&fccid=c6f06dab0431c8f3&vjs=3,"Job Posting




American National is seeking a Sr Business Intelligence Data Engineer for our League City, TX location. The Sr Business Intelligence Data Engineer is responsible for the delivery of the corporate data warehouse and the overall execution of the data integration solutions. The Sr Business Intelligence Data engineer will support strategic, tactical, and operational data warehousing to ensure data is acquired from the correct source system and transformed with the correct logic so meaningful information is delivered in a timely manner.


Your Impact:



Develop and deploy the extraction, transformation, and loading routine for the data warehouse environment by sourcing the data from the operational systems, applying the business transformation rules, and loading it to the data warehouse and data mart environments
Analyze and develop strategies for data acquisitions, archives, recovery, and implementation of the ETL repository and load jobs
Determine the optimal approach for obtaining data from diverse source system platforms and moving it to the data warehouse
Implement and execute strategy for change data capture
Create testing methodology and criteria
Perform detailed data analysis including data quality and consistency by monitoring performance production data
Investigate, analyze, document, and correct reported defects.
Develop specifications for data cleansing, data scrubbing, ETL and data migration processes
Develop and maintain standards, common processes and best practices for ETL architecture including batch jobs auditing and balancing
Design and implements automation of data loading and cleansing processes
Modify ETL processes/pipelines to accommodate source system changes with new business user requirements
Populate the data warehouse using data modeling techniques for target structures such as Star schemas, Snowflake schemas, and highly normalized data models
Interpret written business requirements and transform into technical specifications
Create and maintain technical specification documentation


 
What You Will Need to be Successful in this Role:



Extensive hands-on experience with SQL query language development
4+ years of experience in an ETL tool such as SSIS, Azure Data Factory, Informatica, DataStage
4+ years of experience in developing data warehouses/data marts
3+ years of experience in developing cloud-based pipelines in Azure Data Factory / AWS Glue
Excellent knowledge of data warehouse concepts, technologies, and best business practices to include data sourcing, data transformation, data loading, data cleansing, data integrity checking, and end-user tools
Hands on experience with at least 1 massive parallel platform Netezza, Teradata, Synapse
Knowledge of data warehousing tools, patterns, and processes
Experience Database design and well versed with SQL Server best practices
Excellent interpersonal, written, and verbal communication skills


 
Our Preferences:



Mainframe DB2 experience
Familiarity with Agile methodology







Employees (and their families) are covered by medical, dental, vision, and basic life insurance. Employees are able to enroll in our company’s 401k plan. Employees also receive annually a bank of paid time off and paid holidays. We aspire to see people for what they bring to our corporate culture by supporting an inclusive work environment, including an emphasis on a healthy work-life balance, development opportunities, and a casual dress code.


American National is an established, stable, and successful multi-line insurance corporation that has provided financial strength and a sense of security to employees, customers and business partners since 1905. With focus on our organization’s values and cultural richness: Financial Strength, Integrity, Respect, Service and Teamwork (FIRST) and Agility, Collaboration, and Engagement (ACE) we continue to pursue our vision to be a leading provider of financial products and services for current and future generations.


Hiring Practices
The preceding job posting was designed to indicate the general nature and level of work performed by employees assigned to this position. It is not intended to be interpreted as a comprehensive list of all duties, responsibilities, and qualifications. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role, but your past experience doesn’t align perfectly with the job qualifications, we still encourage you to apply. You may be just the right candidate for this position or other opportunities at American National.


American National’s recruitment policies help us place individuals in a timely and efficient manner. Only the most qualified candidates will be contacted by our recruiting team.


American National is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, genetic information or any other legally protected categories. American National is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities.



Nearest Major Market: Springfield  Job Segment: Business Intelligence, Data Warehouse, Database, Social Media, SQL, Technology, Marketing"
Data Engineer/Data Warehouse Engineer,Purple Drive Technologies,"Friendswood, TX 77546",,Full-time,https://www.indeed.com/company/Purple-Drive-Technologies/jobs/Data-Warehouse-Engineer-dca757cf33e54eec?fccid=b50885016c495d25&vjs=3,"( Skills needed :
i) Deep expertise in Data Engineering and Data Warehousing (minimum 4+ years)
ii) Azure synapse , Azure Data Factory , Spark Pool , SQL , SQL Pool (minimum 4+ yrs)
iii) CI/CD and Python/Java programming experience (minimum 3+ years)
iv) Ideal to have a 24 x 7 development i.e offshore presence or different time zones )
Job Type: Full-time
Benefits:

Health insurance

Experience level:

10 years
7 years
8 years
9 years

Schedule:

8 hour shift

Ability to commute/relocate:

Friendswood, TX 77546: Reliably commute or planning to relocate before starting work (Required)

Experience:

Informatica: 6 years (Preferred)
SQL: 6 years (Preferred)
Data warehouse: 6 years (Preferred)

Work Location: In person"
Data Engineer (Immediate Opening),IDEA Public Schools,"Houston, TX",,Full-time,https://www.indeed.com/rc/clk?jk=4e94c3bbf3940bbb&fccid=4c58f1f52a144526&vjs=3,"Description 
Role Mission: The Data Engineer will be responsible for improving IDEA's operational processes and supporting critical strategies by assisting in the new development and implementation related to our internal applications systems. The Engineer will deliver the testing, ongoing evaluation, and validation of organizational data structures and identify issues in current processes while providing proven strategies for ongoing database and data warehouse development relating to internal custom applications development and deployment. This position will provide recommendations and insight on IDEA's IT operations and strategy from an applications development standpoint. This job requires the ability and desire to work and communicate well in a dynamic team environment as well as dependability and self-sufficiency.
 What You'll Do - Accountabilities:
 
On-time Product Delivery: Drive to and maintain on-time development and delivery of high-quality features for custom applications and business intelligence tools as defined by monthly sprint plans as measured by: 

% of Critical defects due to SQL code changes and ETL functioning should be limited to a max of 5% 
% of spilled over development tasks should be limited to a max of 5% 
Should acquire the complete ownership of at least 20% of the features developed 
% of reopened defects should be limited to a max of 2% 


Effective Requirements Analysis: New major product work and execution is detailed with full requirements analysis and effective preparation for sprint planning, with detailed task/effort estimates as measured by: 

Difference between estimated effort and actual effort should be limited to a max of 15% and decrease gradually 
Defects due a mis-match in understanding of the requirements should be limited to a max of 10% 


Efficient Object-Oriented Analysis and Design: Thorough object-oriented analysis and design of features with the documentation of necessary design artifacts as measured by: 

Refactoring time to enhance/improve SQL code changes and ETL development should be less than 15% of the original effort. 
At least 20% of the code developed should be reusable 
Reuse of code should be leveraged when possible. Duplication, if any, should be limited to a max of 5%. 


Adherence to Effective Scrum Practices: Adhering to all of the Scrum processes, with active and punctual participation in Scrum meetings as measured by: 

Absenteeism in scrum ceremonies including daily huddles, retrospectives, product reviews, and planning sessions should be limited to a max of 5% with prior intimation 
All planned leaves (both short and long duration) should be intimated in advance and documented so that sprint commitments are not affected. Deviation should be limited to 5%. 
Unplanned leaves (both short and long duration) should be intimated as soon as possible and documented so that sprint commitments are not affected. Deviation should be limited to 5%. 


Continuous Improvement of Domain, Technical, and Behavioral Skills: Continuously enhancing the Product domain knowledge, technical, and behavioral competencies to grow to the next level as measured by: 

Relevant trainings/actions need to be identified, planned and attended 3 times within the year (1 skill from each area - domain, technical, and behavioral) 
Development and demonstration of these skills for the purpose of the facilitation of team training and/or mentoring should be developed for each team member (1 opportunity per year) 


We look for Team and Family who embody the following values and characteristics: 

Believes and is committed to our mission and being an agent of change: that all students are capable of getting to and through college 
Has demonstrated effective outcomes and results, and wants to be held accountable for them 
Has a propensity for action, willing to make mistakes by doing in order to learn and improve quickly 
Works with urgency and purpose to drive student outcomes 
Thrives in an entrepreneurial, high-growth environment; is comfortable with ambiguity and change 
Seeks and responds well to feedback, which is shared often and freely across all levels of the organization 
Works through silos and forges strong cross-departmental relationships in order to achieve outcomes 
We believe in education as a profession and hold ourselves to high level of conduct, professionalism and behaviors as models for our colleagues and students 

Note: At IDEA, the Data Engineer role is a mid to high level role with a focus on building upon the IDEA data warehouse. The IDEA data warehouse is the central data store for all analytics and reporting. As a result, the Engineer is responsible for data extraction, transformation, and loading of data into the data warehouse and is the primary keeper of this system. These processes require strong skills with a variety of specialized tools and techniques for data cleansing, preparation, modeling, and integration. This role is also required to have a strong background in analytics and server-side processing. 

Supervisory Responsibilities:
 This role leads and oversees the work of others in a project capacity as a project technical lead: 

Planning and directing Data Integration/ETL Developer team member activities on projects 
Assigning work 
Overseeing proper maintenance and back-up of source code 
Participation in evaluating performance (for Data Integration/ETL Developers) 
Mediating conflict resolution 

Qualifications:

 Education: Bachelor's degree from four-year college or university in Information Technology, Computer Science, Computer Engineering, and Software Engineering
 Experience: 6+ years related work experience and/or training; or equivalent combination of education and experience. 
Certification/License:
   
 Microsoft Certified Solutions Associate (SQL 2016 BI Development),
 Certified Associate in Project Management (CAPM) preferred


 
What We Offer
 Compensation: 

Salaries for people entering this role typically fall between $66,626 and $80,618, commensurate with relevant experience and qualifications and in alignment with internal equity. This role is also eligible for a performance bonus based on individual and organizational performance and goal attainment.

 
Other Benefits:
 We offer a comprehensive benefits plan, covering the majority of the employee premium for the base medical plan and subsidizing the majority of costs for a spouse/domestic partner and children. Other benefits include dental and vision plans, disability, life insurance, parenting benefits, generous vacation time, com‐muter benefits, referral bonuses, professional development, and a 403(b) plan. We also offer an inclusive environment where staff are encouraged to bring their whole selves to work every day. IDEA may offer a relocation stipend to defray the cost of moving for this role, if applicable.
 

To Apply:
 Please submit your application online through Jobvite. It's in your best interest to apply as soon as possible. It is recommended that you include a cover letter in your application addressing why you are interested in IDEA and how your experience has prepared you for this position."
Data Analysis / Engineer,AC HOME,"Houston, TX 77036 (Sharpstown area)",,,https://www.indeed.com/rc/clk?jk=93352fe04543c11f&fccid=0caa8fd88f711e54&vjs=3,"We are currently seeking an experienced Real Estate Analyst in the Houston area. This position will be integral to our online platform in analyzing and validating data for use by our staff and customers alike. An eye for detail and the ability to meet deadlines and finalize work will be needed for this position. With our fast growth, the potential to be lead in a team of analysis's is in the near future. 
Must be honest, energetic, with a strong work ethic. 
Description

Provide services to end-users in planning, developing and deploying real estate data online
Develop custom data repositories, content indexing and workflow
Configure and administer services, User Profile Services, site metadata, and Excel services
Provide system administration including, but not limited to, analysis, capacity planning, integration and quality assurance
Promote online solutions and facilitate those solutions; identify practices and processes that can be improved
Create reports for use internally as well as for clients with internal and external data

Requirements

Bachelor's degree or at least 4 years of equivalent work experience
3 years of experience 
Solid technical aptitude and leadership
Strong analytical skills
Strong verbal and written communication skills
Experience in the real estate industry a plus

Compensation
Salary based on experience and performance bonuses contingent upon project completion on time and on budget.AC HOME has exciting opportunities waiting for you! 
Please submit your resume to HR@achome.com."
Data Engineer / Data Architect,GTS Geotech,"Remote in Houston, TX 77002",,,https://www.indeed.com/rc/clk?jk=23656d005d2c7155&fccid=4ba35c44ff727b61&vjs=3,"Data Engineer / Data Architect


 Our Data Scout division has been engaged to find a Data Engineer / Data Architect, with strong Oil and Gas Exploration and Production background in Houston, Texas. This is a salaried position, office based, with some scope for remote work.


 To be successful in this data engineer / data architect position, you will have excellent experience of data engineering, data analytics, modelling and validation. You will be required to create data-loading schemes/workflows, responsible for architecture and integration between multiple G&G Applications.


 Core to this role is an understanding of Big Data as it applies to Oil and Gas Exploration and Production, in particular Apache Spark, Hadoop, SCALA etc. You will need to be highly proficient developing/writing complex SQL queries, Python Scripting etc.


 Types of data may include:

Completion
Production & Injection
RealTime Drilling Data
Production Failure and workover
Competitive Intelligence

This is an urgent opportunity, and therefore candidates should already be authorised to live and work in the United States and available to interview immediately, commence work with short notice."
Lead Data Engineer,Eaton Corporation,"Houston, TX",,"$101,250 - $148,500 a year",https://www.indeed.com/rc/clk?jk=f04bf35868378a85&fccid=87f38351bd29de24&vjs=3,"Eaton’s Corporate Sector division is currently seeking a Lead Data Engineer. 
The expected annual salary range for this role is $101250.0 - $148500.0 a year.
 Please note the salary information shown above is a general guideline only. Salaries are based upon candidate skills, experience, and qualifications, as well as market and business considerations.



 What you’ll do:



      At Eaton we are modernizing the way we use data to accelerate our digital transformation. Join our Information Technology team and help positively impact our business through leading technologies, exciting and challenging enterprise projects, and new platforms. We are transforming to a product centric organization utilizing agile practices to help us work more incrementally and fluidly, allowing us to respond more quickly to changing business needs.
      In this role, you will be instrumental in implementing the enterprise data strategy for the data mesh architecture as part of the Chief Data Management office. You will be the subject matter expert on integration platforms that support movement of data across the enterprise, commercial and IoT sources and drive automation of both platform and integration governance. You will lead research into exploring and enabling the right toolset for the Hybrid integration platform and enabling democratized agile integration across the organization. You will also enable the team to rapidly experiment and iterate on strategies, helping drive critical decisions on how we shape the product and services provided by integration services.
      Making what matters work at Eaton takes the passion of every employee around the world. We create an environment where creativity, invention and discovery become reality, each and every day. It’s where bold, bright professionals like you can reach your full potential—and where you can help us reach ours.""
     

Create robust and automated data pipelines using traditional and modern data integration technologies, including ETL/ELT, data replication/CDC, streaming, message-oriented data movement and API-based data acquisition leveraging cloud native tool-set.
Implement orchestration of data pipelines to support migration of on-premise data platforms to cloud
Define and implement data integration patterns and solutions using standard modeling practices
Design, implement and maintain platform solutions that are reliable and scalable and focused on driving automation and improving productivity
Drive development and adoption of self-service capabilities and champion as an enabler for adopters of the platform. Assist with operationalizing citizen developer personas
Create templates to improve productivity, define standards to enforce consistency and governance. Implement dataops.
Ensure availability and stability of integration platforms and provide operational support for releases and maintenance. Adhere to operational SLAs and KPIs.
Establish end to end continuous integration and deployment and guide the team on best practices
Simplify the tooling landscape to sunset legacy applications while minimizing business disruption.






 Qualifications:


 Basic Qualifications:

Bachelor's degree in STEM from accredited university
6+ years of data engineering experience focusing on modern data management practices and contemporary toolsets
No relocation is offered for this position. All candidates must currently reside within 50 miles of an Eaton Facility to be considered. 
Must be authorized to work in the United States without company sponsorship now or in the future
This position requires use of information or access to hardware which is subject to the International Traffic in Arms Regulations (ITAR). All applicants must be U.S. persons within the meaning of ITAR. ITAR defines a U.S. person as a U.S. Citizen, U.S. Permanent Resident (i.e. 'Green Card Holder'), Political Asylee, or Refugee.


 Preferred Qualifications:

Experience in creating data pipelines using traditional and modern data integration technologies, including ETL/ELT, data replication/CDC, streaming, message-oriented data movement and API-based data acquisition leveraging cloud native tool-set.





 Skills:



Demonstrated experience with data replication/CDC tools such as HVR/FiveTran, Qlik Replicate, Golden Gate etc
Experience with cloud integration tools such as Azure Data Factory, Informatica Data Management Cloud, Amazon Glue
Demonstrated experience in implementing data pipelines using dbt Cloud/CLI, Airflow or similar workflow orchestration tools
Strong experience working with integrating large heterogeneous datasets using modern cloud integration technologies such as Azure
Strong proficiency with SQL, and using Python for data transformation.
Moderate experience working with open-source or commercial message queuing technologies, such as Azure Service Bus, Apache Nifi, Apache Kafka, etc.
Strong understanding of cloud-based data solutions such as Azure BLOB or ADLS and Synapse, AWS S3, EMR and Redshift, Databricks, Snowflake, etc. ""
Ability to lead as the subject matter expertise in the space through diagnosing, isolating, and resolving complex issues and recommending and implementing strategies to resolve problems
Ability to adapt to the situation and pivot based on changing priorities
Curious and solution oriented, ability to handle problems, work outside the comfort zone
Collaborate with the team and be open minded to ideas
Ability to identify operational issues and proactively solutions to resolve problems.
Experience acheiving platform KPIs and defining measurement targets
Ability to drive application modernization and enablement
Experience in independently driving high-level technical delivery.
Experience influencing leadership and key stakeholders on technology solutions.
Experience applying knowledge of the new processes and concepts in day to day work deliveries
Experience establishing & maintaining relationships with individuals at senior levels




 We are committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law.
 Eaton considers qualified applicants regardless of criminal histories, consistent with local laws. To request a disability-related reasonable accommodation to assist you in your job search, application or interview process, please call us at 1-800-836-6345 to discuss your specific need. Only accommodation requests will be accepted by this phone number.
 We know that good benefit programs are important to employees and their families. Eaton provides various Health and Welfare benefits as well as Retirement benefits, and several programs that provide for paid and unpaid time away from work. Click here for more detail: Eaton Benefits Overview. Please note that specific programs and options available to an employee may depend on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements."
Lead Data Engineer,NRG,"Houston, TX 77002 (Downtown area)",,"$99,000 - $144,000 a year",https://www.indeed.com/rc/clk?jk=4c35da77abf5b4ba&fccid=ba62ec521e3e5609&vjs=3,"At NRG, we’re bringing the power of energy to people and organizations by putting customers at the center of everything we do. We generate electricity and provide energy solutions and natural gas to millions of customers through our diverse portfolio of retail brands. A Fortune 500 company, operating in the United States and Canada, NRG delivers innovative solutions while advocating for competitive energy markets and customer choice, working towards a sustainable energy future. More information is available at www.nrg.com. Connect with NRG on Facebook, LinkedIn and follow us on Twitter @nrgenergy.
 Responsibilities

 Lead Analytics Data Manage team and oversee team’s day-to-day operations
 Drive technical solution design and system processes development
 Coordinate with business leaders and users to understand business requirements and implications 
Identify, escalate and manage production risks and issues to resolution
 Empower capability growth of direct reports and provide coaching and counseling as needed
 Motivate and inspire team for maximum performance
 Be part of a leading innovative, customer-centric and data-driven energy company

 Skills and Experience Required

 7+ years of data application design experience to drive end-to-end architecture and solution designs
 5+ years of experience in production support for mission-critical enterprise application
 5+ years hands-on experience with PL/SQL, database and data warehouse development
 5+ years of experience in data application design patterns, i.e., event-driven or layered service
 3+ years of solid experience in Python and Spark
 3+ years of hands-on experience with Amazon Web Services (AWS)
 2+ years of hands-on experience in Big Data or Apache Spark data platform, such as Databricks.
 Enterprise-level job experience, focusing on high volume, scalability, and reusability when architecting technical solutions
 Exceptional communication and interpersonal skills with an ability to extract, translate and communicate meaningful information at the executive, management, and peer levels
 Strong technical documentation skills, including workflows, architectural diagrams, and support documentation
 2+ years’ experience as a manager or team lead - leading, managing and delivering complex technology deliveries with resources in multiple locations
 Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects
 Bachelor's Degree or equivalent professional experience

 Preferred

 Experience with Data Governance Tool, for example, Collibra
 Experience with unstructured data
 Programming experience with Unix/Shell scripting
 Experience with Amazon Lambda, Athena and Redshift
 Hands-on experience with Orchestration tools like Airflow or Step Function
 An advanced degree in the area of specialization is preferred
 Experience with Agile/Scrum methodologies
 Energy / Utility industry experience


 Why NRG is a great place to work:

 Great company culture!! Voted as a BEST employer by Forbes
 A competitive total compensation package, including annual incentive and/or commission
 Stock Purchase Plan
 Benefits on the first day of employment - Medical, Dental, Vision, Life Insurance, and Short Term Disability, Wellness program, etc.
 Company-paid life insurance and disability insurance
 401 (k) plan to help save for retirement
 Generous PTO plan, plus 8 company holidays, and 3 floating holidays
 Numerous discounts, including electricity discounts on NRG brands

 The salary range for this role is $99,000 - $144,000. Pay is based on several factors, including but not limited to education, work experience, certifications, etc.

 NRG Energy is committed to a drug and alcohol free workplace. To the extent permitted by law and any applicable collective bargaining agreement, employees are subject to periodic random drug testing, and post-accident and reasonable suspicion drug and alcohol testing. EOE AA M/F/Protected Veteran Status/Disability
 EEO is the Law Poster (The poster can be found at http://www.eeoc.gov/employers/upload/poster_screen_reader_optimized.pdf)
 Level, Title and/or Salary may be adjusted based on the applicant's experience or skills.
 Official description on file with Talent."
Sr Data Engineer (On-site),Shellpoint Mortgage Servicing,"Houston, TX",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=8a7f91ce99254912&fccid=ee2d6fb81ddfc752&vjs=3,"Who we are
 

   Shellpoint Mortgage Servicing (SMS) is one of America’s top-five non-bank mortgage-servicing companies. What is mortgage servicing? Our clients are businesses that own mortgage loans (such as banks and real estate investment firms). On their behalf, we manage (or “service”) their loan portfolios, which means that we collect homeowners’ mortgage payments, pay their tax and insurance bills, and help homeowners in default to get current.
 



 Primary Function/Summary
  



    We are on a mission to evolve how we use data at Shellpoint to grow our business and fulfill the needs of our customers. We are modernizing our data and integration platform to be best in class. In this role you will be responsible for implementing modern architecture and engineering design patterns in a range of technologies, considering both technical and economic perspectives. You will partner with technical and business stakeholders to implement solutions balancing current and legacy technical standards, while keeping an eye towards scalability and resilience. We are looking for someone who can design, code, and execute in both cloud and on prem environments – while evangelizing the opportunities of good engineering design, modern integration architectures and data as a service.
  




    Direct Reports
  


 N/A




    Principal Duties
  


 Serve as a key contributor to identify, evaluate, and execute the development and implementation of data infrastructure.
 Deliver collaborative products that align with organization and decision strategies.
 Consult with technology and business staff to understand business need and provide thought leadership on solutions during requirements gathering sessions.
 Serve as key contributor in the development and maintenance of the data warehouse.
 Support critical strategic initiatives and architect moderately complex data engineering projects.
 Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to curated data sets to data analysts and data scientists.
 Develop, communicate, and present solution architectures to both technology and business stakeholders.
 Develop highly complex SQL queries to extract data for analysis and model construction.
 Design, build, and maintain internal and external data integrations.
 Build robust data pipelines, optimizing workloads across on prem and cloud environments.
 Test and validate data pipelines, transformations, datasets, reports, and dashboards built by team.
 Document and test data processes including performance of through data validation and verification.
 Contribute to delivery of multiple large, complex data engineering projects simultaneously.
 Collaborate with technology management to define standards and best practices for team.
 Mentor and assist other data engineers, data analytics and data scientists.
 Provide support to other data engineering, data analytics, application development, data systems and production support teams.
 Work on other projects as assigned.
 Performs related duties as assigned by supervisor.




    Core Development Stack
  


 Languages: SQL (standard and DB-specific)
 Tools/Products: Microsoft SQL Server, Snowflake, SSIS (SQL Server Integration Services), HVR/Fivetran, Snaplogic, SSRS (SQL Server Reporting Services), RedGate Developer Toolkit, Tableau, PowerBI
 Frameworks: Amazon Web Services (AWS) & Microsoft Azure cloud services
 Other: Azure DevOps, Smartsheet, Microsoft Visio, TFS (Team Foundation Server), Octopai




    Education and Experience Requirements
  


 College or university degree in the field of Information Technology, Data Science, Computer Science, MIS, or another STEM-related field required. Significant experience in a similar role or industry will be considered as a replacement.
 5-7 years engineering/development experience
 Expertise in SQL Server 2017 or higher
 Expertise with data and analytics technologies such as RDBMS, ETL and BI
 Experience with SQL Server Integration Services (SSIS)
 Experience with SQL Server Reporting Services (SSRS)
 Experience with Microsoft Visual Studio 2017 or higher
 Experience with on prem and cloud solution design and engineering
 Experience with Snowflake, Azure, AWS, or other cloud technologies


   Experience with agile delivery methodologies
 



    Knowledge, Skill, and Ability Requirements
  


 Cloud-based solution design and engineering
 Experience with tools such as HVR/Fivetran and Snaplogic are a plus
 Azure data and analytics deployments
 Experience in solution design spanning multiple frameworks
 Experience in other languages such as Python, R, Spark SQL, Java, etc. are a plus
 Experience with Azure DevOps, TFS
 Familiarity with API-first architectures
 Real time streaming data delivery
 DevOps and CI/CD experience
 Mortgage servicing, mortgage lending and/or finance experience



 While this description is intended to be an accurate reflection of the position’s requirements, it in no way implies/states that these are the only job 
responsibilities.
 Management reserves the right to modify, add or remove duties and request other duties, as necessary.



   Company Perks:
  

15 Paid Time Off (PTO) days and 18 after 1st anniversary!
9 Paid Holidays
Employee Engagement Activities



 Company Benefits:
  

Medical (including Health Savings Account & Flexible Savings Account)
Dental - RX – Vision – Life, Disability Insurance – 401(k) Plan with company match! – Employee Assistance Plan



 Performance-based Incentives
Pet Insurance
Advancement Opportunities



   Newrez NOW:
 

Our Corporate Social Responsibility program, Newrez NOW, empowers employees to become leaders in their communities through a robust program that includes volunteering, philanthropy, nonprofit grants, and more
1 Volunteer Time Off (VTO) day, company-paid volunteer day where all eligible employees may participate in a volunteer event with a nonprofit of their choice
Employee Matching Gifts Program: We will match monetary employee donations to eligible non-profit organizations, dollar-for-dollar, up to $1,000 per employee
Newrez Grants Program: Newrez hosts a giving portal where we provide employees an abundance of resources to search for an opportunity to donate their time or monetary contributions


 Equal Employment Opportunity
   We're proud to be an equal opportunity employer- and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better."
Data Platform Engineer,LyondellBasell Industries,"Hybrid remote in Houston, TX 77010",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=7a9528566d45114f&fccid=5938580c9c7de4d3&vjs=3,"Location: Houston, TX, US, 77010 
    







     Req ID: 82614 
    







     Facility: One Houston Center-130 
    







     Department: Data Platform 
    







     Division: Innovation 
    








LyondellBasell



 Basic Function


 LyondellBasell has fully committed to achieving its vision as “The Chemical Company of the Future” and an industry leader in the areas of Sustainability and Customer Experience. The Digital Enterprise that will act as the foundation for enabling this vision will be built upon three pillars: A modern and extensible technology architecture, an ERP backbone that supports new business models, and a team of talented technologists that are empowered to build innovative solutions and digital products.


At the intersection of these pillars, the Data & Analytics Center of Excellence is building the data foundation and a catalog of data products, analytical applications, and enterprise services that give users across our company the tools, data, and guidance to generate insights.


The Data Platform Engineer is part of the team responsible for providing and supporting a modern, scalable and secure data platform for business intelligence, data science and analytics at scale.




 Roles & Responsibilities



Deployment, configuration, support and maintenance of cloud resources on the data platform to support data and analytics at scale and the delivery of data products and services.
Ensure availability, performance and scalability of the data platform.
Help drive automation of platform and self-service for data consumers.
Work with multiple teams both inside and outside the Data & Analytics CoE, such as the Data Engineers, Product teams, Enterprise Architecture team, Cyber Security etc. in implementing end-to-end solutions on the data platform.
Work with Cyber Security team to ensure data platform adheres to security standards.
Implement recommendations for performance, cost, compliance, security etc.
Contribute to the evaluation of new technologies, vendor products and services.
Implement data protection options, including HA and DR protection in Azure.
Configure monitoring and alerting for both availability and performance of the data platform.
Provide input to report on metrics associated with the performance and availability of data platform services and products.
Contribute to continuous improvements, practices, and operational efficiencies within the team.





Min. Qualifications



Bachelor’s degree in Computer Science, Information Systems, Engineering or equivalent experience in a relevant field
10+ years of relevant work experience in the IT industry
3+ years of experience designing, deploying and configuring Azure services.
3+ years of experience supporting cloud environments including IaaS and PaaS
3+ years of experience working with operating systems like UNIX, Linux and Windows server.
Hands on experience using the Azure administration portal and Azure CLI
Proficiency with PowerShell, Python or other scripting languages
Experience in writing SQL queries and Stored Procedures
Knowledge of the Microsoft Enterprise software products and services
Understanding of data flows, data architecture, ETL and processing of structured and unstructured data
Familiarity with database methodologies and various relational and NoSQL database technologies
Experience in resolving issues with Azure resources.
Knowledge of DevOps and Agile concepts & development principles including continuous integration & continuous delivery (CI/CD).
Ability to troubleshoot problems in a diverse and challenging environment





Preferred Qualifications



Microsoft Azure Cloud Platform certification - Administrator or Architect level
Hands on experience deploying and managing Microsoft Azure PaaS services, such as but not limited to Azure SQL, Azure Synapse, Azure Data Lake Store, Azure Data Factory and Azure Kubernetes Service (AKS)
Experience of Reporting and Analytics tools such as Power BI and Tableau
Experience with global enterprise environment or major consulting firm.
Familiarity with Agile and/or Scrum methods of delivery
Knowledge of enterprise ETL tools like Azure Data Factory, SSIS, Informatica or similar.
Experience with CI/CD tools (Git, Azure DevOps, Jenkins, TFS, Maven, Nexus…)
Data Management, Data Integration or Data Engineering experience.
Knowledge of at least one other cloud hosting solution in addition to Azure (e.g., Google, AWS)
Business Continuity or Disaster Recovery planning experience
Understanding of networking concepts (SSL configurations, vnets, nsg, subnets…)

#LI-SS1
#LI-Hybrid




 Competencies



         Builds effective teams
        

          Collaborates
        

          Cultivates innovation
        

          Customer focus
        

          Demonstrates courage
        

          Drives results
        

          Ensures accountability
        

          Instills trust and exemplifies integrity
        





We are LyondellBasell – a leader in the global chemical industry creating solutions for everyday sustainable living. Through advanced technology and focused investments, we are enabling a circular and low carbon economy. Across all we do, we aim to unlock value for our customers, investors and society. As one of the world’s largest producers of polymers and a leader in polyolefin technologies, we develop, manufacture and market high-quality and innovative products for applications ranging from sustainable transportation and food safety to clean water and quality healthcare. For more information, please visit www.lyondellbasell.com or follow @LyondellBasell on LinkedIn.


Must be at least 18 years of age and must be legally authorized to work in the United States (US) on a permanent basis without visa sponsorship.


LyondellBasell does not accept or retain unsolicited résumés or phone calls and/or respond to them or to any third party representing job seekers.


LyondellBasell is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, veteran status, and other protected characteristics. The US EEO is the Law poster is available here."
Data Engineer Senior Consultant (Clearance Required),Deloitte,"Houston, TX",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=544a9838fb67c0c7&fccid=9e215d88a6b33622&vjs=3,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.
 

Work you'll do

 The Data Engineer will design future-state, modern data architecture for transformation at the enterprise level using advanced architectural principles. Using tools such as Snowflake and/or Databricks, they will also work with cutting-edge DevOps technologies, develop advanced analytics products, and apply data and statistical programming tools to enterprise data to advance and enable key mission outcomes within environments (GCP, AWS, Azure).
 

The team 

 Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.
 
 The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.
 
 Qualifications
 
 Required:
 


Minimum Active Top Secret Level Security Clearance



5+ years of professional experience in data engineering (SQL).



5+ years of experience designing and developing real time ETL architecture for real time predictive analytics.



5+ years of experience with Databricks, Snowflake, or AWS



Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field

 Preferred:
 


3+ years of relevant consulting or industry experience



Creativity and innovation - desire to learn and apply new technologies, products, and libraries



Prior professional services or federal consulting experience

 How you'll grow
 
 At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
 
 The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,000 to $181,000
 
 #LI-JRK"
Big Data Integration Engineer,KBR,"Remote in Houston, TX 77002",Posted 20 days ago,Full-time,https://www.indeed.com/rc/clk?jk=2dfbf0c5302913ff&fccid=cbfa56f19cc95796&vjs=3,"Title: Big Data Integration Engineer
 
 ABOUT THIS POSITION
 The successful candidate will be part of the KBR team supporting the Test Resource Management Center’s (TRMC) Big Data (BD) and Knowledge Management (KM) Team deploying BD and KM systems for DoD testing Ranges and various acquisition programs.

 This is being hired nationwide as it is a remote work capable position. The candidate can either work in one of KBR’s facilities or work from home, assuming the candidate has a stable internet connection.

 Responsibilities: 

Deployment and integration of a highly visible data analytic project called Cloud Hybrid Edge-to-Enterprise Evaluation Test & Analysis Suite (CHEETAS) at multiple DoD ranges and labs
 Work with the data science and software engineering team members to support our customers by demonstrating the ‘art of the possible’ with insights gained from analyzing DoD Test & Evaluation data
 Deploy and configure Big Data and Knowledge Management tools in an enterprise environment
 Configure and troubleshoot a variety of Big Data ecosystem tools
 Work with a wide range of stakeholders and functional teams at various levels of experience
 Become a CHEETAS deployment subject matter expert
 Act as a critical part of our technical team responsible for deploying CHEETAS within customer environments
 Work closely with system administrators and software developers to communicate, document and ultimately resolve deployment issues as they arise
 Provide deployment services to various DoD testing Ranges and acquisition programs
 Deploy CHEETAS within disparate environments (on different non-standard hardware stacks and integrated into different existing ecosystems) sometimes located within DoD vaults with no outside internet connectivity
 Act as the frontline interface that customers will have when first experiencing CHEETAS within their DoD Range and lab environments


 This requisition will be used to hire multiple individuals 
Entry level Integration Engineers will NOT be considered due to the breadth of knowledge necessary to be successful in the position. This position is anticipated to require travel of 25% with surges possible up to 50% to support end users located at various DoD Ranges and Labs across the United States. 

Come join the KBR BDKM team and be a part of the award-winning team responsible for revolutionizing how data analysis is performed across the entire Department of Defense!

 BASIC QUALIFICATIONS

 This position requires a bachelor's degree in a STEM Computer Science, Data Science, Statistics or related, technical field, and 7-10 years of experience. Entry level Integration Engineers will NOT be considered.
 Previous experience must include five (5) years of hands-on experience in big data environments.
 Previous experience must include three (3) years of hands-on experience with Kubernetes. Experience in the integration with and configuration of: Hadoop, SQL Server Big Data Cluster, Kubernetes, CentOS, Ubuntu, RedHat, Windows Server, VMWare, etc.)
 Active or Current Secret Clearance required - Top Secret Clearance preferred.


 Knowledge / Skills / Abilities:

 Experience with installation, configuration, integration with and usage of the following tools and technologies: Helms Charts, YAML, Kubernetes, Kubectl, Kubernetes IDE, NFS, SMB, S3, SQL Server, Windows Server, Windows 10/11, Linux (CentOS, Ubuntu, RedHat), Hadoop.
 Must be prepared to learn new business processes or CHEETAS application nuances every Agile sprint release (roughly every 6 weeks) prior to deploying to customer sites.
 Experience with working in distributed team environment is preferred.
 Ability to problem solve, debug, and troubleshoot while under pressure and time constraints is required.
 Ability to communicate effectively about technical topics to both experts and non-experts at both the management and technical level is required.
 Excellent interpersonal skills, oral and written communication skills, and strong personal motivation are necessary to succeed within this position.
 Ability to work independently and provide appropriate recommendations for optimal design, analysis, and development.
 Excellent written and verbal communications skills are required, as the Integration Engineer will be in frequent contact with the project technical lead, be taking direction from various government leads, and will frequently be interacting with end users to gather requirements and implement solutions while away from other team members.
 Ability to teach and mentor engineers with a variety of skill levels and backgrounds is a plus.
 Excellent testing, debugging and problem-solving skills are required to be successful in this position.
 Experience designing, building, integrating with and maintaining both new and existing big data systems and solutions.

 ADDITIONAL QUALIFICATIONS

 The preferred candidate will have experience working in government/defense labs and their computing restrictions.
 Knowledge of the Test and Training Enabling Architecture (TENA), the Joint Mission Environment Testing Capability (JMETC), and Distributed Testing and Training is a plus.
 Experience working with major DoD Acquisition programs such as Joint Strike Fighter (JSF) or Missile Defense Agency (MDA) is a plus.
 Knowledge of DoD Cybersecurity policies is a plus.


 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law."
Senior SAP Data Engineer,The Friedkin Group,"Houston, TX 77077 (West Oaks area)",Posted 15 days ago,Full-time,https://www.indeed.com/rc/clk?jk=b6ebfb8610f01325&fccid=9b2ecf99472139e7&vjs=3,"External Description: 
 
 LIVING OUR VALUES 


  All associates are guided by Our Values. Our Values are the unifying foundation of our companies. We strive to ensure that every decision we make and every action we take demonstrates Our Values. We believe that putting Our Values into practice creates lasting benefits for all of our associates, shareholders, and the communities in which we live.
 


 JOB SUMMARY


   The Sr. SAP Data Engineer is a member of the Data Science and Analytics Team who is responsible for the execution of GST’s Reporting & Analytics strategy. This Sr. SAP Data Engineer is involved in all phases of the analytic projects, from requirements gathering, data architecture, integration guidance, and development and support artifacts. 
 
This Sr. SAP Data Engineer will support SAP BW/HANA design and development efforts. The ideal candidate has the ability to mentor and coach internal and external resources in maintainable development practices and code reviews. This person will demonstrate an ability to manage complex, high-quantity and potentially contradictory information to effectively solve problems, applies knowledge of the business to advance organizational goals, and intuitively navigates complex policy, people and process-related organizational dynamics.


 ESSENTIAL FUNCTIONS


 Collaborate with Business and IT Functional experts to understand business requirements or issues, perform gap analysis in the SAP BW/4 HANA environment and recommend/implement process and/or technology improvements to optimize current reporting environment. 
Hands-on expertise in data architecture, modeling, integration, quality, security and BI/Analytics capabilities with BW/4HANA development objects and integrations end-to-end.
 Gather requirements and create Functional Design/Technical Design specifications.
 Project life-cycle leadership and support for Design, Development, System integration/UAT cycles and Prod Cutover, Post-Go live support, and Environment strategy.
 SAP Functional knowledge of Sales and Distribution, Procurement, Materials Management, Production Planning, and Finance AP/AR/GL and SAP VMS (helpful) for Analytics
 Strong experience in HANA studio and HANA Development.
 Responsible for performance tuning of BW/4HANA utilizing best practices, in collaboration with other IT teams.
 BW/4HANA object development expertise, BW ABAP Coding/Routines, BW Web Cockpit/Monitoring, Process Chains, Content installs, Data Tiering Optimization, Transports and issues analysis/resolution, SAP support messages
 BW Support Pack upgrades/Post install Steps, OSS note analysis/application.
 S/4HANA Embedded Analytics, CDS View Development, Extractor development/ODP
 SAP Data Services knowledge, SAP & Non-SAP Systems integration with BW.
 Execution of POCs for analytic tools.
 Leads and executes incidents resolution, the delivery of minor/monthly and major SAP BI/BW enhancement release cycles, and small projects.
 Facilitates release scoping, design, build, test, change control, documentation and deployment activities with internal and external project and operations teams, business stakeholders, shared services and compliance teams.
 Executes business user communication regarding release scope and deployment timelines.
 Ensures appropriate risk resolution and mitigation for SAP BI/BW platforms as issues are identified.
 Ensures no disruption to business operations upon deployment of SAP BI/BW releases to production systems.
 Must have deep technical expertise in multiple SAP BI suite of products, especially BW, HANA, BOBJ, BODS, SAC.
 Actively researches and develops new knowledge and collaborates on solutions.
 Develops, designs and implements integrated solutions to resolve highly complex technical and business issues.
 Excellent ability to multi-task assigned duties or projects.
 Effectively communicates complex ideas in a clear and concise manner both verbally and in writing.
 Works with minimal supervision and self-driven
 Highly organized; able to organize and assimilate large quantities of complex information.
 Responsibly receive, transmit, and handle consumer and customer data per applicable policies and procedures.
 Review and follow data privacy practices, policies, and guidelines. 
Other duties as assigned.


 SUPERVISORY RESPONSIBILITIES

   This position has no supervisory responsibilities
 


 QUALIFICATIONS 

Requires bachelors’ degree from a four-year college or university with 8 years of in-depth hands-on experience in SAP BI/BW/HANA platform; or possesses an equivalent combination of education and/or experience. 

At least 4 years of experience in SAP BW/4HANA or BW on HANA, 4 years in SAP BW/BI versions including ETL and reporting tools, and 2 years in native HANA modeling.
 Full SAP BI lifecycle Experience (Data Modeling to Reporting) with at least 3 end-to-end implementation projects as Sr. SAP BW/HANA developer.



 Technical Experience


 Hands-on experience working with BW/4 HANA features, standard and custom SAP BW Extractors, complex transformations, advanced DSOs, composite providers, Data Tiering Optimization, exposing BW models as HANA views, mixed (hybrid) scenarios, HANA Analysis process in BW and LSA ++ best practice, data quality, security and performance optimization concepts.
 Advanced knowledge and Hands-on of SAP BW/4HANA & S/4HANA tools for data analytics, visualizations, reporting etc..
 Advanced knowledge and Hands-on of Data Modeling in SAP Analytics. Ability to assimilate requirements into conceptual/logical data models across information management solutions (relational, Dimensional/Columnar, document) 
Hands-on Experience in BW/4 HANA, S/4, with SAP HANA 2.0 data modelling, and reporting/visualization.
 Hands on experience in BW/4HANA, creating Advanced DSO(ADSO), Open DSO Views, Calculation views, Composite Providers and SAP query.
 Advanced knowledge and extensive experience in Data integration (Point to Point, ETL etc)
 Strong knowledge of Agile Methodologies
 Advanced knowledge of best practices and standards for BI development
 Hands-on experience in cloud data platforms such as SAP DWC/Datasphere, AWS and Databricks is strongly preferred



 Technical Stack


 SAP BW/4HANA 2, HANA 2.0
 S/4HANA 1909
 SAP Datasphere (DWC, DI)
 SAP Fiori 2.0
 BW Query on S4
 BI Platform - Tableau
 Data Virtualization - Denodo
 Data Integration (SAP Data Services, Dell Boomi)
 SQL (Ansi, PLSQL, Analytics)
 Data Modeling (BW, HANA, ABAP CDS)
 Cloud Experience with PaaS, DBaaS
 Team Performance management Tools (TFS, JIRA)



 Soft Skills


 Strong analytical, conceptual, and problem-solving abilities
 Manages complexity in order to effectively find solutions and solves problems
 Drives results by consistently achieving completion and closure of tasks, even the face of obstacles and setbacks
 Adaptive personality and ability to function in a fast-paced environment
 A problem solving attitude that can adapt to varying timelines
 A strong attention to detail combined with the ability to prioritize tasks
 Strong interpersonal skills; promoting healthy relationships and team dynamics
 Strong capability to plan and align work with regards to sense of urgency and priority
 Strong capability to provide Business Insight
 Strong ability to influence organization stakeholders



 To perform this job successfully, an individual must be able to perform each essential function satisfactorily. The requirements listed above are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made, to enable qualified individuals with disabilities to perform the essential functions.
 


 CERTIFICATES, LICENSES, REGISTRATIONS*


   Certifications specific to SAP BI/BW/HANA are a strong advantage.
 

   Valid Driver’s License Required.
 


 PHYSICAL REQUIREMENTS


   The physical requirements described here are representative of those that must be met by an associate to successfully perform the essential functions of the job. While performing the duties of the job, the associate is required on a daily basis to analyze and interpret data, communicate, and remain in a stationary position for a significant amount of the work day; and frequently access, input, and retrieve information from the computer and other office productivity devices. The associate is regularly required to move about the office and around the corporate campus. The associate is occasionally required to travel to other sites, including out-of-state, where applicable, for business. The associate must frequently move up to 10 pounds and occasionally move up to 25 pounds.
 

 


WORK ENVIRONMENT


   The work environment characteristics described here are representative of those an associate encounters while performing the essential functions of this job. While the job is generally performed in an office environment, the associate is occasionally exposed to wet and/or humid conditions, areas in which moving mechanical parts, fumes, toxic or caustic chemicals are present, and outside weather conditions. The noise level in the office environment is typically quiet, but the associate may be occasionally exposed to loud noise levels.
 




TRAVEL REQUIRED


   Minimal travel is required for this position (up to 20% of the time and on a domestic basis).
 

 


  The Friedkin Group and its affiliates are equal opportunity employers and maintain drug-free workplaces by conducting pre-employment drug testing.
  Total Rewards: 
 
 TOTAL REWARDS


   Our Total Rewards package is an integral part of how we recognize our associates’ contributions as well as attract, retain and reward the most qualified employees. We are committed to providing a fair and competitive compensation structure that includes base pay and performance based rewards, where applicable. Compensation is based on various factors including, but not limited to, skill set, experience, qualifications and job-related requirements. Our benefits include medical, dental, and vision along with wellness programs, retirement plans, paid leave and much more! To learn more about these programs and many more, take a tour of our Benefits Page at https://www.friedkin.com/benefits."
Data Center Edge Infrastructure Engineer I - Platform Delivery,Crown Castle USA Inc.,"Hybrid remote in Houston, TX 77024",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=a9907abcf2fd8fb7&fccid=b370e17ef47bfd7b&vjs=3,"Position Title: Edge Infrastructure Engineer – Platform Delivery I (P3)


 Company Summary:
 Crown Castle is the nation’s largest provider of shared communications infrastructure: towers, small cells and fiber. It all works together to meet unprecedented demand—connecting people and communities and transforming the way we do business. Whenever you make a call, track a workout or stream music and videos, we’re the ones providing the communications infrastructure that makes it all possible. From 5G and the internet of things to drones, autonomous vehicles and AR/VR, we enable the technologies that help people stay safe, connected and ready for the future. Crown Castle is publicly traded on the S&P 500, and one of the largest Real Estate Investment Trusts in the US, with an enterprise value of ~$70B.
 We offer a total benefits package and professional growth development for teammates in any stage of their career. Along with caring for our teammates, we’re an active member in the communities where we live, work and do business. We have a responsibility to give back, which we do through our Connected by Good program. Giving back allows us to improve public spaces where people connect, promote public safety and advance access to education and technology.


 Role:
 Crown Castle is looking for motivated employees to help our team grow. As a member of the Edge Infrastructure Platform Delivery Team, you will be responsible for scaling services as we continue expanding into new markets and technologies that require more advanced solutions from Crown Castle’s Data Centers. You will be responsible for ensuring Crown Castle’s Edge Data Center Facilities are operating at optimal performance, 24/7. You will monitor and add capacity as needed in mission-critical locations to proactively manage infrastructure utilization and recommended upgrades. This includes planning, engineering, and deployment of HVAC systems, generators, UPS systems, power distribution networks, DC power plants, fire suppression, and general building construction. You will connect all new infrastructure to Crown Castles BMS/EMS systems for remote connectivity and management. The Edge Infrastructure Engineer must be able to work well in cooperative efforts but also be driven and take initiative on tasks that require independent work.


 Responsibilities

Identify necessary facilities upgrades, capacity requirements, and create budgetary requirements
Manage capital projects to meet deadlines and adhere to the allocated budget 
Schedule and coordinate preventative and demand maintenance activities 
Datacenter design and vendor management



 Expectations

Collaborative work done in a way that balances educated decision-making with measured speed of implementation.
 Ability to continuously prioritize long-term plans with short-term urgent response needs.
Ability to influence conversations and work through building relationships, thoughtful framing of issues, and building influence through excellent work.
 Strong written and verbal communication skills with an ability to present complex information in a clear and simple format.
Travel throughout Crown Castle footprint and on-call rotation 


Education/Certifications

Associates degree or equivalent work experience
3+ years experience in data center edge infrastructure



 Experience/Minimum Requirements

Ability to troubleshoot critical infrastructure (generators, UPS Systems, HVAC, AC/DC) 
Knowledge of BMS (Building Management Systems) and alarming platforms 
Experience with reading and creating standard drawing types – floor plans, electrical one-line diagrams, face equipment drawings 
Familiar with budget creation and solution costing 
Familiarity with data center industry best practices



 Organizational Relationship
 Reports to: Sr. Manager, Edge Infrastructure Engineering Platform Delivery


 Title(s) of direct reports (if applicable):


 Working Conditions: This role falls into our hybrid work model working in your assigned office approximately 60% of the time (3 days per week) and where you do your best work 40% (2 days per week). Beginning September 5, 2023 our hybrid work model will be adjusted to 4 days in the office on Monday through Thursday. On Fridays, teammates on the hybrid schedule will have the option to work from the office or home.


 Additional Information: N/A


 #LI - Hybrid
 #LI-MP1

 Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
 The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Center Applications Engineer,Toshiba International Corporation,"Houston, TX 77041",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=318603b59cf98eda&fccid=9946966e3bd480f8&vjs=3,"Toshiba International Corporation is a world leader in the design and manufacture of motors, motor controls and power electronics products. Many of these products are designed, built and tested in our 1,000,000 square foot state-of-the-art manufacturing facility in Houston, TX. We have developed a totally integrated manufacturing process from research and development, design, engineering, production and manufacturing to after-market service and sales & marketing. Toshiba differentiates itself from its competitors through its commitment to quality and reliability. We build products to perform in the most difficult conditions. From raw material to the finished product, we assure exacting quality, engineering excellence and stringent testing to meet domestic and international performance standards. 


Job Summary:
 The Data Center Application Engineer uses technical knowledge along with interpersonal skills to understand Data Center customer's issues and propose solutions. Data Center Engineer may participate in all facets of the business cycle including; inputs on new product designs, review of Data Center one lines and applications, quoting, forecasting, preparing technical literature, presenting product features and benefits, solving technical issues. 


Responsibilities:
 Assist Product Managers and the UPS sales department with Data Center product support including technical presentations, proper application of our products, review of customer engineering specifications, preparation of quotations, and obtaining answers to questions at all stages of negotiation, production, and after shipment activities. 
Possesses extensive knowledge of the Data Center product lines, industry standards (i.e. UL, CE, NEMA, IEEE, etc.) 
Possesses extensive knowledge of the application of Toshiba's and competitors product offerings in complex Data Center systems. 
Provides technical guidance and mentorship to more junior engineering team members. 
Develops and reviews product literature such as manuals, brochures, application notes, success stories, Technical Document papers, etc. 
Possesses an extensive knowledge of Toshiba Data Center complimentary products. 
Creates test specifications / test plans for Data Center products. 
Capable of testing assigned Data Center products and competitor's products in the laboratory environment for their performance characteristics. Interface with internal and external 
Design Engineers for the design and development of existing and new Data Center products, author and technically review new product specifications, as well as resolving technical problems on supplied products. 
Interface with internal and external manufacturing regarding customer orders. 
Communicate with sales force and customers and serve as a key contributor in Data Center sales activities. 
Train sales force and customers independently and in-group settings. 
Complete additional projects as assigned by management. 
Comply with all Toshiba policies, procedures and link company objectives to assigned activities. 
Provides leadership to ensure group adherence to policies, procedures and company objectives. 
Responsible for preparing competitive analysis. 
Employee needs to be aware and maintain profitability through orders and quotes. 
This position may be responsible for sign off/review of quotes, according to Toshiba s policy. 

Travel: 25% to 50% 

 Requirements 

Educational Requirements: * An engineering degree in electrical engineering (BSEE or MSEE).* At least 4 years' experience in data center infrastructure over 1MW, including UPS, design, and operations."
Data and Analytics Engineer - Senior Associate,PRICE WATERHOUSE COOPERS,"Houston, TX 77002 (Downtown area)",Posted 15 days ago,,https://www.indeed.com/rc/clk?jk=ea145b55d6514e05&fccid=5e964c4afc56b180&vjs=3,N/A
Lead Data Migration Engineer,Molex,"Friendswood, TX 77546",Posted 15 days ago,"$150,000 - $180,000 a year",https://www.indeed.com/rc/clk?jk=feee9d24993703a0&fccid=de113fe345574782&vjs=3,N/A
Senior Data Engineer,The CloudEnd Platform,"Houston, TX",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=a62ad82f436e23c9&fccid=dd616958bd9ddc12&vjs=3,N/A
Data Engineer with Python,TekValue IT Solutions,"Houston, TX 77002 (Midtown area)",EmployerActive 2 days ago,$60 - $65 an hour,https://www.indeed.com/company/TekValue-IT-Solutions/jobs/Data-Engineer-37f0bc3f679fac13?fccid=dd0695607f4cb8d3&vjs=3,N/A
Data Quality Engineer - All-Payor Claims Database - Hybrid,UTHealth Houston,"Hybrid remote in Houston, TX",EmployerActive 2 days ago,"$80,748 - $121,140 a year",https://www.indeed.com/company/UTHealth-Houston/jobs/Data-Engineer-635cd519959c9a18?fccid=2259246cd8a35c6c&vjs=3,N/A
Data Engineer - Architecture,Vantage Point Consulting,"Remote in Houston, TX",Posted 20 days ago,Contract,https://www.indeed.com/rc/clk?jk=750947a4861e2e75&fccid=5b5ea8923be4052d&vjs=3,N/A
Data Engineer,Integration Developer Network LLC,"Houston, TX 77002 (Fourth Ward area)",Posted 30+ days ago,$65 - $70 an hour,https://www.indeed.com/company/Integration-Developer-Network/jobs/Data-Engineer-f1864bf4bc02aba6?fccid=6af1cd9d656e6476&vjs=3,N/A
Data Engineer,Suvida Healthcare,"Houston, TX 77027 (River Oaks area)",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=8bc8eecdd9551297&fccid=6a2b0db8eb92fae8&vjs=3,N/A
Data Engineer only W2,IDC,"Houston, TX 77004 (Midtown area)",EmployerActive 3 days ago,Contract,https://www.indeed.com/company/SAP-Payroll/jobs/Data-Engineer-cc11a74bd99721f4?fccid=28157d8e78737e82&vjs=3,N/A
DevOps & Data Integration Support Engineer,Jacobs,"Houston, TX 77002 (Downtown area)",Posted 27 days ago,Full-time,https://www.indeed.com/rc/clk?jk=bf39fbc2a2d1d5de&fccid=de56d7554bea5214&vjs=3,"Challenging Today. Reinventing Tomorrow.
 We're invested in you and your success. Everything we do is more than just a project. It's our challenge as human beings, too. That's why we bring a thoughtful and collaborative approach to every one of our partnerships.
 At Jacobs, we challenge the status quo and redefine how to solve the world's greatest challenges, transforming big ideas into intelligent solutions for a more connected, sustainable world.
 Design your career with a company that inspires and empowers you to deliver your best work so you can evolve, grow and succeed – today and into tomorrow


 Your Impact:
 Are you passionate about human space exploration, understanding the origins of the universe, and working with a passionate and diverse team to make a difference? If you are, we need you!
We need your talent, teamwork, and energy to help us achieve great things that inspire people all over the globe. We need you to bring creative ideas and diverse backgrounds to help us envision, shape, and deliver systems that will enable the exploration of space while benefiting people here on Earth. We are excited about what we do, and we need you on our team as we take on exciting challenges for NASA’s pursuits in deep space exploration. Jacobs is NASA’s largest engineering solutions provider working together with NASA at centers across the United States.
We have an exciting opportunity for a DevOps & Data Integration Support Engineer to join the team with our IT Division.
Focus:

DevOps & Data Integration Support Engineer
Cloud Infrastructure Automation 50%
Data Pipeline Management 25%
Quality Assurance/ Continuous Monitoring 25%

Responsibilities:

Establishing initial data pipelines for engineering and partner datasets, moving data from existing Corporate and Customer data resources into hosted Cloud resources
Establishing data pipelines for future use cases
Supporting the in-cloud data engineering efforts around providing the data functionality and experiences from hosted Cloud resources
Establishing the core data services (cataloging, pipelines, interfaces)
Establishing core identity platform configurations and initial implementation
Combination of release engineering, infrastructure provisioning and management, system administration, security, and DevOps advocacy
Works on the automation quality assurance efforts for software development projects, including a review of technical specifications and user stories
S/he executes and maintains automated test scripts, provides documentation for testing methodologies and tools, reports automation results and ensures a focused, methodical approach to automation testing
Building software and systems while managing the platform infrastructure and applications
Perform other duties as required

Here’s What You’ll Need:
 Requisition Qualifications:
This position has been posted at multiple levels. Depending on the candidate's experience, requirements, and business needs, we reserve the right to consider candidates at any level for which this position has been advertised. 

Typically requires a bachelor's degree in a related area or experience in the field.
Proficient in Automation tools native to Google Cloud, AWS Platform including 3rd party tools such as Terraform
Understanding a variety of operating systems — most commonly, but not limited to, Linux — as you will be using them regularly
Managing the continuous integration/continuous development pipeline (CI/CD). You’ll probably be tasked with building this pipeline from scratch
Extensive experience with cloud-based distributed technologies such as Ceph, HDFS, NFS, and S3, as well as dynamic resource management frameworks (like Kubernetes, Mesos, or Yarn)
Deep knowledge of version control (such as Git) and monitoring tools like Grafana, as well as a variety of databases (such as NoSQL and MySQL)
Manage and partner with development teams through taxing testing and release cycles
Knowing how to code, typically in a variety of languages, both in a structured and OOP way. The m Ruby, C/C++, and JavaScript

Requisition Preferences:

Having a Bachelor's degree in computer science or some equivalent, highly technical discipline. Previous success in technical engineering is going to be preferable



Why Join Our Team?

Click on the below links to view just a small sample of all that we do! Come join our team and be part of our future. We look forward to seeing you!

See What We Do
Jacobs Aerospace Solutions Overview  (Please view in Chrome or Microsoft Edge)
In addition to exciting career opportunities, we also have: 

Excellent personal and professional career growth 
9/80 work schedule (every other Friday off) 
Onsite cafeteria (breakfast & lunch) 
Much, much more! 

For more information on our partnership with NASA at Johnson Space Center (JSC), please visit www.wehavespaceforyou.com

Proof of U.S. Citizenship or US Permanent Residency may be a requirement for this position
Must be able to complete a U.S. government background investigation
Management has the prerogative to select at any level for which the position is advertised



Essential Functions
Work Environment
Generally, an office environment, but can involve inside or outside work depending on task. 
Physical Requirements
Work may involve sitting or standing for extended periods (90% of time). May require lifting and carrying up to 25 lbs. (5% of time). 
Equipment and Machines
Standard office equipment (PC, telephone, printer, etc.). 
Attendance
Regular attendance in accordance with established work schedule is critical. Ability to work outside normal schedule and adjust schedule to meet peak periods and surge requirements.
Other Essential Functions
Professional behavior that enhances productivity and promotes teamwork and cooperation. Grooming and dress must be appropriate for the position and must not impose a safety risk/hazard to the employee or others. Jacobs is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, religion, creed, color, national origin, ancestry, sex (including pregnancy, childbirth, breastfeeding, or medical conditions related to pregnancy, childbirth, or breastfeeding), age, medical condition, marital or domestic partner status, sexual orientation, gender, gender identity, gender expression and transgender status, mental disability or physical disability, genetic information, military or veteran status, citizenship, low-income status or any other status or characteristic protected by applicable law. Learn more about your rights under Federal EEO laws and supplemental language."
Vibrations and Data Analysis Engineer,"Stress Engineering Services, Inc.","Houston, TX 77041",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=27e0b900b8abdb7c&fccid=83bf139361af05a1&vjs=3,"Overview: 
  Stress Engineering Services, Inc. is a leading engineering firm providing engineered solutions and professional consulting services across a wide range of engineering disciplines and industry sectors. Since 1972, our clients have benefited from our specialized in-depth technical knowledge, domain expertise, and proven performance in failure analysis, solid mechanics and structural design, reliability and predictive engineering, instrumentation and testing, heat transfer, fluid mechanics, floating systems, forensics, and material science. We maintain an excellent reputation within the industries we serve, with more than 80% of our current business from repeat clients or direct referrals.
 We are seeking an experienced driven engineer with specialties in random vibration and data analysis to help grow our core and emerging practice areas in energy (renewable and conventional), aerospace/defense, and digital solutions. SES provides a broad range of specialized design and analysis services to numerous industries. This person will work in multidisciplinary teams supporting SES core and emerging practice areas solving challenging problems in the field of vibration related to component design/analysis, fluid mechanics, data analysis, integrity assessments, failure analysis, repair solutions and remediation. Responsibilities: 
 
Performing random vibration and mechanical shock data analysis and response prediction
 Measured data processing and analysis of deterministic and random processes
 Structural integrity monitoring
 Fatigue damage estimation in time domain and frequency domain
 Process equipment vibration measurement, analysis, and diagnostics
 Modeling and identification of nonlinearities in structures
 Develop tools that automate tasks to improve efficiency and accuracy
 Participate in project reviews internally and externally
 Assist in preparing proposals, presentations, and technical reports
 Assist with internal R&D initiatives as needed
 Adherence to internal quality management system policies and procedures
 Contribute to the growth of the Company through participation in technical associations and presentation of conference papers/presentations
 Stay informed regarding new technologies and improvements in industry to maintain proficiency 
Qualifications: 
 
MS in Engineering Mechanics, Mechanical Engineering, Civil/Structural Engineering, Aerospace Engineering, or related engineering discipline (PhD a plus)
 Minimum five (5) years experience of random vibration/data analysis projects
 Strong academic background in mathematics, statistics, physics, and algorithm development
 Background in computational modeling and simulation
 Excellent verbal and written communication skills with the ability to explain complex technical problems to people familiar with and unfamiliar with the technical details
 Ability to work independently but leverage input in complex problem solving
 Ability to adapt to changing work environments and priorities
 Ability to balance engineering judgment with business priorities and constraints to deliver high-value work products
 Ability to research and develop sound technical solutions and skills
 Desire to solve real-world problems
 This is an on premise position, must be willing and able to travel as needed (10% or less of time expected)"
"Lead, Data Engineer",Bain & Company,"Houston, TX 77010 (Downtown area)",Posted 30+ days ago,"$157,500 - $189,500 a year",https://www.indeed.com/rc/clk?jk=62cdd6b0344b8b2e&fccid=48270b2eee62c2c6&vjs=3,"WHAT MAKES US A GREAT PLACE TO WORK 

 We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are a Glassdoor Best Place to Work and we have maintained a spot in the top four since its founding in 2009. We believe that diversity, inclusion and collaboration are key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally. 

 WHO YOU’LL WORK WITH 

 Working alongside our generalist consultants, Bain's Advanced Analytics Group (AAG) helps clients across industries solve their biggest problems using our expertise in data science, customer insights, statistics, machine learning, data management, supply chain analytics and data engineering. Stationed in our global offices, AAG team members hold advanced degrees in computer science, engineering, AI, data science, physics, statistics, mathematics, and other quantitative disciplines, with backgrounds in a variety of fields including tech, data science, marketing analytics and academia. 

 WHAT YOU’LL DO 

 As a member of the growing Cloud, Apps and Data Engineering team in Bain’s Advanced Analytics Group, you will: 



Partner with Data Science, Machine Learning, and Platform Engineering teams to develop and deploy production quality code
Develop and champion modern Data Engineering concepts to technical audience and business stakeholders
Implement new and innovative deployment techniques, tooling, and infrastructure automation within Bain and our clients.
Travel is required (30%)
 ABOUT YOU 


Master’s degree in Computer Science, Engineering, or a related technical field.
3+ years at Senior or Staff level, or equivalent
3+ years of experience programming with Python, Scala, C/C++, Java, C#, Go, or similar programming language.
3+ years of experience with SQL or NoSQL databases: PostgreSQL, SQL Server, Oracle, MySQL, Redis, MongoDB, Elasticsearch, Hive, HBase, Teradata, Cassandra, Amazon Redshift, Snowflake.
Experience in deploying serverless data pipelines through containerization and terraform orchestration
Industry level experience of working with public cloud environments (AWS, GCP, or Azure), and associated deep understanding of failover, high-availability, and high scalability
Scaling and optimizing schema and performance tuning SQL and ETL pipelines in data lake and data warehouse environments.
Strong computer science fundamentals in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance.
Data ingestion using one or more modern ETL compute and orchestration frameworks (e.g. Apache Airflow, Luigi, Spark, Apache Nifi, and Apache Beam).
Version control and git workflows
Strong interpersonal and communication skills, including the ability to explain and discuss complex mathematical and machine learning technicalities with colleagues and clients from other disciplines at their level of cognition
Curiosity, proactivity and critical thinking
 ABOUT US 

 Bain & Company is a global consultancy that helps the world’s most ambitious change makers define the future. 

 Across 64 cities in 39 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition, and redefine industries. We complement our tailored, integrated expertise with a vibrant ecosystem of digital innovators to deliver better, faster, and more enduring outcomes. Our 10-year commitment to invest more than $1 billion in pro bono services brings our talent, expertise, and insight to organizations tackling today’s urgent challenges in education, racial equity, social justice, economic development, and the environment. We earned a gold rating from EcoVadis, the leading platform for environmental, social, and ethical performance ratings for global supply chains, putting us in the top 2% of all companies. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry. 


U.S. Compensation and Benefit Information:
 Compensation for this role includes base salary, annual discretionary performance bonus, 401(k) plan with an annual employer contribution based on years of service and Bain’s best in class benefits package (details listed below). 

 Some local governments in the United States require a good-faith, reasonable salary range be included in job postings for open roles. The estimated annualized compensation for this role is as follows: 

 In New York City, the good-faith, reasonable annualized full-time salary range for this role is between $157,500 - $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 In California state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 In Washington state, the good-faith, reasonable annualized full-time salary range for this role is between $157,500- $189,500; placement within this range will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 For all other U.S. locations, the good-faith, reasonable annualized full-time salary range for this role is commensurate with competitive geographic market rates for this role and will vary based on several factors including, but not limited to experience, education, licensure/certifications, training and skill level 

 Annual discretionary performance bonus 

 This role may also be eligible for other elements of discretionary compensation 

 4.5% 401(k) company contribution, which increases after 3 years of service and is 100% vested upon start date 

 Bain & Company's comprehensive U.S. benefits and wellness program is designed to help employees achieve personal independence, protection and stability in the areas most important to you and your family."
Sr Data Engineer (On-site),Shellpoint Mortgage Servicing,"Houston, TX",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=8a7f91ce99254912&fccid=ee2d6fb81ddfc752&vjs=3,"Who we are
 

   Shellpoint Mortgage Servicing (SMS) is one of America’s top-five non-bank mortgage-servicing companies. What is mortgage servicing? Our clients are businesses that own mortgage loans (such as banks and real estate investment firms). On their behalf, we manage (or “service”) their loan portfolios, which means that we collect homeowners’ mortgage payments, pay their tax and insurance bills, and help homeowners in default to get current.
 



 Primary Function/Summary
  



    We are on a mission to evolve how we use data at Shellpoint to grow our business and fulfill the needs of our customers. We are modernizing our data and integration platform to be best in class. In this role you will be responsible for implementing modern architecture and engineering design patterns in a range of technologies, considering both technical and economic perspectives. You will partner with technical and business stakeholders to implement solutions balancing current and legacy technical standards, while keeping an eye towards scalability and resilience. We are looking for someone who can design, code, and execute in both cloud and on prem environments – while evangelizing the opportunities of good engineering design, modern integration architectures and data as a service.
  




    Direct Reports
  


 N/A




    Principal Duties
  


 Serve as a key contributor to identify, evaluate, and execute the development and implementation of data infrastructure.
 Deliver collaborative products that align with organization and decision strategies.
 Consult with technology and business staff to understand business need and provide thought leadership on solutions during requirements gathering sessions.
 Serve as key contributor in the development and maintenance of the data warehouse.
 Support critical strategic initiatives and architect moderately complex data engineering projects.
 Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to curated data sets to data analysts and data scientists.
 Develop, communicate, and present solution architectures to both technology and business stakeholders.
 Develop highly complex SQL queries to extract data for analysis and model construction.
 Design, build, and maintain internal and external data integrations.
 Build robust data pipelines, optimizing workloads across on prem and cloud environments.
 Test and validate data pipelines, transformations, datasets, reports, and dashboards built by team.
 Document and test data processes including performance of through data validation and verification.
 Contribute to delivery of multiple large, complex data engineering projects simultaneously.
 Collaborate with technology management to define standards and best practices for team.
 Mentor and assist other data engineers, data analytics and data scientists.
 Provide support to other data engineering, data analytics, application development, data systems and production support teams.
 Work on other projects as assigned.
 Performs related duties as assigned by supervisor.




    Core Development Stack
  


 Languages: SQL (standard and DB-specific)
 Tools/Products: Microsoft SQL Server, Snowflake, SSIS (SQL Server Integration Services), HVR/Fivetran, Snaplogic, SSRS (SQL Server Reporting Services), RedGate Developer Toolkit, Tableau, PowerBI
 Frameworks: Amazon Web Services (AWS) & Microsoft Azure cloud services
 Other: Azure DevOps, Smartsheet, Microsoft Visio, TFS (Team Foundation Server), Octopai




    Education and Experience Requirements
  


 College or university degree in the field of Information Technology, Data Science, Computer Science, MIS, or another STEM-related field required. Significant experience in a similar role or industry will be considered as a replacement.
 5-7 years engineering/development experience
 Expertise in SQL Server 2017 or higher
 Expertise with data and analytics technologies such as RDBMS, ETL and BI
 Experience with SQL Server Integration Services (SSIS)
 Experience with SQL Server Reporting Services (SSRS)
 Experience with Microsoft Visual Studio 2017 or higher
 Experience with on prem and cloud solution design and engineering
 Experience with Snowflake, Azure, AWS, or other cloud technologies


   Experience with agile delivery methodologies
 



    Knowledge, Skill, and Ability Requirements
  


 Cloud-based solution design and engineering
 Experience with tools such as HVR/Fivetran and Snaplogic are a plus
 Azure data and analytics deployments
 Experience in solution design spanning multiple frameworks
 Experience in other languages such as Python, R, Spark SQL, Java, etc. are a plus
 Experience with Azure DevOps, TFS
 Familiarity with API-first architectures
 Real time streaming data delivery
 DevOps and CI/CD experience
 Mortgage servicing, mortgage lending and/or finance experience



 While this description is intended to be an accurate reflection of the position’s requirements, it in no way implies/states that these are the only job 
responsibilities.
 Management reserves the right to modify, add or remove duties and request other duties, as necessary.



   Company Perks:
  

15 Paid Time Off (PTO) days and 18 after 1st anniversary!
9 Paid Holidays
Employee Engagement Activities



 Company Benefits:
  

Medical (including Health Savings Account & Flexible Savings Account)
Dental - RX – Vision – Life, Disability Insurance – 401(k) Plan with company match! – Employee Assistance Plan



 Performance-based Incentives
Pet Insurance
Advancement Opportunities



   Newrez NOW:
 

Our Corporate Social Responsibility program, Newrez NOW, empowers employees to become leaders in their communities through a robust program that includes volunteering, philanthropy, nonprofit grants, and more
1 Volunteer Time Off (VTO) day, company-paid volunteer day where all eligible employees may participate in a volunteer event with a nonprofit of their choice
Employee Matching Gifts Program: We will match monetary employee donations to eligible non-profit organizations, dollar-for-dollar, up to $1,000 per employee
Newrez Grants Program: Newrez hosts a giving portal where we provide employees an abundance of resources to search for an opportunity to donate their time or monetary contributions


 Equal Employment Opportunity
   We're proud to be an equal opportunity employer- and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better."
Data Platform Engineer,LyondellBasell Industries,"Hybrid remote in Houston, TX 77010",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=7a9528566d45114f&fccid=5938580c9c7de4d3&vjs=3,"Location: Houston, TX, US, 77010 
    







     Req ID: 82614 
    







     Facility: One Houston Center-130 
    







     Department: Data Platform 
    







     Division: Innovation 
    








LyondellBasell



 Basic Function


 LyondellBasell has fully committed to achieving its vision as “The Chemical Company of the Future” and an industry leader in the areas of Sustainability and Customer Experience. The Digital Enterprise that will act as the foundation for enabling this vision will be built upon three pillars: A modern and extensible technology architecture, an ERP backbone that supports new business models, and a team of talented technologists that are empowered to build innovative solutions and digital products.


At the intersection of these pillars, the Data & Analytics Center of Excellence is building the data foundation and a catalog of data products, analytical applications, and enterprise services that give users across our company the tools, data, and guidance to generate insights.


The Data Platform Engineer is part of the team responsible for providing and supporting a modern, scalable and secure data platform for business intelligence, data science and analytics at scale.




 Roles & Responsibilities



Deployment, configuration, support and maintenance of cloud resources on the data platform to support data and analytics at scale and the delivery of data products and services.
Ensure availability, performance and scalability of the data platform.
Help drive automation of platform and self-service for data consumers.
Work with multiple teams both inside and outside the Data & Analytics CoE, such as the Data Engineers, Product teams, Enterprise Architecture team, Cyber Security etc. in implementing end-to-end solutions on the data platform.
Work with Cyber Security team to ensure data platform adheres to security standards.
Implement recommendations for performance, cost, compliance, security etc.
Contribute to the evaluation of new technologies, vendor products and services.
Implement data protection options, including HA and DR protection in Azure.
Configure monitoring and alerting for both availability and performance of the data platform.
Provide input to report on metrics associated with the performance and availability of data platform services and products.
Contribute to continuous improvements, practices, and operational efficiencies within the team.





Min. Qualifications



Bachelor’s degree in Computer Science, Information Systems, Engineering or equivalent experience in a relevant field
10+ years of relevant work experience in the IT industry
3+ years of experience designing, deploying and configuring Azure services.
3+ years of experience supporting cloud environments including IaaS and PaaS
3+ years of experience working with operating systems like UNIX, Linux and Windows server.
Hands on experience using the Azure administration portal and Azure CLI
Proficiency with PowerShell, Python or other scripting languages
Experience in writing SQL queries and Stored Procedures
Knowledge of the Microsoft Enterprise software products and services
Understanding of data flows, data architecture, ETL and processing of structured and unstructured data
Familiarity with database methodologies and various relational and NoSQL database technologies
Experience in resolving issues with Azure resources.
Knowledge of DevOps and Agile concepts & development principles including continuous integration & continuous delivery (CI/CD).
Ability to troubleshoot problems in a diverse and challenging environment





Preferred Qualifications



Microsoft Azure Cloud Platform certification - Administrator or Architect level
Hands on experience deploying and managing Microsoft Azure PaaS services, such as but not limited to Azure SQL, Azure Synapse, Azure Data Lake Store, Azure Data Factory and Azure Kubernetes Service (AKS)
Experience of Reporting and Analytics tools such as Power BI and Tableau
Experience with global enterprise environment or major consulting firm.
Familiarity with Agile and/or Scrum methods of delivery
Knowledge of enterprise ETL tools like Azure Data Factory, SSIS, Informatica or similar.
Experience with CI/CD tools (Git, Azure DevOps, Jenkins, TFS, Maven, Nexus…)
Data Management, Data Integration or Data Engineering experience.
Knowledge of at least one other cloud hosting solution in addition to Azure (e.g., Google, AWS)
Business Continuity or Disaster Recovery planning experience
Understanding of networking concepts (SSL configurations, vnets, nsg, subnets…)

#LI-SS1
#LI-Hybrid




 Competencies



         Builds effective teams
        

          Collaborates
        

          Cultivates innovation
        

          Customer focus
        

          Demonstrates courage
        

          Drives results
        

          Ensures accountability
        

          Instills trust and exemplifies integrity
        





We are LyondellBasell – a leader in the global chemical industry creating solutions for everyday sustainable living. Through advanced technology and focused investments, we are enabling a circular and low carbon economy. Across all we do, we aim to unlock value for our customers, investors and society. As one of the world’s largest producers of polymers and a leader in polyolefin technologies, we develop, manufacture and market high-quality and innovative products for applications ranging from sustainable transportation and food safety to clean water and quality healthcare. For more information, please visit www.lyondellbasell.com or follow @LyondellBasell on LinkedIn.


Must be at least 18 years of age and must be legally authorized to work in the United States (US) on a permanent basis without visa sponsorship.


LyondellBasell does not accept or retain unsolicited résumés or phone calls and/or respond to them or to any third party representing job seekers.


LyondellBasell is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, veteran status, and other protected characteristics. The US EEO is the Law poster is available here."
Data Engineer Senior Consultant (Clearance Required),Deloitte,"Houston, TX",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=544a9838fb67c0c7&fccid=9e215d88a6b33622&vjs=3,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.
 

Work you'll do

 The Data Engineer will design future-state, modern data architecture for transformation at the enterprise level using advanced architectural principles. Using tools such as Snowflake and/or Databricks, they will also work with cutting-edge DevOps technologies, develop advanced analytics products, and apply data and statistical programming tools to enterprise data to advance and enable key mission outcomes within environments (GCP, AWS, Azure).
 

The team 

 Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.
 
 The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.
 
 Qualifications
 
 Required:
 


Minimum Active Top Secret Level Security Clearance



5+ years of professional experience in data engineering (SQL).



5+ years of experience designing and developing real time ETL architecture for real time predictive analytics.



5+ years of experience with Databricks, Snowflake, or AWS



Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field

 Preferred:
 


3+ years of relevant consulting or industry experience



Creativity and innovation - desire to learn and apply new technologies, products, and libraries



Prior professional services or federal consulting experience

 How you'll grow
 
 At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
 
 The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,000 to $181,000
 
 #LI-JRK"
Big Data Integration Engineer,KBR,"Remote in Houston, TX 77002",Posted 20 days ago,Full-time,https://www.indeed.com/rc/clk?jk=2dfbf0c5302913ff&fccid=cbfa56f19cc95796&vjs=3,"Title: Big Data Integration Engineer
 
 ABOUT THIS POSITION
 The successful candidate will be part of the KBR team supporting the Test Resource Management Center’s (TRMC) Big Data (BD) and Knowledge Management (KM) Team deploying BD and KM systems for DoD testing Ranges and various acquisition programs.

 This is being hired nationwide as it is a remote work capable position. The candidate can either work in one of KBR’s facilities or work from home, assuming the candidate has a stable internet connection.

 Responsibilities: 

Deployment and integration of a highly visible data analytic project called Cloud Hybrid Edge-to-Enterprise Evaluation Test & Analysis Suite (CHEETAS) at multiple DoD ranges and labs
 Work with the data science and software engineering team members to support our customers by demonstrating the ‘art of the possible’ with insights gained from analyzing DoD Test & Evaluation data
 Deploy and configure Big Data and Knowledge Management tools in an enterprise environment
 Configure and troubleshoot a variety of Big Data ecosystem tools
 Work with a wide range of stakeholders and functional teams at various levels of experience
 Become a CHEETAS deployment subject matter expert
 Act as a critical part of our technical team responsible for deploying CHEETAS within customer environments
 Work closely with system administrators and software developers to communicate, document and ultimately resolve deployment issues as they arise
 Provide deployment services to various DoD testing Ranges and acquisition programs
 Deploy CHEETAS within disparate environments (on different non-standard hardware stacks and integrated into different existing ecosystems) sometimes located within DoD vaults with no outside internet connectivity
 Act as the frontline interface that customers will have when first experiencing CHEETAS within their DoD Range and lab environments


 This requisition will be used to hire multiple individuals 
Entry level Integration Engineers will NOT be considered due to the breadth of knowledge necessary to be successful in the position. This position is anticipated to require travel of 25% with surges possible up to 50% to support end users located at various DoD Ranges and Labs across the United States. 

Come join the KBR BDKM team and be a part of the award-winning team responsible for revolutionizing how data analysis is performed across the entire Department of Defense!

 BASIC QUALIFICATIONS

 This position requires a bachelor's degree in a STEM Computer Science, Data Science, Statistics or related, technical field, and 7-10 years of experience. Entry level Integration Engineers will NOT be considered.
 Previous experience must include five (5) years of hands-on experience in big data environments.
 Previous experience must include three (3) years of hands-on experience with Kubernetes. Experience in the integration with and configuration of: Hadoop, SQL Server Big Data Cluster, Kubernetes, CentOS, Ubuntu, RedHat, Windows Server, VMWare, etc.)
 Active or Current Secret Clearance required - Top Secret Clearance preferred.


 Knowledge / Skills / Abilities:

 Experience with installation, configuration, integration with and usage of the following tools and technologies: Helms Charts, YAML, Kubernetes, Kubectl, Kubernetes IDE, NFS, SMB, S3, SQL Server, Windows Server, Windows 10/11, Linux (CentOS, Ubuntu, RedHat), Hadoop.
 Must be prepared to learn new business processes or CHEETAS application nuances every Agile sprint release (roughly every 6 weeks) prior to deploying to customer sites.
 Experience with working in distributed team environment is preferred.
 Ability to problem solve, debug, and troubleshoot while under pressure and time constraints is required.
 Ability to communicate effectively about technical topics to both experts and non-experts at both the management and technical level is required.
 Excellent interpersonal skills, oral and written communication skills, and strong personal motivation are necessary to succeed within this position.
 Ability to work independently and provide appropriate recommendations for optimal design, analysis, and development.
 Excellent written and verbal communications skills are required, as the Integration Engineer will be in frequent contact with the project technical lead, be taking direction from various government leads, and will frequently be interacting with end users to gather requirements and implement solutions while away from other team members.
 Ability to teach and mentor engineers with a variety of skill levels and backgrounds is a plus.
 Excellent testing, debugging and problem-solving skills are required to be successful in this position.
 Experience designing, building, integrating with and maintaining both new and existing big data systems and solutions.

 ADDITIONAL QUALIFICATIONS

 The preferred candidate will have experience working in government/defense labs and their computing restrictions.
 Knowledge of the Test and Training Enabling Architecture (TENA), the Joint Mission Environment Testing Capability (JMETC), and Distributed Testing and Training is a plus.
 Experience working with major DoD Acquisition programs such as Joint Strike Fighter (JSF) or Missile Defense Agency (MDA) is a plus.
 Knowledge of DoD Cybersecurity policies is a plus.


 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law."
Senior SAP Data Engineer,The Friedkin Group,"Houston, TX 77077 (West Oaks area)",Posted 15 days ago,Full-time,https://www.indeed.com/rc/clk?jk=b6ebfb8610f01325&fccid=9b2ecf99472139e7&vjs=3,"External Description: 
 
 LIVING OUR VALUES 


  All associates are guided by Our Values. Our Values are the unifying foundation of our companies. We strive to ensure that every decision we make and every action we take demonstrates Our Values. We believe that putting Our Values into practice creates lasting benefits for all of our associates, shareholders, and the communities in which we live.
 


 JOB SUMMARY


   The Sr. SAP Data Engineer is a member of the Data Science and Analytics Team who is responsible for the execution of GST’s Reporting & Analytics strategy. This Sr. SAP Data Engineer is involved in all phases of the analytic projects, from requirements gathering, data architecture, integration guidance, and development and support artifacts. 
 
This Sr. SAP Data Engineer will support SAP BW/HANA design and development efforts. The ideal candidate has the ability to mentor and coach internal and external resources in maintainable development practices and code reviews. This person will demonstrate an ability to manage complex, high-quantity and potentially contradictory information to effectively solve problems, applies knowledge of the business to advance organizational goals, and intuitively navigates complex policy, people and process-related organizational dynamics.


 ESSENTIAL FUNCTIONS


 Collaborate with Business and IT Functional experts to understand business requirements or issues, perform gap analysis in the SAP BW/4 HANA environment and recommend/implement process and/or technology improvements to optimize current reporting environment. 
Hands-on expertise in data architecture, modeling, integration, quality, security and BI/Analytics capabilities with BW/4HANA development objects and integrations end-to-end.
 Gather requirements and create Functional Design/Technical Design specifications.
 Project life-cycle leadership and support for Design, Development, System integration/UAT cycles and Prod Cutover, Post-Go live support, and Environment strategy.
 SAP Functional knowledge of Sales and Distribution, Procurement, Materials Management, Production Planning, and Finance AP/AR/GL and SAP VMS (helpful) for Analytics
 Strong experience in HANA studio and HANA Development.
 Responsible for performance tuning of BW/4HANA utilizing best practices, in collaboration with other IT teams.
 BW/4HANA object development expertise, BW ABAP Coding/Routines, BW Web Cockpit/Monitoring, Process Chains, Content installs, Data Tiering Optimization, Transports and issues analysis/resolution, SAP support messages
 BW Support Pack upgrades/Post install Steps, OSS note analysis/application.
 S/4HANA Embedded Analytics, CDS View Development, Extractor development/ODP
 SAP Data Services knowledge, SAP & Non-SAP Systems integration with BW.
 Execution of POCs for analytic tools.
 Leads and executes incidents resolution, the delivery of minor/monthly and major SAP BI/BW enhancement release cycles, and small projects.
 Facilitates release scoping, design, build, test, change control, documentation and deployment activities with internal and external project and operations teams, business stakeholders, shared services and compliance teams.
 Executes business user communication regarding release scope and deployment timelines.
 Ensures appropriate risk resolution and mitigation for SAP BI/BW platforms as issues are identified.
 Ensures no disruption to business operations upon deployment of SAP BI/BW releases to production systems.
 Must have deep technical expertise in multiple SAP BI suite of products, especially BW, HANA, BOBJ, BODS, SAC.
 Actively researches and develops new knowledge and collaborates on solutions.
 Develops, designs and implements integrated solutions to resolve highly complex technical and business issues.
 Excellent ability to multi-task assigned duties or projects.
 Effectively communicates complex ideas in a clear and concise manner both verbally and in writing.
 Works with minimal supervision and self-driven
 Highly organized; able to organize and assimilate large quantities of complex information.
 Responsibly receive, transmit, and handle consumer and customer data per applicable policies and procedures.
 Review and follow data privacy practices, policies, and guidelines. 
Other duties as assigned.


 SUPERVISORY RESPONSIBILITIES

   This position has no supervisory responsibilities
 


 QUALIFICATIONS 

Requires bachelors’ degree from a four-year college or university with 8 years of in-depth hands-on experience in SAP BI/BW/HANA platform; or possesses an equivalent combination of education and/or experience. 

At least 4 years of experience in SAP BW/4HANA or BW on HANA, 4 years in SAP BW/BI versions including ETL and reporting tools, and 2 years in native HANA modeling.
 Full SAP BI lifecycle Experience (Data Modeling to Reporting) with at least 3 end-to-end implementation projects as Sr. SAP BW/HANA developer.



 Technical Experience


 Hands-on experience working with BW/4 HANA features, standard and custom SAP BW Extractors, complex transformations, advanced DSOs, composite providers, Data Tiering Optimization, exposing BW models as HANA views, mixed (hybrid) scenarios, HANA Analysis process in BW and LSA ++ best practice, data quality, security and performance optimization concepts.
 Advanced knowledge and Hands-on of SAP BW/4HANA & S/4HANA tools for data analytics, visualizations, reporting etc..
 Advanced knowledge and Hands-on of Data Modeling in SAP Analytics. Ability to assimilate requirements into conceptual/logical data models across information management solutions (relational, Dimensional/Columnar, document) 
Hands-on Experience in BW/4 HANA, S/4, with SAP HANA 2.0 data modelling, and reporting/visualization.
 Hands on experience in BW/4HANA, creating Advanced DSO(ADSO), Open DSO Views, Calculation views, Composite Providers and SAP query.
 Advanced knowledge and extensive experience in Data integration (Point to Point, ETL etc)
 Strong knowledge of Agile Methodologies
 Advanced knowledge of best practices and standards for BI development
 Hands-on experience in cloud data platforms such as SAP DWC/Datasphere, AWS and Databricks is strongly preferred



 Technical Stack


 SAP BW/4HANA 2, HANA 2.0
 S/4HANA 1909
 SAP Datasphere (DWC, DI)
 SAP Fiori 2.0
 BW Query on S4
 BI Platform - Tableau
 Data Virtualization - Denodo
 Data Integration (SAP Data Services, Dell Boomi)
 SQL (Ansi, PLSQL, Analytics)
 Data Modeling (BW, HANA, ABAP CDS)
 Cloud Experience with PaaS, DBaaS
 Team Performance management Tools (TFS, JIRA)



 Soft Skills


 Strong analytical, conceptual, and problem-solving abilities
 Manages complexity in order to effectively find solutions and solves problems
 Drives results by consistently achieving completion and closure of tasks, even the face of obstacles and setbacks
 Adaptive personality and ability to function in a fast-paced environment
 A problem solving attitude that can adapt to varying timelines
 A strong attention to detail combined with the ability to prioritize tasks
 Strong interpersonal skills; promoting healthy relationships and team dynamics
 Strong capability to plan and align work with regards to sense of urgency and priority
 Strong capability to provide Business Insight
 Strong ability to influence organization stakeholders



 To perform this job successfully, an individual must be able to perform each essential function satisfactorily. The requirements listed above are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made, to enable qualified individuals with disabilities to perform the essential functions.
 


 CERTIFICATES, LICENSES, REGISTRATIONS*


   Certifications specific to SAP BI/BW/HANA are a strong advantage.
 

   Valid Driver’s License Required.
 


 PHYSICAL REQUIREMENTS


   The physical requirements described here are representative of those that must be met by an associate to successfully perform the essential functions of the job. While performing the duties of the job, the associate is required on a daily basis to analyze and interpret data, communicate, and remain in a stationary position for a significant amount of the work day; and frequently access, input, and retrieve information from the computer and other office productivity devices. The associate is regularly required to move about the office and around the corporate campus. The associate is occasionally required to travel to other sites, including out-of-state, where applicable, for business. The associate must frequently move up to 10 pounds and occasionally move up to 25 pounds.
 

 


WORK ENVIRONMENT


   The work environment characteristics described here are representative of those an associate encounters while performing the essential functions of this job. While the job is generally performed in an office environment, the associate is occasionally exposed to wet and/or humid conditions, areas in which moving mechanical parts, fumes, toxic or caustic chemicals are present, and outside weather conditions. The noise level in the office environment is typically quiet, but the associate may be occasionally exposed to loud noise levels.
 




TRAVEL REQUIRED


   Minimal travel is required for this position (up to 20% of the time and on a domestic basis).
 

 


  The Friedkin Group and its affiliates are equal opportunity employers and maintain drug-free workplaces by conducting pre-employment drug testing.
  Total Rewards: 
 
 TOTAL REWARDS


   Our Total Rewards package is an integral part of how we recognize our associates’ contributions as well as attract, retain and reward the most qualified employees. We are committed to providing a fair and competitive compensation structure that includes base pay and performance based rewards, where applicable. Compensation is based on various factors including, but not limited to, skill set, experience, qualifications and job-related requirements. Our benefits include medical, dental, and vision along with wellness programs, retirement plans, paid leave and much more! To learn more about these programs and many more, take a tour of our Benefits Page at https://www.friedkin.com/benefits."
Data Center Edge Infrastructure Engineer I - Platform Delivery,Crown Castle USA Inc.,"Hybrid remote in Houston, TX 77024",Posted 30+ days ago,Full-time,https://www.indeed.com/rc/clk?jk=a9907abcf2fd8fb7&fccid=b370e17ef47bfd7b&vjs=3,"Position Title: Edge Infrastructure Engineer – Platform Delivery I (P3)


 Company Summary:
 Crown Castle is the nation’s largest provider of shared communications infrastructure: towers, small cells and fiber. It all works together to meet unprecedented demand—connecting people and communities and transforming the way we do business. Whenever you make a call, track a workout or stream music and videos, we’re the ones providing the communications infrastructure that makes it all possible. From 5G and the internet of things to drones, autonomous vehicles and AR/VR, we enable the technologies that help people stay safe, connected and ready for the future. Crown Castle is publicly traded on the S&P 500, and one of the largest Real Estate Investment Trusts in the US, with an enterprise value of ~$70B.
 We offer a total benefits package and professional growth development for teammates in any stage of their career. Along with caring for our teammates, we’re an active member in the communities where we live, work and do business. We have a responsibility to give back, which we do through our Connected by Good program. Giving back allows us to improve public spaces where people connect, promote public safety and advance access to education and technology.


 Role:
 Crown Castle is looking for motivated employees to help our team grow. As a member of the Edge Infrastructure Platform Delivery Team, you will be responsible for scaling services as we continue expanding into new markets and technologies that require more advanced solutions from Crown Castle’s Data Centers. You will be responsible for ensuring Crown Castle’s Edge Data Center Facilities are operating at optimal performance, 24/7. You will monitor and add capacity as needed in mission-critical locations to proactively manage infrastructure utilization and recommended upgrades. This includes planning, engineering, and deployment of HVAC systems, generators, UPS systems, power distribution networks, DC power plants, fire suppression, and general building construction. You will connect all new infrastructure to Crown Castles BMS/EMS systems for remote connectivity and management. The Edge Infrastructure Engineer must be able to work well in cooperative efforts but also be driven and take initiative on tasks that require independent work.


 Responsibilities

Identify necessary facilities upgrades, capacity requirements, and create budgetary requirements
Manage capital projects to meet deadlines and adhere to the allocated budget 
Schedule and coordinate preventative and demand maintenance activities 
Datacenter design and vendor management



 Expectations

Collaborative work done in a way that balances educated decision-making with measured speed of implementation.
 Ability to continuously prioritize long-term plans with short-term urgent response needs.
Ability to influence conversations and work through building relationships, thoughtful framing of issues, and building influence through excellent work.
 Strong written and verbal communication skills with an ability to present complex information in a clear and simple format.
Travel throughout Crown Castle footprint and on-call rotation 


Education/Certifications

Associates degree or equivalent work experience
3+ years experience in data center edge infrastructure



 Experience/Minimum Requirements

Ability to troubleshoot critical infrastructure (generators, UPS Systems, HVAC, AC/DC) 
Knowledge of BMS (Building Management Systems) and alarming platforms 
Experience with reading and creating standard drawing types – floor plans, electrical one-line diagrams, face equipment drawings 
Familiar with budget creation and solution costing 
Familiarity with data center industry best practices



 Organizational Relationship
 Reports to: Sr. Manager, Edge Infrastructure Engineering Platform Delivery


 Title(s) of direct reports (if applicable):


 Working Conditions: This role falls into our hybrid work model working in your assigned office approximately 60% of the time (3 days per week) and where you do your best work 40% (2 days per week). Beginning September 5, 2023 our hybrid work model will be adjusted to 4 days in the office on Monday through Thursday. On Fridays, teammates on the hybrid schedule will have the option to work from the office or home.


 Additional Information: N/A


 #LI - Hybrid
 #LI-MP1

 Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
 The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data and Analytics Engineer - Senior Associate,PRICE WATERHOUSE COOPERS,"Houston, TX 77002 (Downtown area)",Posted 15 days ago,,https://www.indeed.com/rc/clk?jk=ea145b55d6514e05&fccid=5e964c4afc56b180&vjs=3,"A career in our Managed Services team will provide you an opportunity to collaborate with a wide array of teams to help our clients implement and operate new capabilities, achieve operational efficiencies, and harness the power of technology. Our Managed Data, Analytics & Insights team will provide you with the opportunity to help organizations harness the power of their enterprise data/analytics solutions by optimizing the technology while driving innovation to increase business outcomes and through data insights. We assist our clients in capitalizing on technology improvements, implementing new capabilities and achieving operational insights by managing, maintaining and evolving their analytics platforms and ecosystems. We help our clients maximize the value of their investment focusing on continuous improvement of their analytics solutions such as Microsoft, Amazon Web Services and Google Cloud.
  To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

 As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:


 Use feedback and reflection to develop self awareness, personal strengths and address development areas.
 Delegate to others to provide stretch opportunities, coaching them to deliver results.
 Demonstrate critical thinking and the ability to bring order to unstructured problems.
 Use a broad range of tools and techniques to extract insights from current industry or sector trends.
 Review your work and that of others for quality, accuracy and relevance.
 Know how and when to use tools available for a given situation and can explain the reasons for this choice.
 Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
 Use straightforward communication, in a structured way, when influencing and connecting with others.
 Able to read situations and modify behavior to build quality relationships.
 Uphold the firm's code of ethics and business conduct.


 Additional Responsibilities: 
Our Data and Analytics Managed services team is focused to build, enhance, and scale the modern, connected data ecosystem that accelerates the use of data, analytics, and advanced AI. We are in search of passionate, motivated, and creative Senior Associates in role of Data Technology Engineer, Data Governance SME to join our Managed services team. The senior associate will be responsible for designing and implementing innovative solutions to build and manage the advanced Data ecosystem.

 Basic Qualifications:   Minimum Degree Required:  Bachelor Degree  Minimum Years of Experience:  10 year(s)   Preferred Qualifications:   Preferred Fields of Study:  Computer and Information Science, Information Technology  Certification(s) Preferred: 
Certification in any industry leading tools or technology for Data and Analytics
 Preferred Knowledge/Skills: 
Demonstrates thorough abilities and/or a proven record of success as a team leader by:

 Demonstrating minimum 5 years’ experience of leading data architecture and design implementations and discussions;
 Demonstrating minimum 3 years hand on experience building advanced Data warehousing solutions on leading cloud platforms;
 Demonstrating minimum 3 years’ hands on Experience of delivering Managed Data and Analytics programs (Managed services and Managed assets);
 Designing, implementation and maintaining data technology solutions that meet business requirements;
 Developing scalable, repeatable, and secure data structures and pipelines to ingest, store, collect, standardize, and integrate data that for downstream consumption like Business Intelligence systems, Analytics modelling, Data scientists etc.;
 Building efficient, ETL/ELT processes using industry leading tools like Informatica, Talend, Spark etc.
 Building and maintaining Data Governance solutions (Data Quality, Metadata management, Lineage, Master Data Management and Data security) using industry leading tools;
 Demonstrating experience with Data analytics tools like Informatica, Collibra, Hadoop, Spark, Snowflake etc.;
 Understanding of data consumption patterns and BI tools like tableau, Qlik sense, PowerBI etc.;
 Demonstrating experience of ITIL processes like Incident management, Problem Management, Knowledge management, Release management, Data DevOps etc.;
 Demonstrating communication, problem solving, quantitative and analytical abilities;
 Working with a managed services organization with a passion for building new service offerings in the Data and Analytics space and demonstrate proven experience in following key areas/activities;
 Designing, implementing, and maintaining data technology solutions that meet business requirements;
 Implementing Data processing functions like Data Cleansing, profiling, wrangling standardization and make data available to be ingested the Data ecosystem using advanced concepts like Data lakes, Data fabric, Data Vault, Data Mesh etc.;
 Driving large transformation initiatives like Cloud migration etc.;
 Working closely with cross functional teams to develop and maintain scalable, robust, and efficient data architectures to support business Intelligence, analytics, and reporting needs;
 Evaluating and selecting best fit tools and technologies by conducting PoCs and Pilot solutions;
 Conducting performance tuning, troubleshooting and optimization of Data solutions to improve system performance and stability; and,
 Providing guidance and mentorship to junior associates and engineers in the team.

 Learn more about how we work: https://pwc.to/how-we-work
 
 PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.
 
 All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.
 
 For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.
 
 For positions in Albany (NY), California, Colorado, Nevada, New York City, Washington State, or Westchester County (NY), please visit the following link for pay range information: https://pwc.to/payrange-v1-mgdsrvcsseniorassociate"
Lead Data Migration Engineer,Molex,"Friendswood, TX 77546",Posted 15 days ago,"$150,000 - $180,000 a year",https://www.indeed.com/rc/clk?jk=feee9d24993703a0&fccid=de113fe345574782&vjs=3,"Your Job
 Molex is seeking a Lead Data Migration Engineer, you will play a critical role in ensuring the smooth and efficient transfer of data from SAP PLM to Siemens Teamcenter, two enterprise software solutions used for product lifecycle management in an exciting global project. Your primary responsibility will be to analyze, plan, design, and execute data migration strategies, ensuring data integrity, accuracy, and consistency throughout the process. You will collaborate closely with cross-functional teams, including data analysts, software developers, project managers, and stakeholders, to successfully migrate data from SAP PLM to Siemens Teamcenter within defined timelines and quality standards.
 This role is open to worked remotely in the US, with travel as needed to our headquarters in Lisle, Illinois.
 This role is not open to immigration sponsorship

 Our Team
 This individual will manage a team of Koch Global Soultions resources of 4 to 14 people out of India and drive our technical strategy with inputs from our business teams to ensure the successful migration of data in support of our global Siemens Team Center and Ops Center go lives.
 What You Will Do

 Analyze SAP PLM (ECTR) data and Siemens Teamcenter systems to determine data migration requirements and objectives. 
Develop and implement data migration strategies and plans, ensuring data integrity, accuracy, and consistency. 
Collaborate with stakeholders to gather and define data migration requirements, including data mapping, transformation rules, and validation procedures for the specific migration scenario. 
Design and optimize ETL processes for data extraction, transformation, and loading to ensure efficient and timely migration from SAP PLM to Siemens Teamcenter. 
Develop scripts and automate data migration tasks specific to the SAP PLM to Siemens Teamcenter migration, streamlining the process and minimizing manual intervention. 
Perform data profiling and cleansing activities to identify and address data quality issues prior to migration. 
Attend daily standups and communicate any challenges along with corrective actions upward on a regular basis. 
Develop and maintain documentation of data architecture, data flow and models for various audiences 


Who You Are (Basic Qualifications)


Proven experience as a Data Migration Engineer or similar role, with hands-on experience in migrating PLM data (this could be SAP ECTR PLM, Teamcenter, Enovia, or other) 
Strong understanding of PLM data structures (hierarchical, components to assemblies, etc.). 
Deep knowledge of ETL, and awareness of different ETL solutions such as AWS Glue, Informatica, or Talend. 
Solid understanding of relational databases, data warehousing, and database management systems. 
Familiarity with data modeling such as Erwin ER diagrams and data mapping techniques. 
5+ years of experience with datawarehouse and data transformation technologies. 
5+ years of experience with ETL technology. 
5+ years of SQL development (queries, procedures, views, table design, etc.) 
Knowledge of application development concepts and techniques 


What Will Put You Ahead


Manufacturing environment with a consulting background 
Certification in data management, SAP PLM, Siemens Teamcenter, or related field is a plus. 
A Bachelor or master's degree in computer science, engineering, or Information systems. 
Experience with SAP ECC/BW/HANA/S4/SLT/ABAP 
Awareness of real time replication technologies such as SLT, HVR, Pro2SQL, Goldengate, etc. 
Knowledge of advanced data lake technologies such as Iceberg and Tabular 
Experience with Snowflake on AWS. 
Knowledge and experience building the modern composable architecture. 
Experience in working with multi-vendor, multi-culture, distributed offshore and onshore development teams in a dynamic and complex environment. 
Data Governance, Security and Compliance challenges with data, understanding of ITAR, EAR, and other kinds of restrictions. 
Experience with AWS Services, S3, Lambda, Athena, Glue, etc. 

For this role, we anticipate paying $150,000 - $180,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
 Hiring Philosophy
 All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
 Who We Are
 As a Koch company, Molex is a leading supplier of connectors and interconnect components, driving innovation in electronics and supporting industries from automotive to health care and consumer to data communications. The thousands of innovators who work for Molex have made us a global electronics leader. Our experienced people, groundbreaking products and leading-edge technologies help us deliver a wider array of solutions to more markets than ever before.
 At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
 Our Benefits
 Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
 #LI-KB3
 Equal Opportunities 
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf"
Senior Data Engineer,The CloudEnd Platform,"Houston, TX",Posted 30+ days ago,,https://www.indeed.com/rc/clk?jk=a62ad82f436e23c9&fccid=dd616958bd9ddc12&vjs=3,"What you’ll do

        we are Looking for technical person with strong Data engineering and Analysis skills. Must have Master’s degree or its foreign equivalent in Computer Science, Engineering, or other IT related field and 12 months experience in the job offered or in any information technology field. Job at Houston, TX and other unanticipated client locations across U.S. In lieu of Master’s degree and 12 months experience, employer will also accept Master’s degree without any experience. Employer will accept any other suitable combination of education, training, and/or experience.
      
 Who you are

 A passion for machine learning and developer tools.
 Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result
 Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services.
 Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks.
 Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings
 Mentor and lead data engineers providing technical guidance and oversightwith ongoing support, monitoring, and maintenance of deployed products.

Qualifications

       You have contributed to or working knowledge in two or more of the following:
       
 Open-source ML frameworks (e.g. Tensorflow, TFX, PyTorch)
 Cloud technology stacks (e.g. GCP or AWS and their product offerings)
 ML pipelines and their orchestration
 Jupyter notebooks
 Distributed data processing in Hadoop, Spark, BigQuery, or Apache Beam
 Modeling, model architecture or optimization
 Data and feature engineering
 Distributed training and/or GPU-based training and inference
 Experience with distributed systems, their performance optimization and improving their resilience
 By nature of the problem domain, we expect you to also have experience in:
       
 B.S., M.S. or Ph.D. degree in computer science or a related field or equivalent work experience.


 2+ years of experience in two of: Scala, Python, C++, Java
 2+ years of building and delivering working software through an iterative, agile process.
 2+ years of experience with ML problems and tools.

Additional Information

        CloudEnd values diversity and inclusion and is committed to the principles of Equal Employment Opportunity EOE.All your information will be kept confidential according to EEO guidelines.We are committed to an inclusive and diverse Cloudend. Cloudend is an equal opportunity employer. We do not discriminate based on race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status."
Implementation Specialist - Production Data Lifecycle Solutions | Petroleum Engineer,Peloton,"Katy, TX 77494",Posted 2 days ago,Full-time,https://www.indeed.com/rc/clk?jk=7f91430a6ef07471&fccid=8451b1829a8bc32a&vjs=3,"Implementation Specialist, Production Data Lifecycle Solutions
 Peloton Computer Enterprises Inc. (https://www.peloton.com/)

 Peloton is looking to grow our Production Data Lifecycle Solutions team with the addition of Implementation Specialists within our Houston, TX office. The ideal candidates are Petroleum Engineers with at least 2-3 years' relevant experience and a passion for data.

 Reports To: US Services Manager, Production Data Lifecycle Solutions

 Supervisory responsibilities:

None



 Principal Duties and Responsibilities:

Liaise with clients to determine current and future Peloton application requirements and implement the Production Data Lifecycle solution with these requirements in mind.
Develop project plans and coordinate technical implementations and rollout of Peloton applications at client sites.
Work with clients to deliver Peloton specific, customized application training (including train the trainer programs) to be delivered throughout the organization.
Serve as technical resource of escalated technical issues for clients (liaise with Development team if necessary). 


Deliver technical excellence presentations at staff meetings / gatherings to transfer knowledge throughout the organization.



 Qualifications:

Bachelor of Science in Engineering


Entry to mid-level experience in oil and gas operations with a focus on production accounting systems is a plus
Good understanding of network flow schematics and production allocation
Working knowledge around regulatory filing requirements for production volumes is a plus
Ability to communicate effectively with client and Peloton development team
Ability to manage balance between client business needs and Peloton development capabilities


Excellent oral and written communication skills
Strong problem-solving skills
Proficient in Windows, Microsoft Office and general IT / software installation processes
Understanding of database / reporting technology
Prior knowledge of Peloton applications or competitive products like P2's ProCount, Schlumberger’s Avocet Capture or Landmark’s TOW is a strong plus


Occasional travel will be required to client locations (up to 30% of the time)



 As part of our team you’ll enjoy:

Exceptional benefits package
Vacation & Paid Time Off
Retirement benefit with employer contribution



 About Peloton
 The Peloton Platform energizes the oil and gas digital transformation through mobility, automation and data integration by providing fully integrated well data lifecycle, production data lifecycle and land data management solutions. Today, over 600 oil and gas clients worldwide rely on Peloton technology to equip their stakeholders with the tools and information necessary to manage, simplify and optimize their operations. For more information, visit www.peloton.com.

 By submitting your job application, your confirm that you agree to the storing and processing of your personal data by Peloton as described in our Privacy Policy."
Remote Data Engineer (Clearance Required),Deloitte,"Remote in Houston, TX",Posted 28 days ago,Full-time,https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DIXU_djF9v0NrX_xbLRwj6RWFeuMEgTY6VvwKgvleOVKv2ag2Qg1tPUWJjUAFC1lcA-fJGonFnLQBIzhsK4aBMr9zCIXQIALFX9p_o-wdGFbOHnzidUCfoTKGRuYn7s0uvD0pwAcCRlOHCFf_F_pBrh9XYb94UG5HWnDPoLij1wfKlSH57ixJvZ99peyJpBVjfvn5Wk7fnqRJt0kCi-l7NOYy4Z4n7fcK7OMmi-1vLw6umGBrYFcGQs3-MkDWTYx8tBh29OCfYVybGNJWtwdVIJtyKO1jYElsMWOBBIg0A1ZV9V_uBuBrmTgRg1IHO9aLrgLeRkYH2Dc7_QAzQUrC6XK9OrZ1FDV0Nx0Yn2DE5dIKGieOV30YMI33NtInc7MiGiC6_pRia1GOk3vpDvoKS08Ossx1abNZPVc4eCm9Da9hBH3G0_oSIfVvDT3WwrcMeBWJoN5VI-Ckprdq86sDbSOKolZ3VgNrwXWj5pLpiAQoyRP3vqSFfdwolh9PhOyoUwpTZzDj3iyRLcVlVF9FAWahsgxME6HtW-3oSK4Lw9LTqSX0nq1Jry9QlNf6FpsGXqokFxWv5E9IXRWKcm7hU&xkcb=SoDC-_M3MLz5btX-4Z0FbzkdCdPP&p=14&fvj=0&vjs=3,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.
 

Work you'll do

 The Data Engineer will design future-state, modern data architecture for transformation at the enterprise level using advanced architectural principles. Using tools such as Snowflake and/or Databricks, they will also work with cutting-edge DevOps technologies, develop advanced analytics products, and apply data and statistical programming tools to enterprise data to advance and enable key mission outcomes within environments (GCP, AWS, Azure).
 

The team 

 Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.
 
 The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.
 
 Qualifications
 
 Required:
 


Minimum Active Top Secret Level Security Clearance



10+ years of professional experience in data engineering (SQL).



10+ years of experience designing and developing real time ETL architecture for real time predictive analytics.



5+ years of experience with Databricks, Snowflake, or AWS



Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field

 Preferred:
 


3+ years of relevant consulting or industry experience



Creativity and innovation - desire to learn and apply new technologies, products, and libraries



Prior professional services or federal consulting experience

 How you'll grow
 
 At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
 
 The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,000 to $181,000
 
 #LI-MG1"
